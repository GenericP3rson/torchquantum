Search.setIndex({"docnames": ["api_functional", "api_layers", "api_operators", "api_torchquantum", "examples/ICCAD22_tutorial/README", "examples/ICCAD22_tutorial/sec1_basic", "examples/ICCAD22_tutorial/sec2_pulse", "examples/ICCAD22_tutorial/sec3_gate", "examples/QCE22_tutorial/README", "examples/QCE22_tutorial/sec1_basic", "examples/QCE22_tutorial/sec2_gate", "examples/QCE22_tutorial/sec3_pulse", "examples/README", "examples/clifford_qnn/README", "examples/gradient_pruning/README", "examples/gradient_pruning/probabilistic_gradient_pruning", "examples/grover/README", "examples/hadamard_grad/example", "examples/index", "examples/mnist/README", "examples/param_shift_onchip_training/README", "examples/param_shift_onchip_training/param_shift_onchip_training", "examples/quantum_kernel_method/README", "examples/quantum_kernel_method/quantum_kernel_method", "examples/quantum_lstm/README", "examples/quantum_lstm/qlstm", "examples/quantum_transformer/Qtransformer-torch", "examples/quantum_transformer/README", "examples/quanvolution/README", "examples/quanvolution/quanvolution", "examples/qubit_rotation/README", "examples/qubit_rotation/TQ_Qubit_Rotation_Tutorial", "examples/quest/README", "examples/superdense_coding/README", "examples/superdense_coding/superdense_coding_torchquantum", "examples/train_state_prep/README", "examples/vqe/README", "examples_README", "generated/torchquantum.functional.apply_unitary_bmm", "generated/torchquantum.functional.apply_unitary_einsum", "generated/torchquantum.functional.ccnot", "generated/torchquantum.functional.ccx", "generated/torchquantum.functional.cnot", "generated/torchquantum.functional.cp", "generated/torchquantum.functional.crot", "generated/torchquantum.functional.crx", "generated/torchquantum.functional.cry", "generated/torchquantum.functional.crz", "generated/torchquantum.functional.cswap", "generated/torchquantum.functional.cu", "generated/torchquantum.functional.cu1", "generated/torchquantum.functional.cu2", "generated/torchquantum.functional.cu3", "generated/torchquantum.functional.cx", "generated/torchquantum.functional.cy", "generated/torchquantum.functional.cz", "generated/torchquantum.functional.echoedcrossresonance", "generated/torchquantum.functional.ecr", "generated/torchquantum.functional.gate_wrapper", "generated/torchquantum.functional.hadamard", "generated/torchquantum.functional.i", "generated/torchquantum.functional.multicnot", "generated/torchquantum.functional.multirz", "generated/torchquantum.functional.multixcnot", "generated/torchquantum.functional.p", "generated/torchquantum.functional.paulix", "generated/torchquantum.functional.pauliy", "generated/torchquantum.functional.pauliz", "generated/torchquantum.functional.phaseshift", "generated/torchquantum.functional.qubitunitary", "generated/torchquantum.functional.qubitunitaryfast", "generated/torchquantum.functional.qubitunitarystrict", "generated/torchquantum.functional.reset", "generated/torchquantum.functional.rot", "generated/torchquantum.functional.rx", "generated/torchquantum.functional.rxx", "generated/torchquantum.functional.ry", "generated/torchquantum.functional.ryy", "generated/torchquantum.functional.rz", "generated/torchquantum.functional.rzx", "generated/torchquantum.functional.rzz", "generated/torchquantum.functional.s", "generated/torchquantum.functional.shadamard", "generated/torchquantum.functional.singleexcitation", "generated/torchquantum.functional.sswap", "generated/torchquantum.functional.swap", "generated/torchquantum.functional.sx", "generated/torchquantum.functional.t", "generated/torchquantum.functional.toffoli", "generated/torchquantum.functional.u", "generated/torchquantum.functional.u1", "generated/torchquantum.functional.u2", "generated/torchquantum.functional.u3", "generated/torchquantum.functional.x", "generated/torchquantum.functional.y", "generated/torchquantum.functional.z", "generated/torchquantum.functional.zx", "generated/torchquantum.functional.zz", "generated/torchquantum.layers.CXCXCXLayer", "generated/torchquantum.layers.CXLayer", "generated/torchquantum.layers.ClassicalInOpAll", "generated/torchquantum.layers.FixedOpAll", "generated/torchquantum.layers.Op1QAllLayer", "generated/torchquantum.layers.Op2QAllLayer", "generated/torchquantum.layers.Op2QButterflyLayer", "generated/torchquantum.layers.Op2QDenseLayer", "generated/torchquantum.layers.QFTLayer", "generated/torchquantum.layers.QuantumModuleFromOps", "generated/torchquantum.layers.RXYZCXLayer0", "generated/torchquantum.layers.RandomLayer", "generated/torchquantum.layers.RandomLayerAllTypes", "generated/torchquantum.layers.RandomOp1All", "generated/torchquantum.layers.SWAPSWAPLayer", "generated/torchquantum.layers.TrainableOpAll", "generated/torchquantum.layers.TwoQAll", "generated/torchquantum.operators.AllWires", "generated/torchquantum.operators.AnyWires", "generated/torchquantum.operators.CNOT", "generated/torchquantum.operators.CRX", "generated/torchquantum.operators.CRY", "generated/torchquantum.operators.CRZ", "generated/torchquantum.operators.CRot", "generated/torchquantum.operators.CSWAP", "generated/torchquantum.operators.CU1", "generated/torchquantum.operators.CU2", "generated/torchquantum.operators.CU3", "generated/torchquantum.operators.CY", "generated/torchquantum.operators.CZ", "generated/torchquantum.operators.DiagonalOperation", "generated/torchquantum.operators.ECR", "generated/torchquantum.operators.EchoedCrossResonance", "generated/torchquantum.operators.Hadamard", "generated/torchquantum.operators.I", "generated/torchquantum.operators.MultiCNOT", "generated/torchquantum.operators.MultiRZ", "generated/torchquantum.operators.MultiXCNOT", "generated/torchquantum.operators.NParamsEnum", "generated/torchquantum.operators.Observable", "generated/torchquantum.operators.Operation", "generated/torchquantum.operators.Operator", "generated/torchquantum.operators.PauliX", "generated/torchquantum.operators.PauliY", "generated/torchquantum.operators.PauliZ", "generated/torchquantum.operators.PhaseShift", "generated/torchquantum.operators.QubitUnitary", "generated/torchquantum.operators.QubitUnitaryFast", "generated/torchquantum.operators.RX", "generated/torchquantum.operators.RXX", "generated/torchquantum.operators.RY", "generated/torchquantum.operators.RYY", "generated/torchquantum.operators.RZ", "generated/torchquantum.operators.RZX", "generated/torchquantum.operators.RZZ", "generated/torchquantum.operators.Reset", "generated/torchquantum.operators.Rot", "generated/torchquantum.operators.S", "generated/torchquantum.operators.SHadamard", "generated/torchquantum.operators.SSWAP", "generated/torchquantum.operators.SWAP", "generated/torchquantum.operators.SX", "generated/torchquantum.operators.SingleExcitation", "generated/torchquantum.operators.T", "generated/torchquantum.operators.Toffoli", "generated/torchquantum.operators.TrainableUnitary", "generated/torchquantum.operators.TrainableUnitaryStrict", "generated/torchquantum.operators.U1", "generated/torchquantum.operators.U2", "generated/torchquantum.operators.U3", "generated/torchquantum.operators.WiresEnum", "index", "usage_installation"], "filenames": ["api_functional.rst", "api_layers.rst", "api_operators.rst", "api_torchquantum.rst", "examples/ICCAD22_tutorial/README.md", "examples/ICCAD22_tutorial/sec1_basic.ipynb", "examples/ICCAD22_tutorial/sec2_pulse.ipynb", "examples/ICCAD22_tutorial/sec3_gate.ipynb", "examples/QCE22_tutorial/README.md", "examples/QCE22_tutorial/sec1_basic.ipynb", "examples/QCE22_tutorial/sec2_gate.ipynb", "examples/QCE22_tutorial/sec3_pulse.ipynb", "examples/README.md", "examples/clifford_qnn/README.md", "examples/gradient_pruning/README.md", "examples/gradient_pruning/probabilistic_gradient_pruning.ipynb", "examples/grover/README.md", "examples/hadamard_grad/example.ipynb", "examples/index.rst", "examples/mnist/README.md", "examples/param_shift_onchip_training/README.md", "examples/param_shift_onchip_training/param_shift_onchip_training.ipynb", "examples/quantum_kernel_method/README.md", "examples/quantum_kernel_method/quantum_kernel_method.ipynb", "examples/quantum_lstm/README.md", "examples/quantum_lstm/qlstm.ipynb", "examples/quantum_transformer/Qtransformer-torch.ipynb", "examples/quantum_transformer/README.md", "examples/quanvolution/README.md", "examples/quanvolution/quanvolution.ipynb", "examples/qubit_rotation/README.md", "examples/qubit_rotation/TQ_Qubit_Rotation_Tutorial.ipynb", "examples/quest/README.md", "examples/superdense_coding/README.md", "examples/superdense_coding/superdense_coding_torchquantum.ipynb", "examples/train_state_prep/README.md", "examples/vqe/README.md", "examples_README.md", "generated/torchquantum.functional.apply_unitary_bmm.rst", "generated/torchquantum.functional.apply_unitary_einsum.rst", "generated/torchquantum.functional.ccnot.rst", "generated/torchquantum.functional.ccx.rst", "generated/torchquantum.functional.cnot.rst", "generated/torchquantum.functional.cp.rst", "generated/torchquantum.functional.crot.rst", "generated/torchquantum.functional.crx.rst", "generated/torchquantum.functional.cry.rst", "generated/torchquantum.functional.crz.rst", "generated/torchquantum.functional.cswap.rst", "generated/torchquantum.functional.cu.rst", "generated/torchquantum.functional.cu1.rst", "generated/torchquantum.functional.cu2.rst", "generated/torchquantum.functional.cu3.rst", "generated/torchquantum.functional.cx.rst", "generated/torchquantum.functional.cy.rst", "generated/torchquantum.functional.cz.rst", "generated/torchquantum.functional.echoedcrossresonance.rst", "generated/torchquantum.functional.ecr.rst", "generated/torchquantum.functional.gate_wrapper.rst", "generated/torchquantum.functional.hadamard.rst", "generated/torchquantum.functional.i.rst", "generated/torchquantum.functional.multicnot.rst", "generated/torchquantum.functional.multirz.rst", "generated/torchquantum.functional.multixcnot.rst", "generated/torchquantum.functional.p.rst", "generated/torchquantum.functional.paulix.rst", "generated/torchquantum.functional.pauliy.rst", "generated/torchquantum.functional.pauliz.rst", "generated/torchquantum.functional.phaseshift.rst", "generated/torchquantum.functional.qubitunitary.rst", "generated/torchquantum.functional.qubitunitaryfast.rst", "generated/torchquantum.functional.qubitunitarystrict.rst", "generated/torchquantum.functional.reset.rst", "generated/torchquantum.functional.rot.rst", "generated/torchquantum.functional.rx.rst", "generated/torchquantum.functional.rxx.rst", "generated/torchquantum.functional.ry.rst", "generated/torchquantum.functional.ryy.rst", "generated/torchquantum.functional.rz.rst", "generated/torchquantum.functional.rzx.rst", "generated/torchquantum.functional.rzz.rst", "generated/torchquantum.functional.s.rst", "generated/torchquantum.functional.shadamard.rst", "generated/torchquantum.functional.singleexcitation.rst", "generated/torchquantum.functional.sswap.rst", "generated/torchquantum.functional.swap.rst", "generated/torchquantum.functional.sx.rst", "generated/torchquantum.functional.t.rst", "generated/torchquantum.functional.toffoli.rst", "generated/torchquantum.functional.u.rst", "generated/torchquantum.functional.u1.rst", "generated/torchquantum.functional.u2.rst", "generated/torchquantum.functional.u3.rst", "generated/torchquantum.functional.x.rst", "generated/torchquantum.functional.y.rst", "generated/torchquantum.functional.z.rst", "generated/torchquantum.functional.zx.rst", "generated/torchquantum.functional.zz.rst", "generated/torchquantum.layers.CXCXCXLayer.rst", "generated/torchquantum.layers.CXLayer.rst", "generated/torchquantum.layers.ClassicalInOpAll.rst", "generated/torchquantum.layers.FixedOpAll.rst", "generated/torchquantum.layers.Op1QAllLayer.rst", "generated/torchquantum.layers.Op2QAllLayer.rst", "generated/torchquantum.layers.Op2QButterflyLayer.rst", "generated/torchquantum.layers.Op2QDenseLayer.rst", "generated/torchquantum.layers.QFTLayer.rst", "generated/torchquantum.layers.QuantumModuleFromOps.rst", "generated/torchquantum.layers.RXYZCXLayer0.rst", "generated/torchquantum.layers.RandomLayer.rst", "generated/torchquantum.layers.RandomLayerAllTypes.rst", "generated/torchquantum.layers.RandomOp1All.rst", "generated/torchquantum.layers.SWAPSWAPLayer.rst", "generated/torchquantum.layers.TrainableOpAll.rst", "generated/torchquantum.layers.TwoQAll.rst", "generated/torchquantum.operators.AllWires.rst", "generated/torchquantum.operators.AnyWires.rst", "generated/torchquantum.operators.CNOT.rst", "generated/torchquantum.operators.CRX.rst", "generated/torchquantum.operators.CRY.rst", "generated/torchquantum.operators.CRZ.rst", "generated/torchquantum.operators.CRot.rst", "generated/torchquantum.operators.CSWAP.rst", "generated/torchquantum.operators.CU1.rst", "generated/torchquantum.operators.CU2.rst", "generated/torchquantum.operators.CU3.rst", "generated/torchquantum.operators.CY.rst", "generated/torchquantum.operators.CZ.rst", "generated/torchquantum.operators.DiagonalOperation.rst", "generated/torchquantum.operators.ECR.rst", "generated/torchquantum.operators.EchoedCrossResonance.rst", "generated/torchquantum.operators.Hadamard.rst", "generated/torchquantum.operators.I.rst", "generated/torchquantum.operators.MultiCNOT.rst", "generated/torchquantum.operators.MultiRZ.rst", "generated/torchquantum.operators.MultiXCNOT.rst", "generated/torchquantum.operators.NParamsEnum.rst", "generated/torchquantum.operators.Observable.rst", "generated/torchquantum.operators.Operation.rst", "generated/torchquantum.operators.Operator.rst", "generated/torchquantum.operators.PauliX.rst", "generated/torchquantum.operators.PauliY.rst", "generated/torchquantum.operators.PauliZ.rst", "generated/torchquantum.operators.PhaseShift.rst", "generated/torchquantum.operators.QubitUnitary.rst", "generated/torchquantum.operators.QubitUnitaryFast.rst", "generated/torchquantum.operators.RX.rst", "generated/torchquantum.operators.RXX.rst", "generated/torchquantum.operators.RY.rst", "generated/torchquantum.operators.RYY.rst", "generated/torchquantum.operators.RZ.rst", "generated/torchquantum.operators.RZX.rst", "generated/torchquantum.operators.RZZ.rst", "generated/torchquantum.operators.Reset.rst", "generated/torchquantum.operators.Rot.rst", "generated/torchquantum.operators.S.rst", "generated/torchquantum.operators.SHadamard.rst", "generated/torchquantum.operators.SSWAP.rst", "generated/torchquantum.operators.SWAP.rst", "generated/torchquantum.operators.SX.rst", "generated/torchquantum.operators.SingleExcitation.rst", "generated/torchquantum.operators.T.rst", "generated/torchquantum.operators.Toffoli.rst", "generated/torchquantum.operators.TrainableUnitary.rst", "generated/torchquantum.operators.TrainableUnitaryStrict.rst", "generated/torchquantum.operators.U1.rst", "generated/torchquantum.operators.U2.rst", "generated/torchquantum.operators.U3.rst", "generated/torchquantum.operators.WiresEnum.rst", "index.rst", "usage_installation.rst"], "titles": ["torchquantum.functional", "torchquantum.layers", "torchquantum.operators", "torchquantum", "ICCAD 2022 Tutorial [slides]", "<strong>Setup</strong>", "<strong>Section2 Use Torchquantum on Pulse Level</strong>", "Setup", "QCE 2022 Tutorial [slides]", "<strong>Setup</strong>", "Setup", "<strong>Section3_Use Torchquantum on Pulse Level</strong>", "TorchQuantum Examples", "Clifford QNN for MNIST-2 classification", "Probabilistic Gradient Pruning for Efficient QNN Training", "Probabilistic gradient pruning", "Grover\u2019s Search Algorithm", "Tutorial on Hadamard Test Based Gradient Estimation", "TorchQuantum Examples", "Simple QNN for MNIST Training", "On-chip Training of Quantum Neural Networks with parameter shift", "Apply parameters shift rules to train quantum model using TorchQuantum.", "Quantum Kernel Method", "Quantum Kernel Methods for IRIS dataset classification with TorchQuantum.", "Quantum LSTM", "Build and train a Quantum LSTM.", "Introduction to Transformer", "Quantum Transformer", "Quantum Convolution", "Quanvolution (Quantum convolution) for MNIST image classification with TorchQuantum.", "Qubit Rotation Tutorial", "TorchQuantum Qubit Rotation Tutorial", "predict_quantum_acc", "Superdense Coding", "Superdense Coding", "Train a state preparation circuit", "Simple VQE example", "TorchQuantum Examples", "apply_unitary_bmm", "apply_unitary_einsum", "ccnot", "ccx", "cnot", "cp", "crot", "crx", "cry", "crz", "cswap", "cu", "cu1", "cu2", "cu3", "cx", "cy", "cz", "echoedcrossresonance", "ecr", "gate_wrapper", "hadamard", "i", "multicnot", "multirz", "multixcnot", "p", "paulix", "pauliy", "pauliz", "phaseshift", "qubitunitary", "qubitunitaryfast", "qubitunitarystrict", "reset", "rot", "rx", "rxx", "ry", "ryy", "rz", "rzx", "rzz", "s", "shadamard", "singleexcitation", "sswap", "swap", "sx", "t", "toffoli", "u", "u1", "u2", "u3", "x", "y", "z", "zx", "zz", "layers.CXCXCXLayer", "layers.CXLayer", "layers.ClassicalInOpAll", "layers.FixedOpAll", "layers.Op1QAllLayer", "layers.Op2QAllLayer", "layers.Op2QButterflyLayer", "layers.Op2QDenseLayer", "layers.QFTLayer", "layers.QuantumModuleFromOps", "layers.RXYZCXLayer0", "layers.RandomLayer", "layers.RandomLayerAllTypes", "layers.RandomOp1All", "layers.SWAPSWAPLayer", "layers.TrainableOpAll", "layers.TwoQAll", "AllWires", "AnyWires", "operators.CNOT", "operators.CRX", "operators.CRY", "operators.CRZ", "operators.CRot", "operators.CSWAP", "operators.CU1", "operators.CU2", "operators.CU3", "operators.CY", "operators.CZ", "operators.DiagonalOperation", "operators.ECR", "operators.EchoedCrossResonance", "operators.Hadamard", "operators.I", "operators.MultiCNOT", "operators.MultiRZ", "operators.MultiXCNOT", "operators.NParamsEnum", "operators.Observable", "operators.Operation", "operators.Operator", "operators.PauliX", "operators.PauliY", "operators.PauliZ", "operators.PhaseShift", "operators.QubitUnitary", "operators.QubitUnitaryFast", "operators.RX", "operators.RXX", "operators.RY", "operators.RYY", "operators.RZ", "operators.RZX", "operators.RZZ", "operators.Reset", "operators.Rot", "operators.S", "operators.SHadamard", "operators.SSWAP", "operators.SWAP", "operators.SX", "operators.SingleExcitation", "operators.T", "operators.Toffoli", "operators.TrainableUnitary", "operators.TrainableUnitaryStrict", "operators.U1", "operators.U2", "operators.U3", "operators.WiresEnum", "\ud83d\udc4b Welcome", "Installation"], "terms": {"mit": [0, 3, 5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169, 170], "licens": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "copyright": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "c": [0, 3, 5, 7, 9, 10, 21, 26, 29, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "2020": [0, 3, 7, 10, 21, 25, 26, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "present": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "author": [0, 3, 13, 14, 15, 20, 21, 22, 23, 25, 26, 28, 29, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "permiss": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "i": [0, 3, 5, 6, 7, 9, 10, 11, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "herebi": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "grant": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "free": [0, 3, 7, 10, 19, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "charg": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "ani": [0, 3, 5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "person": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "obtain": [0, 3, 11, 15, 21, 23, 25, 26, 29, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "copi": [0, 3, 5, 7, 9, 10, 15, 17, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "thi": [0, 3, 5, 6, 7, 9, 10, 11, 14, 15, 20, 21, 22, 23, 25, 26, 28, 29, 31, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "softwar": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "associ": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "document": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "file": [0, 3, 5, 7, 9, 10, 15, 16, 21, 23, 25, 26, 29, 31, 32, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "deal": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "without": [0, 3, 7, 10, 15, 21, 28, 29, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "restrict": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "includ": [0, 3, 15, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "limit": [0, 3, 7, 10, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "right": [0, 3, 25, 26, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "us": [0, 3, 5, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 170], "modifi": [0, 3, 7, 10, 15, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "merg": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "publish": [0, 3, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "distribut": [0, 3, 7, 10, 15, 21, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "sublicens": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "sell": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "permit": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "whom": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "furnish": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "do": [0, 3, 5, 7, 9, 10, 12, 21, 29, 31, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "so": [0, 3, 7, 10, 21, 23, 25, 29, 31, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "subject": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "follow": [0, 3, 5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 28, 29, 31, 32, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "condit": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "The": [0, 3, 6, 7, 10, 11, 13, 15, 16, 17, 19, 21, 22, 23, 25, 26, 28, 29, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "abov": [0, 3, 7, 10, 29, 31, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "notic": [0, 3, 11, 31, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "shall": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "all": [0, 3, 5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "substanti": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "portion": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "THE": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "provid": [0, 3, 5, 6, 7, 9, 10, 11, 15, 16, 21, 23, 25, 26, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "AS": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "warranti": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "OF": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "kind": [0, 3, 26, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "express": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "OR": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "impli": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "BUT": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "NOT": [0, 3, 26, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "TO": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "merchant": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "fit": [0, 3, 23, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "FOR": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "A": [0, 3, 7, 10, 15, 16, 20, 23, 25, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "particular": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "purpos": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "AND": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "noninfring": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "IN": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "NO": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "event": [0, 3, 5, 9, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "holder": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "BE": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "liabl": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "claim": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "damag": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "other": [0, 3, 15, 21, 23, 25, 26, 27, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "liabil": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "whether": [0, 3, 7, 10, 15, 21, 29, 31, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "an": [0, 3, 5, 6, 7, 9, 10, 11, 15, 16, 17, 20, 21, 22, 23, 25, 26, 28, 29, 31, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "action": [0, 3, 5, 9, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "contract": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "tort": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "otherwis": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "aris": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "from": [0, 3, 5, 6, 7, 9, 10, 11, 15, 17, 21, 22, 23, 25, 26, 28, 29, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "out": [0, 3, 12, 23, 25, 29, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "connect": [0, 3, 5, 7, 9, 10, 13, 29, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "WITH": [0, 3, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "print": [5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 26, 29, 31, 34, 169], "instal": [5, 6, 7, 9, 10, 11, 15, 21, 23, 31], "git": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169, 170], "clone": [5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 26, 29, 31, 34, 169, 170], "http": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 56, 57, 169, 170], "github": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169, 170], "com": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169, 170], "han": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169, 170], "lab": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169, 170], "cd": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169, 170], "content": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 34], "pip": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169, 170], "edit": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169, 170], "dev": [5, 6, 7, 9, 10, 11, 26, 34], "null": [5, 6, 7, 9, 10, 11], "matplotlib": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "inlin": [5, 7, 9, 10, 21, 25, 29], "requir": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169], "packag": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169], "have": [5, 6, 7, 9, 10, 11, 13, 15, 21, 23, 26, 27, 28, 29, 31, 169], "been": [5, 7, 9, 10, 25], "successfulli": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "39": [5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 26, 29, 31, 32, 34], "remot": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "enumer": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34, 169], "object": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "11836": [5, 7, 9, 10], "done": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "count": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "100": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 36], "726": [5, 7, 9, 10], "compress": [5, 9, 15, 21, 23, 26, 29, 31, 34, 169], "306": [5, 7, 9, 10, 21], "total": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 34], "delta": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "435": [5, 7, 9, 10, 15], "reus": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "685": [5, 7, 9, 10], "405": [5, 7, 9, 10, 15, 21], "pack": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "11110": [5, 7, 9, 10, 26], "receiv": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "33": [5, 7, 9, 10, 15, 21, 25, 31], "59": [5, 7, 9, 10, 15, 21, 23, 25, 31, 34], "mib": [5, 7, 9, 10, 15, 21, 23, 26, 29, 31, 34], "25": [5, 7, 9, 10, 15, 21, 25, 26, 31, 34], "": [5, 6, 7, 9, 10, 11, 15, 21, 22, 23, 25, 26, 29, 30, 31, 33, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "resolv": [5, 6, 7, 9, 10, 11, 15, 21, 23, 26, 29, 31, 34], "6593": [5, 9], "error": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 32], "depend": [5, 6, 7, 9, 10, 11, 15, 21, 23, 26, 29, 31], "doe": [5, 6, 7, 9, 10, 11, 15, 21, 23, 26, 29, 34], "current": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "take": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 29, 31, 33, 34], "account": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29], "ar": [5, 6, 7, 9, 10, 11, 13, 15, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 35], "behaviour": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29], "sourc": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31], "conflict": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29], "0": [5, 6, 7, 9, 10, 11, 13, 15, 17, 21, 23, 25, 26, 29, 31, 32, 34, 169], "gt": [5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 26, 29, 31, 34], "you": [5, 6, 7, 9, 10, 11, 12, 15, 20, 21, 22, 23, 25, 26, 28, 29, 31, 37, 169], "which": [5, 6, 7, 9, 10, 11, 15, 16, 17, 21, 22, 23, 24, 25, 26, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "incompat": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29], "import": [5, 6, 7, 9, 10, 11, 17, 21, 23, 25, 26, 29, 169], "tq": [5, 6, 7, 9, 10, 11, 12, 15, 21, 22, 23, 25, 26, 28, 29, 31, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "function": [5, 6, 9, 11, 15, 17, 22, 23, 25, 26, 28, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "tqf": [5, 6, 7, 9, 10, 11, 21, 25, 26, 31, 34, 169], "numpi": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "np": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 29], "pyplot": [5, 6, 7, 9, 10, 11, 15, 21, 25, 29], "plt": [5, 6, 7, 9, 10, 11, 15, 21, 25, 29], "torch": [5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 26, 27, 29, 31, 32, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "quantumdevic": [5, 7, 9, 10, 21, 22, 23, 25, 26, 28, 29, 31, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "usag": [5, 9], "method": [5, 6, 7, 9, 10, 11, 12, 15, 18, 21, 31, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "quantum": [5, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 32, 33, 34, 37, 169], "gate": [5, 6, 9, 11, 12, 13, 21, 23, 25, 26, 29, 31, 32, 34, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "through": [5, 9, 13, 25], "16": [5, 6, 7, 9, 10, 11, 13, 15, 21, 23, 25, 26, 29, 31, 34, 169], "q_dev": [5, 9], "n_wire": [5, 7, 9, 10, 15, 17, 21, 23, 25, 26, 29, 31, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "reset_st": [5, 9, 23], "bsz": [5, 7, 9, 10, 15, 21, 23, 25, 29, 31, 34, 169], "f": [5, 6, 7, 9, 10, 11, 15, 21, 25, 26, 29, 31, 34, 169], "zero": [5, 7, 9, 10, 17, 25, 26, 29, 31, 35], "h": [5, 9, 21, 26, 33, 34, 169], "wire": [5, 7, 9, 10, 17, 21, 23, 25, 26, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "after": [5, 7, 9, 10, 11, 15, 19, 21, 23, 25, 29, 31, 34], "rx": [5, 7, 9, 10, 13, 15, 21, 23, 25, 26, 31, 169], "param": [5, 6, 9, 11, 17, 21, 23, 26, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "tensor": [5, 6, 7, 9, 10, 11, 17, 21, 25, 26, 31, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "j": [5, 7, 9, 10, 21, 33, 34], "7071": [5, 9], "6992": [5, 9], "1057j": [5, 9], "19": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "h_gate": [5, 9], "rx_gate": [5, 9], "has_param": [5, 7, 9, 10, 21, 25, 26, 31, 169], "true": [5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 26, 29, 31, 169], "init_param": [5, 9, 31, 169], "bitstr": [5, 9], "measur": [5, 7, 9, 10, 15, 21, 22, 23, 25, 26, 29, 31, 169], "n_shot": [5, 7, 9, 10, 15, 31, 34, 169], "1024": [5, 9, 31, 34, 169], "draw_id": [5, 9], "ordereddict": [5, 9, 34], "503": [5, 7, 9, 10], "521": [5, 9], "20": [5, 6, 7, 9, 10, 11, 13, 15, 21, 23, 25, 26, 29, 31, 33, 34], "quantumst": [5, 9], "epr": [5, 9], "pair": [5, 9, 33], "q_state": [5, 9], "cnot": [5, 7, 9, 10, 13, 21, 25, 26, 34, 53, 61, 169], "0000": [5, 6, 7, 9, 10, 11], "00": [5, 7, 9, 10, 11, 15, 21, 22, 23, 25, 26, 29, 31, 34], "492": [5, 9, 15, 21], "01": [5, 7, 9, 10, 11, 15, 21, 26, 34], "10": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 32, 34, 169], "11": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "532": [5, 9], "21": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "x": [5, 6, 7, 9, 10, 11, 21, 22, 23, 25, 26, 29, 31, 34, 65, 169], "6": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169], "pi": [5, 7, 9, 10, 21], "ry": [5, 7, 9, 10, 13, 15, 21, 23, 29, 31, 169], "qubitunitari": [5, 9, 169], "1j": [5, 6, 9, 11, 169], "0000j": [5, 6, 9, 11], "5878": [5, 9, 15], "8090j": [5, 9], "5237j": [5, 9], "7208": [5, 9], "2668j": [5, 9], "3673": [5, 9], "000": [5, 7, 9, 10, 21], "273": [5, 7, 9, 10, 25, 26], "001": [5, 7, 9, 10, 15, 25, 26], "415": [5, 9, 15], "010": [5, 7, 9, 10, 15], "011": [5, 9, 15, 21, 31], "101": [5, 9, 15, 25, 31], "110": [5, 7, 9, 10, 15, 25, 31], "138": [5, 9, 15, 25, 31], "111": [5, 9, 15, 25, 31], "198": [5, 7, 9, 10, 25, 31], "batch": [5, 9, 15, 23, 25, 26, 29, 31, 169], "mode": [5, 7, 9, 10, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "process": [5, 7, 9, 10, 15, 21, 24, 25, 26, 29, 169], "differ": [5, 6, 7, 9, 10, 11, 21, 22, 23, 31], "22": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 34, 169], "64": [5, 7, 9, 10, 15, 23, 25, 26, 31], "23": [5, 7, 9, 10, 15, 21, 23, 25, 29, 31, 34], "set_stat": [5, 9], "py": [5, 6, 7, 9, 10, 11, 13, 15, 16, 17, 19, 21, 23, 25, 26, 29, 30, 31, 32, 34, 35, 36, 169], "47": [5, 7, 9, 10, 15, 21, 25, 26, 31], "userwarn": [5, 7, 9, 10, 15, 17, 21, 29], "To": [5, 7, 9, 10, 17, 19, 22, 23, 24, 25, 29, 31, 34, 169, 170], "construct": [5, 9, 17, 169], "recommend": [5, 7, 9, 10, 15, 17], "sourcetensor": [5, 7, 9, 10, 17], "detach": [5, 7, 9, 10, 17, 26, 29], "requires_grad_": [5, 7, 9, 10, 17], "rather": [5, 7, 9, 10, 17], "than": [5, 7, 9, 10, 13, 15, 17, 21, 28, 29], "dtype": [5, 6, 7, 9, 10, 11, 17, 21, 25, 26], "c_dtype": [5, 9, 17], "self": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 169], "devic": [5, 6, 7, 9, 10, 11, 15, 21, 25, 26, 27, 29, 34, 169], "demonstr": [5, 9], "gpu": [5, 7, 9, 10, 15, 21, 26, 29, 169], "n_qubit": [5, 6, 9, 11, 25, 26], "8": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 32, 34, 169], "run_it": [5, 9], "use_gpu": [5, 9], "fals": [5, 7, 9, 10, 15, 17, 21, 23, 25, 26, 29, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "cuda": [5, 7, 9, 10, 15, 21, 26, 29, 31, 169], "start": [5, 6, 7, 9, 10, 11, 15, 23, 31], "time": [5, 6, 7, 9, 10, 11, 15, 26, 31, 34, 169], "enable_tim": [5, 9], "end": [5, 7, 9, 10, 21, 29, 31, 34], "record": [5, 7, 9, 10, 17, 21, 23, 31], "k": [5, 6, 7, 9, 10, 11, 16, 21, 25, 26, 29, 33, 34, 169], "rang": [5, 6, 7, 9, 10, 11, 21, 23, 25, 26, 29, 31], "qid": [5, 9], "random": [5, 7, 9, 10, 15, 29], "rand": [5, 9], "synchron": [5, 7, 9, 10], "avg": [5, 7, 9, 10], "runtim": [5, 7, 9, 10, 15, 31], "qubit": [5, 6, 7, 9, 10, 11, 13, 20, 25, 26, 29, 32, 33, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "size": [5, 7, 9, 10, 15, 16, 21, 23, 25, 26, 29, 31, 34], "elapsed_tim": [5, 9, 26], "1000": [5, 7, 9, 10, 29], "2f": [5, 7, 9, 10, 25, 26], "second": [5, 7, 9, 10, 15, 21, 25, 34], "automat": [5, 9, 20, 21, 29, 31, 169], "gradient": [5, 6, 7, 9, 10, 11, 12, 13, 18, 20, 25, 29, 35, 37, 169], "comput": [5, 7, 9, 10, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 28, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "_state": [5, 9], "requires_grad": [5, 6, 7, 9, 10, 11, 21, 26], "target_quantum_st": [5, 9], "complex64": [5, 6, 9, 11], "loss": [5, 6, 7, 9, 10, 11, 13, 15, 21, 25, 26, 29, 30, 31], "get_states_1d": [5, 9], "ab": [5, 6, 7, 9, 10, 11, 23], "backward": [5, 6, 7, 9, 10, 11, 21, 25, 26, 29, 31, 169], "grad": [5, 6, 7, 9, 10, 11, 21, 31, 169], "grad_fn": [5, 6, 9, 11, 17], "lt": [5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 26, 29, 31, 34], "unsafeviewbackward0": [5, 9], "1910": [5, 9], "rsubbackward1": [5, 9, 11], "8090": [5, 9], "5878j": [5, 9], "build": [5, 9, 15, 20, 22, 27, 28, 31, 34], "class": [5, 9, 21, 23, 25, 26, 28, 29, 31, 169], "qmodel": [5, 9], "quantummodul": [5, 7, 9, 10, 21, 23, 25, 26, 29], "def": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169], "__init__": [5, 7, 9, 10, 21, 23, 25, 26, 29, 31, 169], "super": [5, 7, 9, 10, 21, 23, 25, 26, 29, 31, 169], "u3_0": [5, 9], "u3": [5, 7, 9, 10, 15, 29, 89], "trainabl": [5, 7, 9, 10, 13, 17, 21, 25, 26, 28, 31, 169], "u3_1": [5, 9], "cu3_0": [5, 9], "cu3": [5, 7, 9, 10, 29], "cu3_1": [5, 9], "u3_2": [5, 9], "u3_3": [5, 9], "random_lay": [5, 7, 9, 10], "randomlay": [5, 7, 9, 10, 28, 29, 169], "n_op": [5, 7, 9, 10, 29], "list": [5, 7, 9, 10, 11, 15, 23, 25, 26, 29, 32, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "forward": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 169], "q_devic": [5, 7, 9, 10, 17, 21, 23, 26, 29, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "model": [5, 9, 12, 14, 15, 18, 20, 22, 23, 25, 27, 28, 31, 32, 37, 169], "1543": [5, 9], "2309j": [5, 9], "2192": [5, 9], "5838j": [5, 9], "4387": [5, 9], "5519j": [5, 9], "0495": [5, 9], "1859j": [5, 9], "easi": [5, 9, 31, 169], "convers": [5, 7, 9, 10], "qiskit": [5, 6, 7, 9, 10, 11, 12, 15, 20, 21, 23, 25, 26, 29, 31, 32, 34, 37, 56, 57], "plugin": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 34, 169], "qiskit_plugin": [5, 9], "tq2qiskit": [5, 7, 9, 10], "circ": [5, 7, 9, 10, 17], "draw": [5, 6, 7, 9, 10, 11], "mpl": [5, 7, 9, 10], "pennylan": [5, 9, 25, 26, 30, 31], "look": [5, 6, 7, 9, 10, 11, 23, 29, 31, 34], "index": [5, 6, 7, 9, 10, 11, 25, 31, 32, 34], "pypi": [5, 6, 7, 9, 10, 11, 34], "org": [5, 6, 7, 9, 10, 11, 34, 56, 57, 169], "simpl": [5, 6, 7, 9, 10, 11, 20, 29, 31, 32, 34, 169], "u": [5, 6, 7, 9, 10, 11, 12, 15, 21, 23, 34, 37, 169], "python": [5, 6, 7, 9, 10, 11, 13, 15, 19, 21, 23, 25, 26, 29, 31, 32, 34, 35, 36, 169], "pkg": [5, 6, 7, 9, 10, 11, 34], "colab": [5, 6, 7, 9, 10, 11, 14, 15, 20, 21, 22, 23, 28, 29, 31, 34], "wheel": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "public": [5, 6, 7, 9, 10, 11, 34], "collect": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "download": [5, 7, 9, 10, 15, 21, 23, 29, 31, 34], "py3": [5, 6, 9, 11, 15, 21, 23, 29, 31, 34], "none": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "whl": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 34], "mb": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 34], "35": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31], "alreadi": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "satisfi": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "appdir": [5, 9], "usr": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 34], "local": [5, 6, 7, 9, 10, 11, 15, 21, 23, 26, 29, 31, 34], "lib": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "python3": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 30, 31, 34], "7": [5, 6, 7, 9, 10, 11, 15, 17, 21, 23, 25, 26, 29, 31, 34, 169], "dist": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 34], "autograd": [5, 9, 26, 169], "scipi": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "cachetool": [5, 7, 9, 10, 21, 23, 25, 26, 29, 31, 34], "toml": [5, 7, 9, 10, 21, 23, 25, 26, 29, 31, 34], "networkx": [5, 9, 31, 34], "lightn": [5, 9], "pennylane_lightn": [5, 9], "cp37": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31], "cp37m": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29], "manylinux_2_17_x86_64": [5, 6, 9, 11, 15, 21, 23, 29, 31, 34], "manylinux2014_x86_64": [5, 6, 9, 11, 15, 21, 23, 29, 31, 34], "13": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 32, 33, 34], "29": [5, 7, 9, 10, 15, 21, 23, 25, 29, 31, 34], "semant": [5, 9], "version": [5, 7, 9, 10, 15, 31, 34], "semantic_vers": [5, 9], "py2": [5, 9, 15, 21, 23, 29, 31, 34], "15": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "kb": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 34], "autorai": [5, 9], "36": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31], "retworkx": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "ninja": [5, 9], "manylinux_2_5_x86_64": [5, 7, 9, 10, 15, 21, 23, 29, 31, 34], "manylinux1_x86_64": [5, 6, 7, 9, 10, 11, 15, 21, 23, 29, 31, 34], "108": [5, 9, 25, 31], "68": [5, 7, 9, 10, 15, 25, 29, 31], "futur": [5, 7, 9, 10, 15], "12": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "speed": [5, 9, 16], "comparison": [5, 9, 29], "qml": [5, 9, 169], "18": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 29, 31, 34], "32": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31], "default": [5, 6, 7, 9, 10, 11, 15, 25, 26, 31, 32, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "qnode": [5, 9], "interfac": [5, 9], "pennylane_circ": [5, 9], "rot": [5, 9], "ctrl": [5, 9], "control": [5, 9, 34, 169], "9": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169], "14": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 34, 169], "17": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "return": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "els": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31], "cpu": [5, 7, 9, 10, 21, 29, 31, 34, 169], "rep": [5, 6, 9, 11], "_": [5, 7, 9, 10, 21, 25, 26, 29, 32], "pennylane_tim": [5, 9], "infer": [5, 7, 9, 10, 15, 20, 21, 29, 169], "3734148144721985": [5, 9], "definit": [5, 9, 31], "tq_circ": [5, 9], "tq_time": [5, 9], "faster": [5, 6, 9, 11, 29, 169], "004048892259597778": [5, 9], "92": [5, 9, 15, 25, 29, 31, 34], "22641417218001": [5, 9], "26": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 34], "puls": [5, 9, 169], "quantumpulsedirect": [5, 6, 9, 11], "n_step": [5, 6, 7, 9, 10, 11, 21], "hamil": [5, 6, 9, 11], "get_unitari": [5, 6, 9, 11], "6536": [5, 9], "7568j": [5, 9], "mmbackward0": [5, 6, 9, 11], "28": [5, 6, 7, 9, 10, 11, 15, 21, 25, 26, 29, 31, 169], "theta": [5, 6, 9, 11, 21, 31], "target_unitari": [5, 6, 9, 11], "co": [5, 6, 9, 11, 21, 26, 31], "sin": [5, 6, 9, 11, 21, 26, 31], "trace": [5, 6, 9, 11], "shape": [5, 6, 7, 9, 10, 11, 21, 23, 25, 29, 169], "pulse_shap": [5, 6, 9, 11], "4441": [5, 9], "optim": [5, 7, 9, 10, 15, 21, 22, 23, 25, 26, 29, 169], "argpars": [5, 6, 7, 9, 10, 11, 15, 26, 34], "lr_schedul": [5, 7, 9, 10, 15, 21, 29], "cosineannealinglr": [5, 7, 9, 10, 15, 21, 29], "train": [5, 6, 9, 11, 12, 15, 18, 22, 23, 27, 28, 31, 32, 37, 169], "target_st": [5, 9], "result_st": [5, 9], "infidel": [5, 9], "dot": [5, 9], "zero_grad": [5, 6, 7, 9, 10, 11, 21, 25, 26, 29, 31], "step": [5, 6, 7, 9, 10, 11, 15, 21, 25, 26, 31], "item": [5, 6, 7, 9, 10, 11, 21, 25, 26, 29, 31], "n": [5, 7, 9, 10, 15, 21, 26], "target": [5, 6, 7, 9, 10, 11, 21, 25, 29, 31, 34], "result": [5, 7, 9, 10, 13, 15, 21, 23, 26, 29, 31, 34], "main": [5, 7, 9, 10, 31], "n_epoch": [5, 7, 9, 10, 15, 21, 25, 26, 29, 31], "3000": [5, 7, 9, 10, 21], "seed": [5, 7, 9, 10, 15, 29, 31], "42": [5, 7, 9, 10, 15, 21, 25, 29, 31], "manual_se": [5, 7, 9, 10, 15, 29, 31], "use_cuda": [5, 7, 9, 10, 21, 29, 31], "is_avail": [5, 7, 9, 10, 21, 29, 31], "adam": [5, 6, 7, 9, 10, 11, 15, 21, 26, 29], "paramet": [5, 6, 7, 9, 10, 11, 12, 15, 18, 23, 25, 26, 27, 29, 31, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "lr": [5, 6, 7, 9, 10, 11, 15, 21, 25, 26, 29, 31], "1e": [5, 7, 9, 10, 21, 29], "weight_decai": [5, 7, 9, 10, 15, 21, 29], "schedul": [5, 6, 7, 9, 10, 11, 15, 21, 29], "t_max": [5, 7, 9, 10, 15, 21, 29], "epoch": [5, 7, 9, 10, 13, 15, 19, 21, 25, 26, 29, 30, 31, 36], "param_group": [5, 7, 9, 10, 21, 29], "wget": [5, 7, 9, 10], "www": [5, 7, 9, 10], "dropbox": [5, 7, 9, 10], "1rtttfxoo02s09": [5, 9], "h2_new": [5, 9], "txt": [5, 9, 36], "2022": [5, 6, 7, 9, 10, 11, 15, 21, 24, 25, 26, 29, 34, 169], "09": [5, 7, 9, 10, 15, 21], "162": [5, 7, 9, 10, 15, 21, 25, 31, 34], "125": [5, 7, 9, 10, 25, 31], "65": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 34], "2620": [5, 7, 9, 10], "6017": [5, 9], "a27d": [5, 7, 9, 10], "212": [5, 9, 15, 25], "443": [5, 7, 9, 10], "request": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "sent": [5, 7, 9, 10, 25, 34], "await": [5, 7, 9, 10], "respons": [5, 7, 9, 10], "302": [5, 7, 9, 10, 25], "found": [5, 6, 7, 9, 10, 11, 15, 16, 21, 22, 23, 25, 26, 29], "locat": [5, 7, 9, 10], "raw": [5, 7, 9, 10, 15, 21, 29, 32], "exist": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29], "ucfcd04121af2228bb42634017f1": [5, 9], "dl": [5, 7, 9, 10], "dropboxusercont": [5, 7, 9, 10], "btnq0j4qw_p3ndqdfhmscfqmtf5umizmfhmybbzezdmfqxvt": [5, 9], "6xxj8l4v68idx990zbzggjfv_datohocphy7hqn47vgl7wu3mzikkumskckzel": [5, 9], "c8mspgrwrgbblvst8keznexc4dk4dfyqqym9yojytb_h_hbasmwsn9xn": [5, 9], "vsgg": [5, 9], "20f": [5, 9], "200": [5, 7, 9, 10, 15, 25, 31], "ok": [5, 7, 9, 10], "length": [5, 7, 9, 10], "139": [5, 9, 15, 25, 26, 31], "text": [5, 9, 21, 26], "plain": [5, 7, 9, 10], "save": [5, 7, 9, 10, 11, 12, 15, 26, 29, 31, 37, 169], "nn": [5, 6, 7, 9, 10, 11, 15, 21, 25, 26, 29, 31, 34, 169], "vqe_util": [5, 9], "parse_hamiltonian_fil": [5, 9], "dataset": [5, 9, 15, 18, 21, 25, 26], "constantlr": [5, 9], "qvqemodel": [5, 9], "arch": [5, 7, 9, 10, 15, 21, 29], "hamil_info": [5, 9], "n_block": [5, 7, 9, 10, 15, 21, 29, 36], "u3_lay": [5, 9], "quantummodulelist": [5, 9], "cu3_lay": [5, 9], "append": [5, 6, 7, 9, 10, 11, 15, 21, 25, 29], "op1qalllay": [5, 7, 9, 10], "op": [5, 7, 9, 10, 169], "op2qalllay": [5, 7, 9, 10], "circular": [5, 7, 9, 10], "measuremultipletim": [5, 9], "obs_list": [5, 9], "hamil_list": [5, 9], "hamil_coeffici": [5, 9], "coeffici": [5, 9], "doubl": [5, 7, 9, 10, 29], "observ": [5, 6, 9, 11, 15, 17, 21, 31, 169], "zip": [5, 9], "cumprod": [5, 9], "dim": [5, 7, 9, 10, 21, 25, 26, 29, 169], "unsqueez": [5, 9, 25, 26], "dataflow": [5, 7, 9, 10, 15, 21, 29], "output": [5, 7, 9, 10, 15, 21, 22, 23, 24, 25, 26, 29, 31], "mean": [5, 7, 9, 10, 23, 25, 26, 29], "expect": [5, 7, 9, 10, 19, 21, 25, 26, 29, 30, 31, 169], "energi": [5, 6, 9, 11], "valid_test": [5, 7, 9, 10, 21, 29], "split": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31], "no_grad": [5, 7, 9, 10, 21, 25, 26, 29], "arg": [5, 7, 9, 10, 26], "pass": [5, 7, 9, 10, 23, 25, 26, 29], "parser": [5, 9, 26], "argumentpars": [5, 9, 26], "add_argu": [5, 9, 26], "pdb": [5, 6, 7, 9, 10, 11, 15], "store_tru": [5, 9], "help": [5, 6, 9, 11, 23], "debug": [5, 7, 9, 10, 15, 169], "type": [5, 6, 7, 9, 10, 11, 15, 17, 21, 22, 23, 25, 26, 29, 31, 32, 34, 38, 39, 49], "int": [5, 6, 7, 9, 10, 11, 26, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "number": [5, 6, 7, 9, 10, 11, 15, 17, 21, 26, 29, 31, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "block": [5, 7, 9, 10, 13, 25, 26, 29], "each": [5, 7, 9, 10, 13, 15, 20, 21, 23, 24, 25, 26, 29, 31, 32], "contain": [5, 6, 7, 9, 10, 11, 13, 21, 23, 25, 26, 29, 32], "one": [5, 7, 9, 10, 21, 23, 25, 29, 31, 33, 34], "layer": [5, 7, 9, 10, 21, 24, 25, 28, 29, 32, 169], "ring": [5, 9, 13], "steps_per_epoch": [5, 9, 36], "hamil_filenam": [5, 9, 36], "str": [5, 7, 9, 10, 15, 26, 58, 59], "set_trac": [5, 7, 9, 10], "dict": [5, 7, 9, 10, 15, 21, 23, 29, 32], "sampler": [5, 7, 9, 10, 15, 21, 29], "util": [5, 7, 9, 10, 15, 21, 26, 29, 31, 34], "data": [5, 6, 7, 9, 10, 11, 15, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 34, 169], "randomsampl": [5, 7, 9, 10, 15, 21, 29], "sequentialsampl": [5, 9], "dataload": [5, 7, 9, 10, 15, 21, 29], "batch_siz": [5, 7, 9, 10, 15, 21, 25, 26, 29], "num_work": [5, 7, 9, 10, 15, 21, 29], "pin_memori": [5, 7, 9, 10, 15, 21, 29], "5e": [5, 6, 7, 9, 10, 11, 21, 29], "valid": [5, 7, 9, 10, 15, 21, 29], "final": [5, 6, 7, 9, 10, 11, 25, 26, 29, 31, 34], "005": [5, 9, 15, 21, 29], "308297323072801": [5, 9], "3150710661499416": [5, 9], "3222581990990716": [5, 9], "3298538992153188": [5, 9], "3378549958850836": [5, 9], "3462580818360128": [5, 9], "35506080617605584": [5, 9], "3642611309815864": [5, 9], "37385944604789345": [5, 9], "3838581631128637": [5, 9], "39426284856410665": [5, 9], "40508255287436734": [5, 9], "41632968098560474": [5, 9], "4280217907429371": [5, 9], "4401789326278298": [5, 9], "4528248988932262": [5, 9], "4659814090349086": [5, 9], "4796671753594215": [5, 9], "49389354536284613": [5, 9], "5086673454400741": [5, 9], "5239896705033897": [5, 9], "5398575345128833": [5, 9], "5562654188755087": [5, 9], "5732025354929666": [5, 9], "5906582814303059": [5, 9], "6086202753284728": [5, 9], "6270759125807044": [5, 9], "6460131499584596": [5, 9], "6654197248861027": [5, 9], "6852816790901917": [5, 9], "7055832865251654": [5, 9], "726304925766776": [5, 9], "7474252975601621": [5, 9], "7689180912762086": [5, 9], "7907567045661701": [5, 9], "8129120128083609": [5, 9], "835353362605799": [5, 9], "8580469167888662": [5, 9], "880957539042001": [5, 9], "904049305753527": [5, 9], "9272828409789278": [5, 9], "9506195169472338": [5, 9], "9740194497956998": [5, 9], "997441343767171": [5, 9], "02084374128577": [5, 9], "044184479376973": [5, 9], "0674212651913764": [5, 9], "0905136089809482": [5, 9], "1134209261619075": [5, 9], "1361055443887715": [5, 9], "1585309511002313": [5, 9], "180663069118116": [5, 9], "2024708840223917": [5, 9], "2239266828663689": [5, 9], "2450046695668322": [5, 9], "2656832661683326": [5, 9], "2859423163229518": [5, 9], "305764713513226": [5, 9], "3251346780127407": [5, 9], "3440385075139858": [5, 9], "3624633073585322": [5, 9], "3803982401215706": [5, 9], "3978330414034656": [5, 9], "4147587108826005": [5, 9], "4311684817015302": [5, 9], "4470565159801254": [5, 9], "4624191672379407": [5, 9], "4772557899128564": [5, 9], "491566312061463": [5, 9], "5053538021332036": [5, 9], "518623216448085": [5, 9], "5313816111045064": [5, 9], "543637582764402": [5, 9], "5554010688327917": [5, 9], "566683542253599": [5, 9], "577497960326701": [5, 9], "58785648515607": [5, 9], "5977735926623289": [5, 9], "6072629639575209": [5, 9], "6163387675503167": [5, 9], "6250154649982833": [5, 9], "6333083096243592": [5, 9], "641231861539749": [5, 9], "6488010623233564": [5, 9], "6560317510167233": [5, 9], "6629380850645679": [5, 9], "6695359678676125": [5, 9], "6758402260292533": [5, 9], "6818649964748809": [5, 9], "6876251155377096": [5, 9], "6931347620651545": [5, 9], "6984065362320644": [5, 9], "7034537412957578": [5, 9], "7082888786232986": [5, 9], "712923466852262": [5, 9], "7173688625873273": [5, 9], "721636092546762": [5, 9], "7257351333265731": [5, 9], "7296762987476333": [5, 9], "7334682116242563": [5, 9], "7371199700047164": [5, 9], "0049987664009143295": [5, 9], "7406386912828493": [5, 9], "7440335320517497": [5, 9], "7473111102056609": [5, 9], "7504782222782216": [5, 9], "7535412787390154": [5, 9], "7565058968835403": [5, 9], "759377074174433": [5, 9], "7621601697925975": [5, 9], "7648592241832979": [5, 9], "767479029402394": [5, 9], "7700228962512232": [5, 9], "7724949221862025": [5, 9], "7748978987552877": [5, 9], "7772350746150434": [5, 9], "7795094983733064": [5, 9], "7817232498377027": [5, 9], "7838785571014317": [5, 9], "7859782904080883": [5, 9], "7880235033033915": [5, 9], "7900170050286142": [5, 9], "7919597975826154": [5, 9], "7938537272504917": [5, 9], "7957003241548335": [5, 9], "797500955558857": [5, 9], "7992573516104649": [5, 9], "8009698268775123": [5, 9], "8026405103866445": [5, 9], "804269877594594": [5, 9], "8058594881338932": [5, 9], "8074098600566129": [5, 9], "8089226514277743": [5, 9], "810398198739981": [5, 9], "8118380108759542": [5, 9], "8132425321819088": [5, 9], "814613142876332": [5, 9], "8159501233090745": [5, 9], "8172551329175004": [5, 9], "81852813868538": [5, 9], "8197706051011815": [5, 9], "8209829790204506": [5, 9], "822166207271819": [5, 9], "823321290024784": [5, 9], "8244487293863783": [5, 9], "825549328783198": [5, 9], "826623644407344": [5, 9], "827672846005034": [5, 9], "8286970344156346": [5, 9], "8296970745633039": [5, 9], "8306736130123746": [5, 9], "8316279059184533": [5, 9], "8325600031308331": [5, 9], "8334701107569": [5, 9], "8343597108248098": [5, 9], "835228860710742": [5, 9], "8360780770628609": [5, 9], "8369080639366242": [5, 9], "8377194101268466": [5, 9], "8385121571643477": [5, 9], "839287746366928": [5, 9], "8400452195649581": [5, 9], "8407862108857265": [5, 9], "8415108212650382": [5, 9], "8422191268123873": [5, 9], "842912218641005": [5, 9], "843589837129386": [5, 9], "8442525461550558": [5, 9], "8449012251925572": [5, 9], "8455352366198263": [5, 9], "8461557895161853": [5, 9], "8467627958509403": [5, 9], "8473564416067503": [5, 9], "8479375633844264": [5, 9], "8485057965199916": [5, 9], "8490621453479181": [5, 9], "8496065068888792": [5, 9], "8501391349165532": [5, 9], "850660377615957": [5, 9], "8511703488993607": [5, 9], "8516692967983088": [5, 9], "8521575221191722": [5, 9], "852635510121204": [5, 9], "8531035138774734": [5, 9], "8535609310452": [5, 9], "8540091911125138": [5, 9], "854447580289549": [5, 9], "8548766488154402": [5, 9], "8552966706316276": [5, 9], "8557072927267524": [5, 9], "8561093597275444": [5, 9], "8565031928483973": [5, 9], "8568882184730278": [5, 9], "8572652794722904": [5, 9], "8576336223059016": [5, 9], "857994803989237": [5, 9], "8583482620165608": [5, 9], "8586940939268743": [5, 9], "8590323445415504": [5, 9], "8593632780779858": [5, 9], "8596873680752544": [5, 9], "8600042583654561": [5, 9], "00499506682107068": [5, 9], "8603142172677518": [5, 9], "860617707234636": [5, 9], "8609146078146557": [5, 9], "8612047972227": [5, 9], "861489111623201": [5, 9], "8617669604698208": [5, 9], "8620390353977796": [5, 9], "8623051691146995": [5, 9], "862565688347211": [5, 9], "8628202542502552": [5, 9], "8630695684233585": [5, 9], "8633132516951922": [5, 9], "8635518523975556": [5, 9], "8637851993068324": [5, 9], "8640135702935257": [5, 9], "8642365658098885": [5, 9], "8644549037971103": [5, 9], "8646687229796104": [5, 9], "864877684421353": [5, 9], "8650817248095304": [5, 9], "8652815026994112": [5, 9], "8654769467233923": [5, 9], "8656678268330742": [5, 9], "8658546957856224": [5, 9], "8660376180907576": [5, 9], "866216213133451": [5, 9], "866390751170692": [5, 9], "8665617093688085": [5, 9], "86672876160534": [5, 9], "8668919349778421": [5, 9], "8670513010336973": [5, 9], "8672075259416876": [5, 9], "8673598074301596": [5, 9], "867508964918732": [5, 9], "8676544929727523": [5, 9], "8677965953155866": [5, 9], "8679359598789396": [5, 9], "8680717979680017": [5, 9], "8682042940612478": [5, 9], "8683345937557774": [5, 9], "8684613316493213": [5, 9], "8685852106391083": [5, 9], "868706061337477": [5, 9], "8688243485956573": [5, 9], "8689398058035107": [5, 9], "8690525834900675": [5, 9], "8691624684803183": [5, 9], "869270188715714": [5, 9], "869375385808313": [5, 9], "8694779908720567": [5, 9], "8695781291362437": [5, 9], "8696761419427235": [5, 9], "8697714187081478": [5, 9], "8698645602351573": [5, 9], "8699556702287476": [5, 9], "8700443964500817": [5, 9], "8701308651455928": [5, 9], "8702161275244586": [5, 9], "870298457945267": [5, 9], "8703787897589728": [5, 9], "8704577178424848": [5, 9], "8705343695584336": [5, 9], "870609235947981": [5, 9], "8706823050632249": [5, 9], "8707531503177026": [5, 9], "8708231370286865": [5, 9], "870890831030976": [5, 9], "8709570938094435": [5, 9], "8710214026011474": [5, 9], "8710843600539504": [5, 9], "keyboardinterrupt": [5, 7, 9, 10], "traceback": [5, 7, 9, 10], "most": [5, 7, 9, 10, 24, 25], "recent": [5, 7, 9, 10, 27], "call": [5, 7, 9, 10, 20, 21, 22, 23, 25, 26, 29, 31], "last": [5, 7, 9, 10, 15, 29], "ipython": [5, 7, 9, 10], "input": [5, 9, 21, 24, 25, 26, 28, 29], "263240bbee7": [5, 7, 9, 10], "modul": [5, 7, 9, 10, 21, 23, 25, 26, 29, 31, 169], "ee35acbb01d2": [5, 9], "67": [5, 7, 9, 10, 15, 25, 31, 34], "34": [5, 7, 9, 10, 15, 21, 23, 25, 29, 31, 34], "69": [5, 7, 9, 10, 15, 21, 23, 25, 29, 31, 33, 34], "70": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 33, 34], "71": [5, 7, 9, 10, 15, 25, 31], "8bc26e701b2": [5, 9], "57": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 29, 31], "58": [5, 7, 9, 10, 15, 21, 23, 25, 29, 31, 34], "60": [5, 7, 9, 10, 15, 23, 25, 26, 29, 31, 34], "61": [5, 7, 9, 10, 15, 25, 31], "_tensor": [5, 9], "retain_graph": [5, 9, 26], "create_graph": [5, 9], "394": [5, 9, 15, 25], "395": [5, 9, 15], "396": [5, 9], "397": [5, 9, 15, 21, 25], "398": [5, 9, 21], "register_hook": [5, 9], "hook": [5, 7, 9, 10, 169], "grad_tensor": [5, 9], "grad_vari": [5, 9], "173": [5, 7, 9, 10, 15, 25, 31], "variabl": [5, 7, 9, 10, 26, 31], "_execution_engin": [5, 9], "run_backward": [5, 9], "engin": [5, 9], "run": [5, 6, 7, 9, 10, 11, 14, 15, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32, 34, 169], "174": [5, 9, 15, 25, 31], "grad_tensors_": [5, 9], "175": [5, 9, 25, 31], "allow_unreach": [5, 9], "accumulate_grad": [5, 9], "176": [5, 7, 9, 10, 15, 25, 31], "177": [5, 7, 9, 10, 25, 31], "tq2qiskit_expand_param": [5, 9], "tq2qiskit_measur": [5, 9], "qiskit_assemble_circ": [5, 9], "mnist": [5, 7, 9, 10, 12, 15, 18, 21, 37], "49": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 34], "qfcmodel": [5, 7, 9, 10, 21, 169], "qlayer": [5, 7, 9, 10, 26], "50": [5, 7, 9, 10, 15, 21, 25, 26, 31], "rx0": [5, 7, 9, 10, 25, 26, 31, 169], "ry0": [5, 7, 9, 10, 31, 169], "rz0": [5, 7, 9, 10, 169], "rz": [5, 7, 9, 10, 13, 15, 21, 23, 62, 169], "crx0": [5, 7, 9, 10, 169], "crx": [5, 7, 9, 10, 169], "static_support": [5, 7, 9, 10, 23], "convert": [5, 7, 9, 10, 12, 24, 25, 26, 37, 169], "static": [5, 7, 9, 10, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "need": [5, 7, 9, 10, 17, 21, 23, 25, 26, 29, 31, 34, 169], "add": [5, 6, 7, 9, 10, 11, 21, 22, 23, 26, 31, 36, 169], "befor": [5, 7, 9, 10, 11, 15, 21, 24, 25, 29, 31], "make": [5, 7, 9, 10, 26, 29, 31], "sure": [5, 9], "static_mod": [5, 7, 9, 10], "parent_graph": [5, 7, 9, 10, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "graph": [5, 7, 9, 10, 20, 21, 31, 169], "hadamard": [5, 7, 9, 10, 34], "below": [5, 6, 7, 9, 10, 11, 21, 25], "some": [5, 6, 7, 9, 10, 11, 15, 27, 31, 169], "instanti": [5, 7, 9, 10, 31, 169], "ahead": [5, 7, 9, 10, 31, 169], "more": [5, 7, 9, 10, 12, 13, 15, 21, 23, 28, 29, 36, 37, 169], "non": [5, 7, 9, 10, 13, 22, 23, 169], "parameter": [5, 7, 9, 10, 15, 21, 169], "fly": [5, 7, 9, 10, 169], "sx": [5, 7, 9, 10, 21, 169], "encod": [5, 7, 9, 10, 12, 13, 21, 25, 26, 29, 37, 169], "generalencod": [5, 7, 9, 10, 21, 25, 26, 28, 29], "encoder_op_list_name_dict": [5, 7, 9, 10, 21, 29], "4x4_ryzxi": [5, 7, 9, 10, 15, 21, 29], "q_layer": [5, 7, 9, 10, 21, 26, 29], "measureal": [5, 7, 9, 10, 21, 25, 26, 28, 29, 169], "pauliz": [5, 7, 9, 10, 21, 25, 26, 28, 29, 169], "use_qiskit": [5, 7, 9, 10, 15, 21, 23, 29], "avg_pool2d": [5, 7, 9, 10, 21, 29, 169], "view": [5, 7, 9, 10, 21, 23, 25, 26, 29, 169], "devi": [5, 9], "encoder_circ": [5, 9], "func_list": [5, 7, 9, 10, 23], "q_layer_circ": [5, 9], "measurement_circ": [5, 9], "assembled_circ": [5, 9], "x0": [5, 9], "qiskit_processor": [5, 7, 9, 10, 15, 21, 29], "process_ready_circ": [5, 9], "x1": [5, 9], "process_parameter": [5, 7, 9, 10, 21, 29], "max": [5, 7, 9, 10, 15, 21, 25, 29], "reshap": [5, 7, 9, 10, 21, 23, 29, 169], "sum": [5, 6, 7, 9, 10, 11, 15, 21, 25, 26, 29, 169], "squeez": [5, 7, 9, 10, 21, 26, 169], "log_softmax": [5, 7, 9, 10, 21, 25, 26, 29, 169], "feed_dict": [5, 7, 9, 10, 21, 29], "imag": [5, 7, 9, 10, 15, 18, 21, 169], "digit": [5, 7, 9, 10, 15, 21, 29], "nll_loss": [5, 7, 9, 10, 15, 21, 26, 29], "r": [5, 7, 9, 10, 15, 21, 29, 33, 34, 169], "target_al": [5, 7, 9, 10, 21, 29], "output_al": [5, 7, 9, 10, 21, 29], "cat": [5, 7, 9, 10, 21, 25, 29], "indic": [5, 7, 9, 10, 21, 25, 27, 29], "topk": [5, 7, 9, 10, 21, 29], "mask": [5, 9, 21, 26, 29], "eq": [5, 7, 9, 10, 21, 29], "expand_a": [5, 7, 9, 10, 21, 29], "correct": [5, 7, 9, 10, 21, 25, 26, 29], "accuraci": [5, 6, 7, 9, 10, 11, 13, 19, 21, 23, 25, 26, 29], "set": [5, 6, 7, 9, 10, 11, 15, 19, 21, 22, 23, 29, 31, 32, 34], "52": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 34], "per": [5, 9, 26], "parse_arg": [5, 9, 26], "root": [5, 7, 9, 10, 15, 21, 23, 29, 31, 34], "mnist_data": [5, 7, 9, 10, 15, 21, 29], "train_valid_split_ratio": [5, 7, 9, 10, 15, 21, 29], "digits_of_interest": [5, 7, 9, 10, 15, 21, 29], "n_test_sampl": [5, 7, 9, 10, 15, 21, 29], "75": [5, 7, 9, 10, 15, 25, 31], "256": [5, 7, 9, 10, 15, 21, 25], "test": [5, 9, 13, 15, 19, 21, 26, 29], "simul": [5, 6, 7, 9, 10, 11, 13, 22, 23, 25, 29, 31, 169], "real": [5, 6, 7, 9, 10, 11, 15, 21, 28, 31, 169], "try": [5, 6, 7, 9, 10, 11, 29], "ibmq": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34, 169], "qiskitprocessor": [5, 7, 9, 10, 15, 21, 29], "firstli": [5, 7, 9, 10, 21, 29], "perform": [5, 6, 7, 9, 10, 11, 22, 23, 25, 26, 28, 29, 31, 32, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "ntest": [5, 7, 9, 10, 29], "processor_simul": [5, 7, 9, 10, 29], "use_real_qc": [5, 7, 9, 10, 15, 21, 29], "set_qiskit_processor": [5, 7, 9, 10, 15, 21, 29], "qc": [5, 7, 9, 10, 29], "backend_nam": [5, 7, 9, 10, 15, 21, 29], "ibmq_lima": [5, 9], "pleas": [5, 6, 7, 9, 10, 11, 12, 15, 21, 29, 32, 37, 169], "specifi": [5, 7, 9, 10, 23, 31], "your": [5, 7, 9, 10, 15, 21, 23, 29, 31], "own": [5, 7, 9, 10, 15, 21, 23, 29], "hub": [5, 7, 9, 10], "group": [5, 7, 9, 10], "project": [5, 7, 9, 10, 26, 169], "premium": [5, 9], "plan": [5, 9], "access": [5, 7, 9, 10, 21, 29], "machin": [5, 6, 9, 11, 15, 21, 22, 23, 25, 26, 27, 29, 31, 169], "processor_real_qc": [5, 7, 9, 10, 21, 29], "ibm": [5, 9, 25, 29, 169], "q": [5, 7, 9, 10, 21, 26, 29], "open": [5, 7, 9, 10, 15], "except": [5, 7, 9, 10, 29], "importerror": [5, 9, 29], "creat": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 34, 169], "experi": [5, 9, 15, 29], "token": [5, 9, 15, 21, 23, 25, 26, 29], "accord": [5, 7, 9, 10, 15, 29], "instruct": [5, 9, 29], "again": [5, 9, 29, 31], "53": [5, 7, 9, 10, 15, 21, 23, 25, 29, 31], "05": [5, 7, 9, 10, 11, 15, 21, 26, 29, 31], "24": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 26, 29, 31], "683": [5, 9, 15], "onli": [5, 6, 7, 9, 10, 11, 15, 21, 23, 25, 29, 31, 32, 33, 34, 169], "front": [5, 7, 9, 10, 15, 21, 23, 29], "700414937759336": [5, 9], "6310521364212036": [5, 9], "c815ef425ce3": [5, 9], "51": [5, 7, 9, 10, 15, 21, 25, 31], "7f3a43b36b13": [5, 9], "91": [5, 9, 15, 25, 31], "93": [5, 7, 9, 10, 15, 25, 31], "94": [5, 7, 9, 10, 15, 25, 31], "95": [5, 7, 9, 10, 15, 25, 31], "_call_impl": [5, 7, 9, 10], "kwarg": [5, 7, 9, 10], "1128": [5, 7, 9, 10], "_backward_hook": [5, 7, 9, 10], "_forward_hook": [5, 7, 9, 10], "_forward_pre_hook": [5, 7, 9, 10], "_global_backward_hook": [5, 7, 9, 10], "1129": [5, 7, 9, 10], "_global_forward_hook": [5, 7, 9, 10], "_global_forward_pre_hook": [5, 7, 9, 10], "1130": [5, 7, 9, 10], "forward_cal": [5, 7, 9, 10], "1131": [5, 7, 9, 10], "when": [5, 7, 9, 10, 11, 21, 23, 29, 31], "jit": [5, 7, 9, 10], "1132": [5, 7, 9, 10], "full_backward_hook": [5, 7, 9, 10], "non_full_backward_hook": [5, 7, 9, 10], "76": [5, 7, 9, 10, 15, 25, 31, 34], "77": [5, 7, 9, 10, 15, 25, 31], "78": [5, 7, 9, 10, 15, 21, 23, 25, 29, 31], "79": [5, 9, 25, 31, 34], "80": [5, 7, 9, 10, 25, 31], "forward_register_graph": [5, 9], "add_op": [5, 9], "re": [5, 7, 9, 10], "is_graph_top": [5, 9], "27": [5, 7, 9, 10, 15, 21, 23, 25, 26, 29, 31, 34], "finish": [5, 7, 9, 10, 15, 25], "flag": [5, 7, 9, 10], "72": [5, 7, 9, 10, 15, 25, 31], "73": [5, 7, 9, 10, 15, 25, 29, 31], "invers": [5, 9, 17, 23, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "comp_method": [5, 9, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "1685": [5, 9], "1686": [5, 9], "1687": [5, 9], "1688": [5, 9], "1689": [5, 9], "gate_wrapp": [5, 9], "name": [5, 7, 9, 10, 15, 17, 23, 31, 36, 58], "mat": [5, 9, 26, 38, 39, 58], "260": [5, 9, 25], "qubitunitaryfast": [5, 9], "261": [5, 7, 9, 10, 15, 21, 25], "qubitunitarystrict": [5, 9], "262": [5, 9, 25], "matrix": [5, 6, 9, 11, 21, 23, 26, 31, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "263": [5, 9, 15, 25], "elif": [5, 7, 9, 10, 15], "multicnot": [5, 9], "multixcnot": [5, 9], "264": [5, 9, 15, 25], "can": [5, 6, 7, 9, 10, 11, 15, 16, 20, 21, 22, 23, 25, 26, 28, 29, 31, 34, 35, 169], "appli": [5, 7, 9, 10, 17, 18, 26, 28, 29, 31, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "arbitrari": [5, 9, 25, 26, 35], "ry_matrix": [5, 9], "354": [5, 7, 9, 10, 15, 21], "355": [5, 7, 9, 10, 15], "356": [5, 9, 15, 25], "357": [5, 9, 15], "si": [5, 9], "358": [5, 9], "fatal": [6, 11, 25], "destin": [6, 11, 25], "path": [6, 7, 10, 11, 15, 25], "empti": [6, 11, 25], "directori": [6, 7, 10, 11, 15, 21, 23, 25, 29, 31, 34], "natur": [6, 11, 25, 26], "4": [6, 10, 11, 13, 15, 17, 21, 23, 25, 26, 29, 31, 32, 169], "terra": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "3": [6, 15, 17, 21, 23, 25, 26, 27, 29, 31, 32, 36, 169], "qiskit_natur": [6, 11], "extens": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "cach": [6, 7, 10, 11, 15, 21, 23, 29, 31, 34], "qiskit_terra": [6, 11, 15, 21, 23, 29, 31, 34], "scikit": [6, 11, 15, 21, 23, 29], "setuptool": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "40": [6, 7, 10, 11, 15, 21, 23, 25, 29, 31, 34], "psutil": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "5": [6, 7, 11, 13, 15, 17, 19, 21, 23, 25, 26, 29, 31, 34, 169], "h5py": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "stevedor": [6, 7, 10, 11, 25, 26, 31, 34], "share": [6, 7, 10, 11, 15], "memory38": [6, 7, 10, 11], "tweedledum": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "symengin": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "sympi": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "ply": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "dill": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "dateutil": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "six": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "joblib": [6, 11, 15, 21, 23, 29], "threadpoolctl": [6, 11, 15, 21, 23, 29], "pbr": [6, 7, 10, 11, 25, 26, 31, 34], "importlib": [6, 7, 10, 11, 15, 21, 23, 29], "metadata": [6, 7, 10, 11, 15, 21, 23, 29, 31, 34], "zipp": [6, 7, 10, 11, 15, 21, 23, 29], "mpmath": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "properti": [6, 7, 10, 11, 15, 21, 23, 29], "attempt": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29], "uninstal": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29], "cannot": [6, 7, 10, 11, 15, 21, 23, 29], "displai": [6, 7, 10, 11, 15, 21, 23, 29], "applic": [6, 7, 10, 11, 15, 21, 23, 29, 169], "vnd": [6, 7, 10, 11, 15, 21, 23, 29], "json": [6, 7, 10, 11, 15, 21, 23, 29], "38": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "aer": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "qiskit_a": [6, 11, 15, 21, 23, 29, 31, 34], "qiskit_ibmq_provid": [6, 11, 15, 21, 23, 29, 31, 34], "240": [6, 11, 21, 25, 31, 34], "websocket": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "urllib3": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "ntlm": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "client": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "certifi": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "2017": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "idna": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "charset": [6, 11, 15, 21, 23, 29, 31, 34], "normal": [6, 7, 10, 11, 15, 21, 23, 29, 31, 34, 169], "cryptographi": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "auth": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "cffi": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "pycpars": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "pypars": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "cycler": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "kiwisolv": [6, 7, 10, 11, 15, 21, 23, 25, 26, 29, 31, 34], "pulse_util": [6, 11], "achiev": [6, 11, 22, 23, 29], "effici": [6, 7, 10, 11, 13, 15, 20, 21], "state": [6, 7, 10, 11, 12, 21, 22, 23, 24, 25, 26, 29, 31, 33, 37, 38, 39, 169], "prepar": [6, 11, 23, 25, 31, 169], "transfer": [6, 11, 22, 23, 34], "unitari": [6, 11, 17, 21, 22, 38, 39, 58], "system": [6, 7, 10, 11, 15, 21, 26, 29], "manipul": [6, 11, 33, 34], "wai": [6, 7, 10, 11, 21, 31], "vari": [6, 11], "amplitud": [6, 7, 10, 11, 12, 16, 23, 37, 169], "microwav": [6, 11], "act": [6, 11, 23], "superconduct": [6, 11], "circuit": [6, 11, 13, 15, 21, 22, 24, 25, 26, 28, 29, 32, 56, 57, 169], "In": [6, 7, 10, 11, 13, 15, 20, 21, 22, 23, 25, 26, 28, 29, 31, 34], "exampl": [6, 7, 10, 11, 14, 15, 16, 17, 19, 20, 22, 25, 26, 28, 31], "qoc": [6, 11, 169], "rotat": [6, 11, 21, 25, 26, 29], "we": [6, 7, 10, 11, 13, 15, 17, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 169], "compos": [6, 11, 15, 21, 29], "four": [6, 11, 25, 26, 29], "hamiltonian": [6, 11, 36], "pauli": [6, 11, 17, 21, 25, 26, 29, 31, 34, 65, 66, 67, 93, 94, 95], "base": [6, 7, 10, 11, 15, 20, 21, 22, 23, 26, 27, 30, 169], "abl": [6, 11, 25, 31], "desir": [6, 7, 10, 11, 31], "angl": [6, 7, 10, 11, 25, 26], "ha": [6, 7, 9, 10, 11, 15, 21, 25, 26, 27, 29, 31, 34], "slot": [6, 11], "drive": [6, 11], "todo": [6, 11, 26], "jinleic": [6, 11], "bloch": [6, 11], "sphere": [6, 11], "here": [6, 7, 10, 11, 16, 17, 21, 23, 25, 26, 29, 31, 34], "figur": [6, 7, 10, 11, 21, 23, 29], "see": [6, 7, 10, 11, 12, 22, 23, 26, 28, 29, 31, 37], "curv": [6, 11, 29], "xlabel": [6, 7, 10, 11, 15], "iter": [6, 7, 10, 11, 23, 26, 29], "ylabel": [6, 7, 10, 11, 15], "titl": [6, 11, 25, 169], "initi": [6, 7, 10, 11, 21, 23, 29, 31], "plot": [6, 7, 10, 11, 29], "9950": [6, 11], "6686": [6, 11], "7436j": [6, 11], "9900": [6, 11], "6834": [6, 11], "7300j": [6, 11], "9850": [6, 11], "6979": [6, 11], "7162j": [6, 11], "9800": [6, 11], "7121": [6, 11], "7021j": [6, 11], "9749": [6, 11], "7261": [6, 11], "6876j": [6, 11], "9699": [6, 11], "7398": [6, 11], "6728j": [6, 11], "9649": [6, 11], "7532": [6, 11], "6577j": [6, 11], "9598": [6, 11], "7664": [6, 11], "6423j": [6, 11], "9547": [6, 11], "7793": [6, 11], "6266j": [6, 11], "9496": [6, 11], "7919": [6, 11], "6106j": [6, 11], "9445": [6, 11], "8042": [6, 11], "5943j": [6, 11], "9394": [6, 11], "8162": [6, 11], "5777j": [6, 11], "9342": [6, 11], "8279": [6, 11], "5608j": [6, 11], "9291": [6, 11], "8393": [6, 11], "5437j": [6, 11], "9239": [6, 11], "8504": [6, 11], "5262j": [6, 11], "9188": [6, 11], "8611": [6, 11], "5085j": [6, 11], "9136": [6, 11], "8714": [6, 11], "4905j": [6, 11], "9084": [6, 11], "8814": [6, 11], "4723j": [6, 11], "9032": [6, 11], "8911": [6, 11], "4538j": [6, 11], "8980": [6, 11], "9003": [6, 11], "4352j": [6, 11], "8927": [6, 11], "9092": [6, 11], "4163j": [6, 11], "8875": [6, 11], "9177": [6, 11], "3972j": [6, 11], "8823": [6, 11], "9258": [6, 11], "3780j": [6, 11], "8771": [6, 11], "9335": [6, 11], "3586j": [6, 11], "8719": [6, 11], "9407": [6, 11], "3391j": [6, 11], "8667": [6, 11], "9476": [6, 11], "3195j": [6, 11], "8615": [6, 11], "9540": [6, 11], "2998j": [6, 11], "8564": [6, 11], "9600": [6, 11], "2801j": [6, 11], "8512": [6, 11], "9655": [6, 11], "2603j": [6, 11], "8461": [6, 11], "9707": [6, 11], "2405j": [6, 11], "8410": [6, 11], "9753": [6, 11], "2207j": [6, 11], "8360": [6, 11], "9796": [6, 11], "2009j": [6, 11], "8310": [6, 11], "9834": [6, 11], "1812j": [6, 11], "8260": [6, 11], "9869": [6, 11], "1616j": [6, 11], "8211": [6, 11], "9898": [6, 11], "1422j": [6, 11], "9924": [6, 11], "1229j": [6, 11], "8114": [6, 11], "9946": [6, 11], "1037j": [6, 11], "8066": [6, 11], "9964": [6, 11], "0848j": [6, 11], "8019": [6, 11], "9978": [6, 11], "0661j": [6, 11], "7973": [6, 11], "9989": [6, 11], "0477j": [6, 11], "7928": [6, 11], "9996": [6, 11], "0296j": [6, 11], "7883": [6, 11], "9999": [6, 11], "0118j": [6, 11], "7840": [6, 11], "0057j": [6, 11], "7797": [6, 11], "9997": [6, 11], "0228j": [6, 11], "7755": [6, 11], "9992": [6, 11], "0395j": [6, 11], "7714": [6, 11], "9984": [6, 11], "0558j": [6, 11], "7675": [6, 11], "9974": [6, 11], "0716j": [6, 11], "7636": [6, 11], "9962": [6, 11], "0870j": [6, 11], "7599": [6, 11], "9948": [6, 11], "1020j": [6, 11], "7562": [6, 11], "9932": [6, 11], "1164j": [6, 11], "7527": [6, 11], "9915": [6, 11], "1303j": [6, 11], "7493": [6, 11], "9896": [6, 11], "1438j": [6, 11], "7461": [6, 11], "9876": [6, 11], "1567j": [6, 11], "7429": [6, 11], "9856": [6, 11], "1691j": [6, 11], "7399": [6, 11], "9835": [6, 11], "1809j": [6, 11], "7370": [6, 11], "9814": [6, 11], "1922j": [6, 11], "7343": [6, 11], "9792": [6, 11], "2030j": [6, 11], "7317": [6, 11], "9770": [6, 11], "2132j": [6, 11], "7292": [6, 11], "9748": [6, 11], "2229j": [6, 11], "7268": [6, 11], "9727": [6, 11], "2321j": [6, 11], "7246": [6, 11], "9706": [6, 11], "2407j": [6, 11], "7225": [6, 11], "9686": [6, 11], "2488j": [6, 11], "7206": [6, 11], "9666": [6, 11], "2564j": [6, 11], "7187": [6, 11], "9647": [6, 11], "2635j": [6, 11], "7170": [6, 11], "9628": [6, 11], "2700j": [6, 11], "7155": [6, 11], "9611": [6, 11], "2761j": [6, 11], "7140": [6, 11], "9595": [6, 11], "2818j": [6, 11], "7126": [6, 11], "9579": [6, 11], "2869j": [6, 11], "7114": [6, 11], "9565": [6, 11], "2917j": [6, 11], "7103": [6, 11], "9552": [6, 11], "2960j": [6, 11], "7093": [6, 11], "2999j": [6, 11], "7083": [6, 11], "9529": [6, 11], "3034j": [6, 11], "7075": [6, 11], "9519": [6, 11], "3065j": [6, 11], "7068": [6, 11], "9510": [6, 11], "3093j": [6, 11], "7062": [6, 11], "9502": [6, 11], "3117j": [6, 11], "7056": [6, 11], "9495": [6, 11], "3138j": [6, 11], "7051": [6, 11], "9489": [6, 11], "3156j": [6, 11], "7047": [6, 11], "9484": [6, 11], "3171j": [6, 11], "7044": [6, 11], "9480": [6, 11], "3183j": [6, 11], "7041": [6, 11], "3193j": [6, 11], "7040": [6, 11], "9474": [6, 11], "3201j": [6, 11], "7038": [6, 11], "9472": [6, 11], "3206j": [6, 11], "7037": [6, 11], "9471": [6, 11], "3209j": [6, 11], "3210j": [6, 11], "3208j": [6, 11], "9473": [6, 11], "3205j": [6, 11], "3200j": [6, 11], "3194j": [6, 11], "7043": [6, 11], "9478": [6, 11], "3187j": [6, 11], "7045": [6, 11], "9481": [6, 11], "3180j": [6, 11], "3172j": [6, 11], "7050": [6, 11], "9487": [6, 11], "3163j": [6, 11], "7052": [6, 11], "9490": [6, 11], "3153j": [6, 11], "7055": [6, 11], "9493": [6, 11], "3143j": [6, 11], "7057": [6, 11], "9497": [6, 11], "3133j": [6, 11], "7060": [6, 11], "9500": [6, 11], "3123j": [6, 11], "7063": [6, 11], "9503": [6, 11], "3112j": [6, 11], "7066": [6, 11], "9507": [6, 11], "3101j": [6, 11], "3091j": [6, 11], "line": [6, 7, 10, 11, 15, 36], "line2d": [6, 11], "0x7fdcc725dc10": [6, 11], "sinc": [6, 7, 10, 11, 23, 31], "gener": [6, 11, 13, 21, 24, 25, 26, 28, 29], "influenc": [6, 11], "It": [6, 7, 10, 11, 21, 23, 29, 33, 34, 169], "would": [6, 11], "great": [6, 11, 15], "choos": [6, 11, 25, 26], "better": [6, 7, 10, 11], "point": [6, 11, 13, 169], "intuit": [6, 11], "close": [6, 7, 10, 11], "similar": [6, 7, 10, 11, 26, 31], "reduc": [6, 7, 10, 11, 15], "simpli": [6, 7, 10, 11, 23, 29, 34], "show": [6, 7, 10, 11, 15, 21, 25, 26, 29], "previou": [6, 11, 31], "converg": [6, 11, 31], "varit": [6, 11], "schme": [6, 11], "design": [6, 7, 10, 11, 26, 169], "avoid": [6, 7, 10, 11, 15, 21, 29], "drawback": [6, 11], "approach": [6, 11, 31], "well": [6, 11, 15, 23], "find": [6, 7, 10, 11, 15, 31], "intermdi": [6, 11, 21], "abstract": [6, 11], "post": [6, 11, 12, 37, 169], "algorithm": [6, 7, 10, 11, 22, 23, 27, 169], "improv": [6, 7, 10, 11, 13], "nisq": [6, 11], "backend": [6, 7, 10, 11, 15, 21, 25], "note": [6, 7, 10, 11, 21, 31], "hardwar": [6, 11, 25, 27, 31, 169], "everi": [6, 7, 10, 11], "calibr": [6, 11], "also": [6, 11, 15, 22, 23, 26, 28, 29, 31, 169], "fakejakarta": [6, 11], "snp": [6, 11], "namli": [6, 11], "singl": [6, 11, 31, 83], "tnp": [6, 11], "two": [6, 7, 10, 11, 21, 25, 29, 31, 33, 34], "ansatz": [6, 7, 10, 11, 21, 25, 26, 29, 35], "task": [6, 7, 10, 11, 20, 29, 31, 169], "sched0": [6, 11], "sched1": [6, 11], "sched2": [6, 11], "pul_append": [6, 11], "combin": [6, 11, 15, 21, 24, 25], "pulse_ansatz": [6, 11], "extract_amp": [6, 11], "get": [6, 7, 10, 11, 15, 21, 23, 25, 26, 28, 29, 31, 34, 169], "extract_realamp": [6, 11], "part": [6, 11, 13, 24, 25, 26, 29], "ignor": [6, 7, 10, 11, 25], "imaginari": [6, 11], "extract_phas": [6, 11], "classic": [6, 11, 21, 22, 23, 24, 25, 28, 31, 33, 34, 169], "phase": [6, 7, 10, 11, 15, 21, 23], "parameters_arrai": [6, 11], "1007186": [6, 11], "00833101": [6, 11], "096837": [6, 11], "02080554": [6, 11], "20122114": [6, 11], "57079633": [6, 11], "11225338": [6, 11], "01509274": [6, 11], "7727792": [6, 11], "96348159": [6, 11], "12649991": [6, 11], "17811106": [6, 11], "hydrogen": [6, 11], "molecul": [6, 11, 36], "And": [6, 11, 15, 23, 29], "give": [6, 11, 23, 34], "string": [6, 11, 32, 169], "sto3g": [6, 11], "basi": [6, 11, 169], "pariti": [6, 11], "map": [6, 7, 10, 11, 25, 28, 29], "reduct": [6, 11], "pauli_dict": [6, 11], "ii": [6, 11], "0523732": [6, 11], "iz": [6, 11], "39793742": [6, 11], "zi": [6, 11], "3979374": [6, 11], "zz": [6, 11, 21], "0112801": [6, 11], "xx": [6, 11, 21], "18093119": [6, 11], "map_amp": [6, 11], "introduc": [6, 11], "adjust": [6, 7, 10, 11], "new": [6, 7, 10, 11, 15, 26, 38, 39], "send": [6, 7, 10, 11, 34], "observe_gener": [6, 11], "genrat": [6, 11], "run_pulse_sim": [6, 11], "updat": [6, 7, 10, 11, 25, 29], "cur_best_w": [6, 11], "modified_list": [6, 11], "len": [6, 7, 10, 11, 21, 25, 26, 34], "ndarrai": [6, 11], "tolist": [6, 11], "prepuls": [6, 11], "measurement_puls": [6, 11], "observe_geneart": [6, 11], "xx_yy_zz_expect": [6, 11], "h_expect": [6, 11], "cobyla": [6, 11], "vqe_result": [6, 11], "minim": [6, 11, 31], "constraint": [6, 7, 10, 11, 15, 21, 23, 29], "gen_lc": [6, 11], "option": [6, 7, 10, 11, 31, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "rhobeg": [6, 11], "maxit": [6, 11], "disp": [6, 11], "estim": [6, 7, 10, 11, 13, 15, 169], "ground": [6, 11, 31], "format": [6, 7, 10, 11, 21, 29], "fun": [6, 11], "nthe": [6, 11], "compil": [6, 7, 10, 11], "assembl": [6, 11], "461": [6, 7, 10, 11], "runtimewarn": [6, 7, 10, 11], "dynam": [6, 11, 169], "rate": [6, 7, 10, 11, 15, 29], "support": [6, 7, 10, 11, 15, 21, 22, 23, 27, 169], "rep_delai": [6, 11], "instead": [6, 7, 10, 11, 21, 25, 26, 34], "rep_tim": [6, 11], "82": [7, 10, 15, 25, 31], "6592": [7, 10], "tensorflow_model_optim": [7, 10], "l": [7, 10, 15, 21, 24, 26], "artifact": [7, 10, 15, 21], "cp": [7, 10, 15, 21], "aerbackend": [7, 10, 15, 21], "pvoqeab2z2cazk": [7, 10], "acc": [7, 10, 15, 25, 26, 32], "pt": [7, 10, 15, 26], "deprec": [7, 10, 15, 21], "chang": [7, 10, 15, 21, 23, 29], "built": [7, 10, 15, 21, 23, 29, 31, 34], "place": [7, 10, 15, 34], "first": [7, 10, 15, 17, 21, 23, 25, 31, 34, 36, 170], "temporari": [7, 10, 15], "featur": [7, 10, 15, 25, 28, 29, 31, 32], "tree": [7, 10, 15], "behavior": [7, 10, 15], "becom": [7, 10, 15], "remov": [7, 10, 15, 23], "discuss": [7, 10, 15], "regard": [7, 10, 15], "pypa": [7, 10, 15], "issu": [7, 10, 15, 21, 169], "7555": [7, 10, 15], "example2": [7, 10, 15, 21], "example4": [7, 10, 15, 21], "example6": [7, 10, 15, 21], "readm": [7, 10, 15, 21], "md": [7, 10, 15, 21], "example1": [7, 10, 15, 21], "example3": [7, 10, 15, 21], "example5": [7, 10, 15, 21], "example7": [7, 10, 15, 21], "6019": [7, 10], "412": [7, 10, 25], "uc5482d32c36f34b90b578ab5b99": [7, 10], "btq9ol3v0l": [7, 10], "sxlqutssxhwjykpuhnrklk35nt2": [7, 10], "sgcbkcqsbwyrw0fslelnh8g_zsduzs1nj6x7fxcikuayar3ckm": [7, 10], "rn06ct3jmdk68bwvmtarwv_ntvwzjcpij6icv1x_84ww_81cietipxsmv7krdblnko87r3akq2way39yba": [7, 10], "02": [7, 10, 11, 15, 21, 26, 29], "601b": [7, 10], "80f": [7, 10], "inline2": [7, 10], "btsi1u3ew1ndzesp1ud4dkhwvk": [7, 10], "tgaz": [7, 10], "cewmckksz4nhqie4duxetznqo4wl7xrpnfnovnzsk0zlqvudpmlbh1o8efctvyrgn2xr": [7, 10], "vnio6ajgtwiwaahalcqmdrthkem9jjsx_9kak1spa_cx1nqv1xnat6j7dnt1hxflgrzevhr6sgt5ccjzzoaedmfqdijgyj9zvutvyone2befeedw9gwjqi77ygdxe8": [7, 10], "qnc0ro2ifjgriu7c3vyz9fxem4dt3cy1sme1y8az": [7, 10], "qsiypditmdsbjou0vpjk3jl8w_a6ezx0dabhjgjmvk_l8lqhqkqowsvxvzc3lffzuyhsria43nzhrlhskdochgyhbt_cbl_rhv3jmk8oiluwaglqi": [7, 10], "bud9eem6fahz6avbmu07z8_sslve5bra3o9vpwuafdyda4g": [7, 10], "03": [7, 10, 11, 15, 21, 26], "50439": [7, 10], "49k": [7, 10], "octet": [7, 10], "stream": [7, 10, 15], "26k": [7, 10], "528": [7, 10], "o": [7, 10, 15, 26], "sy": [7, 10, 15], "cudnn": [7, 10, 15], "tqdm": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "torchpack": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "io": [7, 10, 26], "environ": [7, 10, 15], "set_run_dir": [7, 10, 15], "config": [7, 10, 15, 36], "log": [7, 10, 15, 21], "logger": [7, 10, 15], "qiskit2tq": [7, 10], "build_module_from_op_list": [7, 10], "build_module_op_list": [7, 10], "get_v_c_reg_map": [7, 10], "get_p_c_reg_map": [7, 10], "get_p_v_reg_map": [7, 10], "get_cared_config": [7, 10], "super_util": [7, 10], "get_named_sample_arch": [7, 10], "tensorboard": [7, 10, 21, 23, 25, 26, 29, 31, 34], "summarywrit": [7, 10], "goal": [7, 10], "sectio": [7, 10], "practic": [7, 10], "subcircuit": [7, 10], "supercircuit": [7, 10, 169], "impact": [7, 10, 15], "assign": [7, 10, 25], "understand": [7, 10, 24, 25, 26], "basic": [7, 10, 29, 30, 31], "concept": [7, 10, 23], "implement": [7, 10, 12, 26, 27, 29, 31, 34, 37, 169], "evolutionari": [7, 10], "super_lay": [7, 10, 169], "super_layer_name_dict": [7, 10], "superqfcmodel0": [7, 10], "encoder_op_list_nam": [7, 10, 15], "q_layer_nam": [7, 10, 15], "sample_arch": [7, 10], "set_sample_arch": [7, 10], "count_sample_param": [7, 10], "verbos": [7, 10], "getattr": [7, 10], "down_sample_kernel_s": [7, 10, 15], "info": [7, 10, 15, 23, 31, 34], "output_len": [7, 10], "arch_spac": [7, 10], "space": [7, 10, 23, 25, 28, 29], "super_layers_al": [7, 10], "sampl": [7, 10, 23, 29, 31, 169], "n_front_share_block": [7, 10], "load": [7, 10, 12, 15, 21, 23, 31, 32, 37, 169], "describ": [7, 10, 15, 21, 29], "everyth": [7, 10, 15], "about": [7, 10, 15, 31], "structur": [7, 10, 15, 29], "config_str": [7, 10], "n_layers_per_block": [7, 10, 15, 21, 29], "u3cu3_s0": [7, 10], "n_front_share_wir": [7, 10], "n_front_share_op": [7, 10], "strategi": [7, 10], "transpile_before_run": [7, 10, 15], "load_op_list": [7, 10, 15], "input_nam": [7, 10, 15, 21], "target_nam": [7, 10, 15, 21], "lambda_lr": [7, 10, 15], "workers_per_gpu": [7, 10, 15], "set_se": [7, 10, 15], "callback": [7, 10, 15], "inferencerunn": [7, 10, 15], "subcallback": [7, 10, 15], "metric": [7, 10, 15, 23], "categoricalaccuraci": [7, 10, 15], "nllerror": [7, 10, 15], "maxsav": [7, 10, 15], "saver": [7, 10, 15], "max_to_keep": [7, 10, 15], "noise_model_nam": [7, 10, 15], "basis_gates_nam": [7, 10, 15], "8192": [7, 10, 15], "initial_layout": [7, 10, 15], "seed_transpil": [7, 10, 15], "seed_simul": [7, 10, 15], "optimization_level": [7, 10, 15], "est_success_r": [7, 10, 15], "max_job": [7, 9, 10, 15], "e": [7, 10, 21, 26, 31], "random_search": [7, 10], "population_s": [7, 10], "parent_s": [7, 10], "mutation_s": [7, 10], "mutation_prob": [7, 10], "crossover_s": [7, 10], "n_iter": [7, 10], "score_mod": [7, 10], "loss_succ": [7, 10], "gene_mask": [7, 10], "eval": [7, 10, 15, 26], "use_noise_model": [7, 10], "qiskit_max": [7, 10], "150": [7, 10, 15, 25, 31], "target_pruning_amount": [7, 10], "init_pruning_amount": [7, 10], "start_epoch": [7, 10], "end_epoch": [7, 10], "30": [7, 10, 15, 21, 23, 25, 29, 31, 169], "yml": [7, 10, 15], "w": [7, 10, 15, 21, 25, 33, 34, 169], "write": [7, 10, 36], "isinst": [7, 10, 15], "300": [7, 10, 15, 25, 29], "n_train_sampl": [7, 10, 15, 21, 29], "5000": [7, 10, 15, 21], "n_valid_sampl": [7, 10, 15], "state_dict": [7, 10, 26], "map_loc": [7, 10], "load_state_dict": [7, 10], "strict": [7, 10], "total_param": [7, 10, 15], "p": [7, 10, 15, 21, 26, 33, 34], "numel": [7, 10, 15, 26], "log_acc": [7, 10], "evaluate_gen": [7, 10], "non_block": [7, 10], "yann": [7, 10, 15, 21, 29], "lecun": [7, 10, 15, 21, 29], "exdb": [7, 10, 15, 21, 29], "idx3": [7, 10, 15, 21, 29], "ubyt": [7, 10, 15, 21, 29], "gz": [7, 10, 15, 21, 23, 29, 31, 34], "extract": [7, 10, 15, 21, 29, 34], "label": [7, 10, 15, 21, 23, 25, 26, 29], "idx1": [7, 10, 15, 21, 29], "t10k": [7, 10, 15, 21, 29], "081": [7, 10, 21, 25], "141": [7, 10, 15, 25, 31], "157": [7, 10, 15, 25, 31], "333": [7, 10, 15, 25], "let": [7, 10, 21, 31, 34], "predict": [7, 10, 15, 21, 23, 25, 26, 32], "n_sampl": [7, 10, 29], "break": [7, 10, 29, 31], "down": [7, 10, 31, 169], "28x28": [7, 10, 29], "4x4": [7, 10, 21], "after_down_sampl": [7, 10], "pred": [7, 10, 25, 26], "fig": [7, 10, 21, 25, 29], "ax": [7, 10, 21, 29], "subplot": [7, 10, 21, 25, 29], "figsiz": [7, 10, 21, 29], "set_ylabel": [7, 10, 21, 25, 29], "yaxi": [7, 10, 29], "set_vis": [7, 10, 29], "set_xlabel": [7, 10, 21, 25, 29], "norm": [7, 10, 29], "color": [7, 10, 21, 25, 29], "vmin": [7, 10, 29], "vmax": [7, 10, 29], "imshow": [7, 10, 29], "cmap": [7, 10, 29], "grai": [7, 10, 29], "downsampl": [7, 10], "tight_layout": [7, 10, 21, 29], "stack": [7, 10, 25], "suffici": [7, 10], "pre": [7, 10, 27, 169], "defin": [7, 10, 17, 21, 23, 25, 29, 31], "cover": [7, 10, 34], "larg": [7, 10, 15], "Then": [7, 10, 21, 25, 26, 29, 34], "subset": [7, 10], "inherit": [7, 10], "reliabl": [7, 10, 15, 169], "rel": [7, 10, 15, 26], "individu": [7, 10, 31], "scratch": [7, 10], "pai": [7, 10], "cost": [7, 10, 31], "onc": [7, 10, 20, 21, 31, 34], "evalu": [7, 10, 15, 23, 26, 28], "fast": [7, 10, 16, 169], "henc": [7, 10, 15], "significantli": [7, 10], "posit": [7, 10, 21, 23, 26, 29], "how": [7, 10, 12, 16, 20, 21, 23, 25, 26, 27, 28, 29, 31, 34, 37, 169], "mani": [7, 10, 23, 169], "put": [7, 10, 29, 34], "kth": [7, 10], "code": [7, 10, 15, 18, 21, 23, 25, 26, 29], "cell": [7, 10, 25, 29], "randomli": [7, 10], "further": [7, 10, 34], "relat": [7, 10, 26], "between": [7, 10, 21, 22, 23, 24, 25, 26, 31, 34], "architectur": [7, 10, 25, 26, 29, 169], "its": [7, 10, 17, 31, 169], "gene_choic": [7, 10], "gene_len": [7, 10], "samp_gen": [7, 10], "choic": [7, 10], "depth": [7, 10, 15, 21], "noisi": [7, 10], "On": [7, 10, 14, 27, 169], "distort": [7, 10], "subsect": [7, 10], "gap": [7, 10], "brought": [7, 10], "layout": [7, 10], "attach": [7, 10, 21, 25], "our": [7, 10, 15, 20, 21, 23, 25, 26, 29, 31, 169], "save_account": [7, 9, 10, 15, 21, 23, 29], "0238b0afc0dc515fe7987b02706791d1719cb89b68befedc125eded0607e6e9e9f26d3eed482f66fdc45fdfceca3aab2edb9519d96b39e9c78040194b86e7858": [7, 9, 10, 15, 23], "overwrit": [7, 9, 10, 15, 21, 23, 29], "ibmq_quito": [7, 10, 21, 29], "set_layout": [7, 10], "virtual": [7, 10], "physic": [7, 10, 33, 34], "gene_list": [7, 10], "param_num": [7, 10], "accu_noise_fre": [7, 10], "accu_noisy_model": [7, 10], "marker": [7, 10, 15, 21], "num": [7, 10, 15, 21], "legend": [7, 10, 15, 21, 25, 29], "29it": [7, 10], "558": [7, 10, 15], "49666666666666665": [7, 10], "559": [7, 10, 15], "2080743312835693": [7, 10], "778": [7, 10, 21], "transpil": [7, 10, 15, 21], "width": [7, 10, 15, 21], "n_single_g": [7, 10, 15, 21], "n_two_gat": [7, 10, 15, 21], "n_three_more_g": [7, 10, 15, 21], "n_gates_dict": [7, 10, 15, 21], "887": [7, 10, 15, 21], "job": [7, 9, 10, 15, 21], "statu": [7, 9, 10, 15, 21], "being": [7, 10, 15, 21, 22, 23, 31], "43": [7, 10, 15, 21, 23, 25, 26, 29, 31], "44": [7, 10, 15, 21, 25, 31], "065": [7, 10, 15, 25], "107": [7, 10, 25, 31], "027": [7, 10, 25], "49333333333333335": [7, 10], "041": [7, 10, 25], "2184091266935244": [7, 10], "36it": [7, 10], "340": [7, 10, 15, 21, 25], "5466666666666666": [7, 10], "346": [7, 10, 15, 25, 26], "1071999073028564": [7, 10], "537": [7, 10, 15], "577": [7, 10, 15, 21], "56": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "926": [7, 10], "053": [7, 10, 15, 21, 25], "643": [7, 10, 25], "5433333333333333": [7, 10], "644": [7, 10, 15, 21], "125934737653964": [7, 10], "15it": [7, 10], "980": [7, 10, 15, 31], "7133333333333334": [7, 10], "983": [7, 10, 15, 21], "067213535308838": [7, 10], "37": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "181": [7, 10, 15, 25, 31], "227": [7, 10, 15, 25], "87": [7, 10, 25, 29, 31], "873": [7, 10], "918": [7, 10], "45": [7, 10, 15, 21, 25, 31], "902": [7, 10, 15, 25], "903": [7, 10, 21], "090604862178361": [7, 10], "order": [7, 10, 20, 21, 31], "randomsearch": [7, 10], "accuracy_predictor": [7, 10], "random_sampl": [7, 10], "sample_num": [7, 10], "popul": [7, 10], "while": [7, 10, 29, 31, 34], "run_search": [7, 10], "n_subcircuit": [7, 10], "subnet": [7, 10, 15], "arrai": [7, 10, 21, 23, 25], "best_idx": [7, 10], "argmax": [7, 10, 25], "agent": [7, 10, 169], "861": [7, 10, 15], "893": [7, 10, 15], "927": [7, 10, 25], "958": [7, 10, 15], "31": [7, 10, 15, 21, 25, 26, 29, 31, 34], "060": [7, 10, 25], "5233333333333333": [7, 10], "062": [7, 10, 15, 21, 25], "1178400952332603": [7, 10], "268": [7, 10, 15, 25], "319": [7, 10, 15], "07": [7, 10, 11, 15, 21, 23, 29, 31], "208": [7, 10, 25], "538": [7, 10, 15], "0768679596464827": [7, 10], "795": [7, 10], "828": [7, 10], "55": [7, 10, 15, 21, 23, 25, 29, 31], "749": [7, 10], "770": [7, 10, 15, 21, 25], "871": [7, 10, 15, 21], "5066666666666667": [7, 10], "2454881983522421": [7, 10], "152": [7, 10, 15, 25, 31], "46": [7, 10, 15, 21, 25, 31], "353": [7, 10, 15, 25], "376": [7, 10, 25], "310": [7, 10, 21], "313": [7, 10, 25], "2137750657866044": [7, 10], "507": [7, 10, 15, 25], "535": [7, 10], "605": [7, 10], "632": [7, 10], "580": [7, 10, 15], "203591203062656": [7, 10], "855": [7, 10, 15, 21], "891": [7, 10], "762": [7, 10, 21, 25], "777": [7, 10], "43666666666666665": [7, 10], "2419370779175787": [7, 10], "990": [7, 10, 15, 21], "019": [7, 10, 15], "48": [7, 10, 15, 21, 25, 31, 34], "457": [7, 10, 15], "481": [7, 10, 15, 21, 29], "460": [7, 10, 15, 25], "6033333333333334": [7, 10], "464": [7, 10, 15], "1190118859257092": [7, 10], "731": [7, 10, 15], "772": [7, 10, 21], "242": [7, 10, 15, 21, 25], "278": [7, 10, 25], "332": [7, 10, 21], "6333333333333333": [7, 10], "336": [7, 10, 15], "1388151342143036": [7, 10], "524": [7, 10, 15], "553": [7, 10], "710": [7, 10], "735": [7, 10, 25], "673": [7, 10], "676": [7, 10, 15], "2040349949356608": [7, 10], "874": [7, 10, 21, 25], "236": [7, 10, 25, 26], "331": [7, 10, 21], "222": [7, 10, 15, 25], "226": [7, 10, 21, 25], "124545208780707": [7, 10], "inspir": [7, 10, 15], "evolut": [7, 10], "genet": [7, 10], "sub": [7, 10], "network": [7, 10, 14, 24, 25, 26, 169], "mutat": [7, 10], "crossov": [7, 10], "oper": [7, 10, 12, 17, 23, 24, 25, 28, 29, 31, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "shown": [7, 10], "highest": [7, 10], "kept": [7, 10], "repeat": [7, 10, 15], "until": [7, 10, 33, 34], "reach": [7, 10, 30], "max_time_budget": [7, 10], "throughout": [7, 10], "discard": [7, 10], "evolutionarysearch": [7, 10], "ask": [7, 10], "solut": [7, 10], "select_and_transform": [7, 10], "score": [7, 10, 26], "evo": [7, 10], "sort": [7, 10], "descend": [7, 10], "sorted_idx": [7, 10], "argsort": [7, 10], "hint": [7, 10], "best_solut": [7, 10], "best_scor": [7, 10], "parent": [7, 10, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "mutate_popul": [7, 10], "mutated_gen": [7, 10], "crossover_popul": [7, 10], "crossovered_gen": [7, 10], "uniform": [7, 10], "decid": [7, 10, 15, 29], "ith": [7, 10], "probabl": [7, 10, 21, 22, 23, 25, 32, 34], "agent2": [7, 10], "661": [7, 10, 25], "680": [7, 10, 15, 21, 25], "074": [7, 10, 15, 25], "088": [7, 10, 21, 25], "41": [7, 10, 15, 21, 25, 31], "315": [7, 10, 26], "48333333333333334": [7, 10], "318": [7, 10, 15, 21], "3191448190211976": [7, 10], "584": [7, 10, 15], "604": [7, 10, 15], "502": [7, 10], "518": [7, 10, 15], "763": [7, 10], "41333333333333333": [7, 10], "765": [7, 10, 34], "2413019612492695": [7, 10], "118": [7, 10, 25, 31], "767": [7, 10, 21, 26], "803": [7, 10, 21], "804": [7, 10, 15], "0950444565797663": [7, 10], "007": [7, 10, 15, 25], "036": [7, 10, 15, 21, 25], "776": [7, 10, 21], "84": [7, 10, 15, 19, 25, 29, 31], "497": [7, 10, 15], "6166666666666667": [7, 10], "506": [7, 10, 15], "1218471647477868": [7, 10], "834": [7, 10, 21], "857": [7, 10], "719": [7, 10, 15], "736": [7, 10], "04": [7, 10, 11, 15, 21, 26, 29], "972": [7, 10, 15], "975": [7, 10, 15], "3008524031639626": [7, 10], "248": [7, 10, 25], "280": [7, 10, 15, 25], "586": [7, 10, 15], "613": [7, 10, 15, 21], "477": [7, 10], "1746351749823487": [7, 10], "734": [7, 10, 15, 21], "775": [7, 10], "971": [7, 10, 15, 21], "078": [7, 10, 15, 25], "901": [7, 10, 21], "66": [7, 10, 15, 25, 31], "904": [7, 10, 15], "0752779175902272": [7, 10], "167": [7, 10, 15, 25, 31], "197": [7, 10, 15, 25, 26, 31], "312": [7, 10], "5133333333333333": [7, 10], "323": [7, 10], "1748284086133955": [7, 10], "530": [7, 10], "549": [7, 10], "551": [7, 10], "567": [7, 10, 15], "534": [7, 10], "3191143722568632": [7, 10], "761": [7, 10, 21], "796": [7, 10, 25], "589": [7, 10, 21], "618": [7, 10, 15, 21], "08": [7, 10, 15, 21], "287": [7, 10, 15, 25], "289": [7, 10, 15, 25], "098475417196267": [7, 10], "293": [7, 10, 15, 25], "294": [7, 10, 21, 25], "565": [7, 10, 21], "610": [7, 10, 15], "917": [7, 10, 15], "962": [7, 10], "960": [7, 10], "6566666666666666": [7, 10], "0750944120117145": [7, 10], "155": [7, 10, 15, 25, 31], "186": [7, 10, 25, 31], "401": [7, 10, 15, 25], "426": [7, 10], "422": [7, 10, 21], "62": [7, 10, 15, 21, 23, 25, 29, 31], "1214948036790837": [7, 10], "636": [7, 10, 21], "681": [7, 10, 21], "86": [7, 10, 25, 29, 31, 34], "324": [7, 10, 25], "585": [7, 10], "5933333333333334": [7, 10], "0902662745224483": [7, 10], "709": [7, 10, 15], "196": [7, 10, 15, 25, 31], "221": [7, 10, 25], "forkpoolwork": [7, 10], "multiprocess": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "297": [7, 10, 15, 25], "_bootstrap": [7, 10], "99": [7, 10, 17, 21, 25, 31], "_target": [7, 10], "_arg": [7, 10], "_kwarg": [7, 10], "pool": [7, 10, 26], "121": [7, 10, 15, 25, 31], "worker": [7, 10, 15, 21, 29], "func": [7, 10, 21, 23, 25, 26, 29], "kwd": [7, 10], "mapstar": [7, 10], "run_job_work": [7, 10], "job_monitor": [7, 10], "interv": [7, 10], "tool": [7, 10, 23], "monitor": [7, 10], "90": [7, 10, 15, 21, 23, 25, 29, 31], "_interval_set": [7, 10], "quiet": [7, 10], "line_disciplin": [7, 10], "_text_check": [7, 10], "sleep": [7, 10], "199": [7, 10, 25, 31], "msg": [7, 10, 34], "ipykernel": [7, 10], "iostream": [7, 10], "pub_thread": [7, 10], "_flush": [7, 10], "207": [7, 10, 15, 21, 23, 25, 29], "384": [7, 10, 15, 21, 25], "parent_head": [7, 10], "ident": [7, 10], "topic": [7, 10], "jupyter_cli": [7, 10], "session": [7, 10, 15], "753": [7, 10, 15, 21, 25], "send_multipart": [7, 10], "to_send": [7, 10], "214": [7, 10, 15, 21, 25], "lambda": [7, 10], "_really_send": [7, 10], "228": [7, 10, 15, 25], "pipe_out": [7, 10], "_pipe_uuid": [7, 10], "zmq": [7, 10], "sugar": [7, 10], "socket": [7, 10], "sndmore": [7, 10], "track": [7, 10], "cython": [7, 10], "pyx": [7, 10], "740": [7, 10, 21], "787": [7, 10, 15], "244": [7, 10, 25], "_send_copi": [7, 10], "checkrc": [7, 10], "pxd": [7, 10], "_check_rc": [7, 10], "intern": [7, 10, 24, 25, 26, 169], "inspect": [7, 10], "201": [7, 10, 15, 25, 26], "202": [7, 10, 15, 21, 25], "203": [7, 10, 25], "core": [7, 10, 26], "interactiveshel": [7, 10], "3326": [7, 10], "run_cod": [7, 10], "exec": [7, 10], "code_obj": [7, 10], "user_global_n": [7, 10], "user_n": [7, 10], "2676529f6b94": [7, 10], "b3ecfd9cf7ea": [7, 10], "88": [7, 10, 15, 25, 31], "0001952830ed": [7, 10], "54": [7, 10, 15, 21, 25, 31, 34], "7bff2f22f587": [7, 10], "275": [7, 10, 15, 25], "_map_async": [7, 10], "chunksiz": [7, 10], "651": [7, 10, 15, 21], "wait": [7, 10], "timeout": [7, 10], "648": [7, 10, 13, 15, 21], "_event": [7, 10], "thread": [7, 10], "552": [7, 10], "signal": [7, 10, 24, 25, 26], "_cond": [7, 10], "296": [7, 10, 15, 21, 23, 25, 29, 31, 34], "waiter": [7, 10], "acquir": [7, 10], "dure": [7, 10, 21], "handl": [7, 10, 21], "anoth": [7, 10], "occur": [7, 10], "2040": [7, 10], "showtraceback": [7, 10], "stb": [7, 10], "valu": [7, 9, 10, 21, 23, 25, 26, 29, 31, 169], "_render_traceback_": [7, 10], "attributeerror": [7, 10], "attribut": [7, 10], "ultratb": [7, 10], "1101": [7, 10], "get_record": [7, 10], "_fixed_getinnerfram": [7, 10], "etb": [7, 10], "number_of_lines_of_context": [7, 10], "tb_offset": [7, 10], "wrap": [7, 10, 34], "fix_frame_records_filenam": [7, 10], "getinnerfram": [7, 10], "context": [7, 10, 28, 29], "1502": [7, 10], "frameinfo": [7, 10], "tb": [7, 10], "tb_frame": [7, 10], "getframeinfo": [7, 10], "1464": [7, 10], "lnum": [7, 10], "findsourc": [7, 10], "frame": [7, 10], "getsourcefil": [7, 10], "getfil": [7, 10], "696": [7, 10, 15, 21], "getmodul": [7, 10], "filenam": [7, 10, 15, 21, 23, 29, 31, 34], "__loader__": [7, 10], "733": [7, 10], "ismodul": [7, 10], "hasattr": [7, 10], "__file__": [7, 10], "queue": [7, 10], "_rlock": [7, 10], "_reader": [7, 10], "recv_byt": [7, 10], "102": [7, 10, 25, 31], "__enter__": [7, 10], "_semlock": [7, 10], "219": [7, 10, 25], "buf": [7, 10], "_recv_byt": [7, 10], "maxlength": [7, 10], "410": [7, 10, 15, 21, 25], "_recv": [7, 10], "382": [7, 10, 15, 21], "chunk": [7, 10], "read": [7, 10, 25, 34], "remain": [7, 10], "subcircui": [7, 10], "count_op": [7, 10], "neeed": [7, 10], "comparis": [7, 10], "those": [7, 10, 21], "mod_pi": [7, 10], "params_before_prun": [7, 10], "2060113": [7, 10], "float32": [7, 10, 21], "2385259": [7, 10], "831825": [7, 10], "8875616232501429": [7, 10], "16537467": [7, 10], "1199452": [7, 10], "0714889": [7, 10], "319183": [7, 10], "8012493": [7, 10], "55449617": [7, 10], "776839558278219": [7, 10], "1050001": [7, 10], "3458017": [7, 10], "2216663": [7, 10], "2591805": [7, 10], "3722651": [7, 10], "46867403": [7, 10], "3104833": [7, 10], "6374984": [7, 10], "1927967": [7, 10], "537862": [7, 10], "961351": [7, 10], "6752364": [7, 10], "6030566": [7, 10], "2493807": [7, 10], "7007474": [7, 10], "1528023": [7, 10], "5733373": [7, 10], "05264929": [7, 10], "218637": [7, 10], "9736960569964808": [7, 10], "276383701954977": [7, 10], "9545443": [7, 10], "6112427": [7, 10], "768812": [7, 10], "8226218859301966": [7, 10], "2936784": [7, 10], "0202014": [7, 10], "8791962": [7, 10], "7627599875079554": [7, 10], "3225196": [7, 10], "5350167": [7, 10], "2173138": [7, 10], "9756929": [7, 10], "0122225": [7, 10], "3282573": [7, 10], "5098736": [7, 10], "5967889": [7, 10], "23826292": [7, 10], "8825165": [7, 10], "1583827": [7, 10], "00144892": [7, 10], "1891487": [7, 10], "0944161": [7, 10], "0276417": [7, 10], "7321627775775355": [7, 10], "5605937": [7, 10], "4463723": [7, 10], "2150304": [7, 10], "6005719": [7, 10], "27260005": [7, 10], "6578254": [7, 10], "6727466": [7, 10], "172121": [7, 10], "4109098e": [7, 10], "06": [7, 10, 11, 15, 21, 31], "9533401": [7, 10], "7146789": [7, 10], "851705e": [7, 10], "014969": [7, 10], "19204804": [7, 10], "6795934e": [7, 10], "74116415": [7, 10], "trainer": [7, 10, 15], "prune_util": [7, 10], "phasel1unstructuredpruningmethod": [7, 10], "thresholdschedul": [7, 10], "writer": [7, 10], "tfeventwrit": [7, 10], "callabl": [7, 10], "pruningtrain": [7, 10], "criterion": [7, 10, 15, 26], "legalized_model": [7, 10], "_parameters_to_prun": [7, 10], "_target_pruning_amount": [7, 10], "_init_pruning_amount": [7, 10], "prune_amount_schedul": [7, 10], "prune_amount": [7, 10], "init_prun": [7, 10], "staticmethod": [7, 10], "extract_prunable_paramet": [7, 10], "named_modul": [7, 10], "procedur": [7, 10], "_remove_prun": [7, 10], "_prune_model": [7, 10], "global": [7, 10, 26, 32], "threshold": [7, 10], "percentag": [7, 10, 15], "just": [7, 10, 23, 31], "parametr": [7, 10, 21], "weight_orig": [7, 10], "weight_mask": [7, 10], "clear": [7, 10, 25], "want": [7, 10, 12, 23, 29, 37, 169], "cascad": [7, 10], "perman": [7, 10], "epoch_num": [7, 10], "given": [7, 10], "amount": [7, 10, 31], "global_unstructur": [7, 10], "pruning_method": [7, 10, 15], "summari": [7, 10, 15], "add_scalar": [7, 10], "_before_epoch": [7, 10], "run_step": [7, 10], "legal": [7, 10], "output_dict": [7, 10], "_run_step": [7, 10], "unitary_loss": [7, 10], "lr_group": [7, 10], "add_text": [7, 10], "global_step": [7, 10, 15], "_after_epoch": [7, 10], "commit": [7, 10, 169], "num_epoch": [7, 10, 15], "_after_step": [7, 10], "_state_dict": [7, 10], "store": [7, 10, 15, 21, 23, 29, 31, 32, 34, 169], "becaus": [7, 10, 29, 31], "model_arch": [7, 10], "q_layer_op_list": [7, 10, 15], "encoder_func_list": [7, 10], "warn": [7, 10, 15, 21], "No": [7, 10, 15, 32], "them": [7, 10, 25, 26, 31, 34], "v_c_reg_map": [7, 10], "_load_state_dict": [7, 10], "gradient_prun": [7, 10, 15], "get_subcallback": [7, 10, 15], "rais": [7, 10, 15, 26, 34], "notimplementederror": [7, 10, 15, 26], "make_callback": [7, 10, 15], "ratio": [7, 10, 15, 23], "If": [7, 10, 12, 23, 29, 37], "tri": [7, 10], "rerun": [7, 10], "codecel": [7, 10], "reset": [7, 10, 23, 29], "target_pruning_amout": [7, 10], "n_finetune_epoch": [7, 10], "model2": [7, 10, 29], "nllloss": [7, 10, 15, 25, 26], "run_dir": [7, 10, 15], "join": [7, 10, 15, 169], "execut": [7, 10, 15, 21, 23, 26], "argv": [7, 10, 15], "train_with_default": [7, 10, 15], "977": [7, 10], "bin": [7, 10, 15], "ipykernel_launch": [7, 10, 15], "jupyt": [7, 10, 15], "kernel": [7, 10, 12, 15, 18, 37, 169], "70920978": [7, 10], "dd9d": [7, 10], "487a": [7, 10], "878a": [7, 10], "8181130f4ed5": [7, 10], "981": [7, 10], "0001": [7, 10, 15], "194": [7, 10, 15, 25, 31], "863": [7, 10, 15, 21], "831": [7, 10], "905": [7, 10, 15], "checkpoint": [7, 10, 15], "084": [7, 10, 25], "951": [7, 10, 15], "954": [7, 10, 15], "96537": [7, 10], "99263": [7, 10], "99843": [7, 10], "lr_group0": [7, 10, 15], "957": [7, 10, 15, 21], "left": [7, 10, 15], "minut": [7, 10, 15, 25], "998": [7, 10, 15], "571": [7, 10], "659": [7, 10], "591": [7, 10], "592": [7, 10], "997": [7, 10, 15], "97": [7, 10, 15, 25, 26, 31], "9794": [7, 10], "049923": [7, 10], "13868": [7, 10], "597": [7, 10, 21], "602": [7, 10], "603": [7, 10], "674": [7, 10, 15, 21, 34], "517": [7, 10, 15, 21], "230": [7, 10, 15, 25], "232": [7, 10, 15, 25], "667": [7, 10, 15, 21], "447": [7, 10, 15], "0032": [7, 10, 11], "98233": [7, 10], "98394": [7, 10], "049692": [7, 10], "17479": [7, 10], "235": [7, 10, 25], "238": [7, 10, 25], "63": [7, 10, 15, 21, 23, 25, 29, 31], "241": [7, 10, 25], "745": [7, 10], "250": [7, 10, 25], "_multiprocessingdataloaderit": [7, 10], "__del__": [7, 10], "0x7f9f0bb9f320": [7, 10], "1510": [7, 10], "_shutdown_work": [7, 10], "1493": [7, 10], "is_al": [7, 10], "151": [7, 10, 21, 25, 31], "assert": [7, 10, 26], "_parent_pid": [7, 10], "getpid": [7, 10], "child": [7, 10], "assertionerror": [7, 10], "409": [7, 10, 21], "462": [7, 10, 15], "495": [7, 10, 15], "498": [7, 10, 15, 21], "95921": [7, 10], "97466": [7, 10], "97699": [7, 10], "049309": [7, 10], "2084": [7, 10], "511": [7, 10, 15], "570": [7, 10, 15], "122": [7, 10, 25, 31], "153": [7, 10, 15, 25, 31], "215": [7, 10, 25], "0229": [7, 10], "96918": [7, 10], "97377": [7, 10], "048776": [7, 10], "23961": [7, 10], "160": [7, 10, 15, 21, 25, 26, 30, 31], "284": [7, 10, 21, 25], "817": [7, 10, 15, 21], "529": [7, 10], "849": [7, 10, 15, 21], "225": [7, 10, 15, 25], "946": [7, 10, 15], "120": [7, 10, 25, 31], "961": [7, 10, 15, 25], "99482": [7, 10], "96391": [7, 10], "97313": [7, 10], "048097": [7, 10], "26852": [7, 10], "967": [7, 10, 15, 25], "609": [7, 10], "846": [7, 10, 15], "140": [7, 10, 25, 31], "821": [7, 10, 15, 25], "94251": [7, 10], "96686": [7, 10], "047275": [7, 10], "2952": [7, 10], "856": [7, 10, 15], "860": [7, 10, 15, 25], "864": [7, 10], "479": [7, 10, 15], "595": [7, 10, 15, 21], "630": [7, 10, 21], "633": [7, 10, 29], "721": [7, 10], "0047": [7, 10, 11], "99141": [7, 10], "0062": [7, 10, 11], "046316": [7, 10], "31975": [7, 10], "639": [7, 10], "642": [7, 10, 21], "338": [7, 10], "449": [7, 10], "180": [7, 10, 21, 25, 31], "459": [7, 10, 15], "98988": [7, 10], "0081": [7, 10, 11], "0098": [7, 10, 11], "045225": [7, 10, 15], "34225": [7, 10], "469": [7, 10, 15], "471": [7, 10], "098": [7, 10, 21, 25], "637": [7, 10, 15, 21], "554": [7, 10, 15], "711": [7, 10, 15], "99656": [7, 10], "1146": [7, 10], "076": [7, 10, 15, 25], "04401": [7, 10], "3628": [7, 10], "229": [7, 10, 15, 25], "compar": [7, 10, 25, 28], "params_after_prun": [7, 10], "hist": [7, 10], "alpha": [7, 10, 21], "ibmqfactori": [7, 10, 15], "load_account": [7, 10, 15], "608": [7, 10, 15], "credenti": [7, 10, 15], "replac": [7, 10, 15, 21, 23, 24, 25, 26, 28, 29], "915": [7, 10, 15], "004": [7, 10, 15], "135": [7, 10, 15, 25, 31], "119": [7, 10, 15, 25, 31], "cx": [7, 10, 21, 34], "317": [7, 10, 25], "316": [7, 10, 25], "3caf9e3ce3e2": [7, 10], "q_layer_parameter": [7, 10], "q_layer_fix": [7, 10], "q_layer_measur": [7, 10], "parallel": [7, 10, 15], "274": [7, 10, 15, 25], "276": [7, 10, 21, 25], "277": [7, 10, 15, 25], "266": [7, 10, 15, 25], "267": [7, 10, 15, 25], "269": [7, 10, 15, 21, 25], "270": [7, 10, 15, 25], "starmap": [7, 10], "649": [7, 10, 15], "650": [7, 10, 21], "652": [7, 10, 15, 25], "readi": [7, 10, 25], "653": [7, 10, 15, 21], "timeouterror": [7, 10], "646": [7, 10, 21], "647": [7, 10, 21], "550": [7, 10, 15], "_flag": [7, 10], "restor": [7, 10, 34], "matter": [7, 10, 11], "what": [7, 10, 15, 21, 22, 23, 26, 29], "g": [7, 10, 21, 33, 34], "295": [7, 10, 25], "gotit": [7, 10], "298": [7, 10, 21, 25], "noise_model_tq": [7, 10], "builder": [7, 10], "make_noise_model_tq": [7, 10], "mai": [7, 10, 12, 25, 29, 37, 169], "permut": [7, 10], "reg": [7, 10], "measure_al": [7, 9, 10], "processor": [7, 9, 10, 15, 21, 169], "circ_transpil": [7, 10], "set_v_c_reg_map": [7, 10], "noisemodeltq": [7, 10], "noise_total_prob": [7, 10, 15], "ignored_op": [7, 10], "ignored_noise_op": [7, 10], "factor": [7, 10, 21], "add_therm": [7, 10], "is_add_nois": [7, 10], "p_c_reg_map": [7, 10], "p_v_reg_map": [7, 10], "set_noise_model_tq": [7, 10], "654": [7, 10], "022": [7, 10], "typeerror": [7, 10], "connectionpool": [7, 10], "_make_request": [7, 10], "conn": [7, 10], "url": [7, 10], "httplib_request_kw": [7, 10], "buffer": [7, 10], "377": [7, 10, 15], "httplib_respons": [7, 10], "getrespons": [7, 10], "378": [7, 10, 13, 15, 21], "got": [7, 10], "unexpect": [7, 10, 22, 23], "keyword": [7, 10], "argument": [7, 10, 31], "970bff9ee84b": [7, 10], "189": [7, 10, 15, 21, 25, 31], "disable_account": [7, 10], "190": [7, 10, 15, 21, 25, 31], "191": [7, 10, 15, 25, 31], "_initialize_provid": [7, 10], "prefer": [7, 10], "192": [7, 10, 25, 31], "193": [7, 10, 15, 25, 31], "prevent": [7, 10, 169], "edg": [7, 10], "case": [7, 10, 15, 25, 29, 31], "where": [7, 10, 21, 22, 23, 34], "avail": [7, 10, 29, 31, 169], "458": [7, 10, 21], "connection_paramet": [7, 10], "service_url": [7, 10], "auth_client": [7, 10], "current_service_url": [7, 10], "user_hub": [7, 10], "api": [7, 10], "respect": [7, 10, 15, 21], "base_api": [7, 10], "123": [7, 10, 21, 25, 31], "var": [7, 10], "annot": [7, 10], "rest": [7, 10], "85": [7, 10, 15, 25, 29, 31], "get_url": [7, 10], "union": [7, 10, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "bool": [7, 10, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "598": [7, 10, 15], "599": [7, 10, 15, 25], "setdefault": [7, 10], "allow_redirect": [7, 10], "600": [7, 10], "601": [7, 10, 21], "bare": [7, 10], "_log_request_info": [7, 10], "final_url": [7, 10], "header": [7, 10], "raise_for_statu": [7, 10], "279": [7, 10, 15, 25], "requestexcept": [7, 10], "ex": [7, 10], "cooki": [7, 10], "proxi": [7, 10], "verifi": [7, 10, 31], "cert": [7, 10], "send_kwarg": [7, 10], "587": [7, 10, 15], "resp": [7, 10], "prep": [7, 10], "588": [7, 10], "699": [7, 10, 21], "700": [7, 10, 21], "701": [7, 10, 15], "adapt": [7, 10, 25, 26, 31, 169], "702": [7, 10, 15], "703": [7, 10, 15, 21], "elaps": [7, 10], "approxim": [7, 10, 21, 25, 31, 169], "decode_cont": [7, 10], "retri": [7, 10], "max_retri": [7, 10], "499": [7, 10, 15, 21, 25], "500": [7, 10, 15, 29], "501": [7, 10, 15, 21], "urlopen": [7, 10], "bodi": [7, 10], "redirect": [7, 10], "assert_same_host": [7, 10], "pool_timeout": [7, 10], "release_conn": [7, 10], "body_po": [7, 10], "response_kw": [7, 10], "timeout_obj": [7, 10], "go": [7, 10, 15, 21, 29], "releas": [7, 10], "379": [7, 10, 25], "380": [7, 10, 15, 25], "381": [7, 10, 15, 25], "chain": [7, 10, 20, 21], "1371": [7, 10], "1372": [7, 10], "1373": [7, 10], "begin": [7, 10, 12, 21, 31, 37, 169], "1374": [7, 10], "connectionerror": [7, 10], "1375": [7, 10], "reason": [7, 10], "_read_statu": [7, 10], "320": [7, 10, 15, 25], "continu": [7, 10, 31], "321": [7, 10, 25], "fp": [7, 10], "readlin": [7, 10], "_maxlin": [7, 10], "iso": [7, 10], "8859": [7, 10], "281": [7, 10, 25], "282": [7, 10, 15, 25], "linetoolong": [7, 10], "readinto": [7, 10], "b": [7, 10, 23, 26, 28], "_sock": [7, 10], "recv_into": [7, 10], "590": [7, 10, 25], "_timeout_occur": [7, 10], "ssl": [7, 10], "nbyte": [7, 10], "1069": [7, 10], "allow": [7, 10, 31, 33, 34], "1070": [7, 10], "__class__": [7, 10], "1071": [7, 10], "1072": [7, 10], "1073": [7, 10], "928": [7, 10, 15], "929": [7, 10, 31, 34], "_sslobj": [7, 10], "930": [7, 10, 15], "931": [7, 10], "chip": [7, 10, 12, 14, 15, 37, 169], "part1": [7, 10], "shift": [7, 10, 12, 18, 37, 169], "rule": [7, 10, 18, 34], "rzz": [7, 10, 21, 23, 97], "sethlayer0": [7, 10, 21], "calcul": [7, 10, 15, 20, 21, 23, 25, 26, 29], "both": [7, 10, 21, 25, 31, 34], "expectaion": [7, 10, 21], "shift_and_run": [7, 10, 21], "param_list": [7, 10, 21], "grad_list": [7, 10, 21], "copy_": [7, 10, 21], "out1": [7, 10, 21], "out2": [7, 10, 21], "classif": [7, 10, 18, 20, 22, 169], "566": [7, 10, 15], "suggest": [7, 10, 15, 21, 29], "smaller": [7, 10, 15, 21, 29], "excess": [7, 10, 15, 21, 29], "creation": [7, 10, 15, 21, 29], "might": [7, 10, 15, 21, 29], "slow": [7, 10, 15, 21, 29], "even": [7, 10, 15, 21, 27, 29], "freez": [7, 10, 15, 21, 29], "lower": [7, 10, 15, 21, 26, 29], "potenti": [7, 10, 15, 21, 28, 29], "necessari": [7, 10, 15, 21, 23, 29], "cpuset_check": [7, 10, 15, 21, 29], "twice": [7, 10, 21], "back": [7, 10, 15, 21, 169], "propag": [7, 10, 21], "grads_bp": [7, 10, 21], "grads_p": [7, 10, 21], "train_and_return_grad": [7, 10, 21], "via": [7, 10, 21, 31, 33, 34, 169], "grad_bp": [7, 10, 21], "grad_p": [7, 10, 21], "0017274575140626314": [7, 10], "4705394190871369": [7, 10], "8642696738243103": [7, 10], "0004774575140626316": [7, 10], "4605809128630705": [7, 10], "8554338812828064": [7, 10], "8554337024688721": [7, 10], "00047745751406263136": [7, 10], "8481622338294983": [7, 10], "001727457514062632": [7, 10, 21, 29], "43651452282157677": [7, 10], "8257133960723877": [7, 10], "45884146341463417": [7, 10], "8054772615432739": [7, 10], "now": [7, 10, 21, 25, 29, 31], "exactli": [7, 10, 21], "same": [7, 10, 21, 28, 29, 31], "n_param": [7, 10, 21], "ax_list": [7, 10, 21], "sharex": [7, 10, 21, 29], "1f77b4": [7, 10, 21], "scatter": [7, 10, 21], "ff7f0e": [7, 10, 21], "axhlin": [7, 10, 21], "black": [7, 10, 21], "lw": [7, 10, 21], "jiang": [7, 10, 21], "et": [7, 10, 21, 169], "al": [7, 10, 21, 169], "classification2dataset": [7, 10, 21], "sum0": [7, 10, 21], "sum1": [7, 10, 21], "linspac": [7, 10, 21], "y": [7, 10, 21, 22, 23, 26, 29, 31, 66], "__getitem__": [7, 10, 21], "idx": [7, 10, 21, 25], "__len__": [7, 10, 21], "simple2class": [7, 10, 21], "train_dataset": [7, 10, 21], "valid_dataset": [7, 10, 21], "three": [7, 10, 15, 17, 21, 23, 25, 26, 29], "transform": [7, 10, 21, 22, 23, 24, 25, 32, 36, 169], "arcsin": [7, 10, 21], "sqrt": [7, 10, 21, 26], "xy": [7, 10, 21], "feed": [7, 10, 21, 23, 26, 29], "outsid": [7, 10, 21, 23], "logsoftmax": [7, 10, 21, 29], "q2model": [7, 10, 21], "op1": [7, 10, 21, 31], "op2": [7, 10, 21, 31], "op3": [7, 10, 21], "op4": [7, 10, 21], "input_idx": [7, 10, 21, 23, 25, 26, 29], "slightli": [7, 10, 21, 29, 31], "train_2qubit": [7, 10, 21], "valid_test_2qubit": [7, 10, 21], "259": [7, 10, 15, 21, 25], "queu": [7, 10], "330": [7, 10, 15, 25], "328": [7, 10, 15], "329": [7, 10, 15], "403ea847616a": [7, 10], "a0fc95429015": [7, 10], "23e3f28ce15f": [7, 10], "f7c1624287d6": [7, 10], "transpiled_circ": [7, 10], "panda": [7, 10, 15, 21, 23, 29], "m": [7, 10, 21, 26], "qthhn8ispg631v2": [7, 10], "pth": [7, 10], "chardet": [7, 10, 15, 21, 23, 25, 26, 29], "pytz": [7, 10, 15, 21, 23, 29], "pylatexenc": [7, 10, 25, 26, 31, 34], "cu113": [7, 10], "patho": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "torchvis": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "dev20210130": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "pillow": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "fonttool": [7, 10, 15, 21, 23, 29, 31, 34], "ppft": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "pox": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "tensorpack": [7, 10, 21, 23, 25, 26, 29, 31, 34], "multimethod": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "loguru": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "pyyaml": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "googl": [7, 10, 15, 21, 23, 25, 26, 29, 31, 34], "oauthlib": [7, 10, 21, 23, 25, 26, 29, 31, 34], "werkzeug": [7, 10, 21, 23, 25, 26, 29, 31, 34], "wit": [7, 10, 21, 23, 25, 26, 29, 34], "protobuf": [7, 10, 21, 23, 25, 26, 29, 31, 34], "markdown": [7, 10, 21, 23, 25, 26, 29, 31, 34], "absl": [7, 10, 21, 23, 25, 26, 29, 31, 34], "grpcio": [7, 10, 21, 23, 25, 26, 29, 31, 34], "server": [7, 10, 21, 23, 25, 26, 29, 31, 34], "rsa": [7, 10, 21, 23, 25, 26, 29, 31, 34], "pyasn1": [7, 10, 21, 23, 25, 26, 29, 31, 34], "tabul": [7, 10, 21, 23, 25, 26, 29, 31, 34], "termcolor": [7, 10, 21, 23, 25, 26, 29, 31, 34], "msgpack": [7, 10, 21, 23, 25, 26, 29, 31, 34], "pyzmq": [7, 10, 21, 23, 25, 26, 29, 31, 34], "uc7a7f21d3297147c9998733ad57": [7, 10], "btpk9hninw6t8bv4vbn7auvyzfufjqlzslyc4emjnnwccnz2grhdyqpkvz7iqyabpeb5cahfrzhuic4cokyckq3zocpp2dw0l_1rv2djxggvzrqx9z7k": [7, 10], "zaava1u_rds92ebfztzztkdukn9": [7, 10], "n4g1ffaf27xneiqtbbyyqkqhj6vnq": [7, 10], "40f": [7, 10], "btmsrs6zzp58luhhrfa3vwxk0krxvicu3ocgsqdys8br5ayiuriq9i": [7, 10], "1l": [7, 10], "mckp6j2mi": [7, 10], "a5tevb6xfv7hmktm7": [7, 10], "_gbag": [7, 10], "jf5w56f1bm0e": [7, 10], "awag": [7, 10], "l30sdogazo3zjtpjrb1p6zrfrxgexslvo1cdwcps62ugeurbl6zdv3qiwoyw5xydvlqjvsvsccblk3xjdfiad6y2i0fsjp0q48ebyivad8jtnrskxejoo0vxxrhfu3yv4hhsiluajlmtleclghuaxotv3n8judndymbgfiyhb7oy4b1ggoe_7_ht0xpddftygruj5ok9hqtgq4vxgimhpfwx8b8cizvayutbkjrgl4wgjcsb60xgthp4quz_8lclrmh8tli4e9khcckvhrgku": [7, 10], "h2vrn6tlrt192cpf1xclt8adhm7i3iwd6fi5clnqha": [7, 10], "20137": [7, 10], "20k": [7, 10], "67k": [7, 10], "quantumcircuit": [7, 10, 15, 21], "math": [7, 10, 26, 34], "mock": [7, 10], "fakevalencia": [7, 10], "pd": [7, 10], "set_random_se": [7, 10], "manual_seed_al": [7, 10], "benchmark": [7, 10], "determinist": [7, 10], "pythonhashse": [7, 10], "deprecationwarn": [7, 10, 15, 21], "month": [7, 10], "later": [7, 10, 23], "should": [7, 10, 26, 31], "directli": [7, 10, 15, 31], "fake_provid": [7, 10], "lut_construct": [7, 10], "fixing_point": [7, 10], "logical_g": [7, 10], "head": [7, 10, 23, 25, 26], "extend": [7, 10, 28, 29, 31], "df": [7, 10], "datafram": [7, 10], "column": [7, 10], "val": [7, 10, 26], "row": [7, 10], "cry": [7, 10], "crz": [7, 10], "loc": [7, 10, 25], "test_fixing_point": [7, 10], "to_csv": [7, 10], "csv": [7, 10], "binari": [7, 10], "th": [7, 10, 25], "high": [7, 10, 15, 22, 23, 169], "low": [7, 10], "sign": [7, 10], "randomdataset": [7, 10], "feature_num": [7, 10], "normal_data": [7, 10], "randn": [7, 10], "data01": [7, 10], "14159": [7, 10], "data02": [7, 10], "data1": [7, 10], "concat": [7, 10, 26], "data2": [7, 10], "input_data": [7, 10], "shuffl": [7, 10], "weight1": [7, 10], "ones": [7, 10], "weight2": [7, 10], "weight": [7, 10, 26], "mm": [7, 10], "int64": [7, 10], "train_db": [7, 10], "2000": [7, 10], "train_load": [7, 10], "test_db": [7, 10], "test_load": [7, 10], "qlayer18": [7, 10], "layer_index": [7, 10], "rys1": [7, 10], "rxs1": [7, 10], "rzs1": [7, 10], "crys1": [7, 10], "crxs1": [7, 10], "crzs2": [7, 10], "hadmard": [7, 10], "dens": [7, 10, 25], "stateencod": [7, 10], "keepdim": [7, 10], "view_a": [7, 10], "float": [7, 10, 25, 26, 29, 32], "get_weight_from_model": [7, 10], "set_model_weight": [7, 10], "para": [7, 10], "get_fixing_points_from_lut": [7, 10], "gates_fixing_point": [7, 10], "get_model_depth": [7, 10], "q_model": [7, 10, 15], "lut_reconstrut": [7, 10], "metrics_func": [7, 10], "original_depth": [7, 10], "original_acc": [7, 10], "max_len": [7, 10], "para_acc": [7, 10], "para_depth": [7, 10], "zeros_lik": [7, 10], "para_metrics1": [7, 10], "best_fixing_point": [7, 10], "min_d_acc": [7, 10], "w2": [7, 10], "acc2": [7, 10], "depth2": [7, 10], "best_index": [7, 10], "axi": [7, 10, 31], "read_csv": [7, 10], "new_lut": [7, 10], "npy": [7, 10], "divid": [7, 10], "encount": [7, 10], "true_divid": [7, 10], "get_fixing_paramet": [7, 10], "regu_v": [7, 10], "2831853071796": [7, 10], "fixing_para": [7, 10], "get_fixing_ab": [7, 10], "fix_para": [7, 10], "fixing_ab": [7, 10], "rho": [7, 10], "admm_u": [7, 10], "admm_z": [7, 10], "init": [7, 10], "prune_ratio": [7, 10], "z": [7, 10, 25, 26, 29, 31, 34, 67, 169], "get_sensitive_fixing_paramet": [7, 10], "sensitive_fixing_paramet": [7, 10], "set_sensitive_fixing_paramet": [7, 10], "weight_prun": [7, 10], "percent": [7, 10], "weight_temp": [7, 10], "percentil": [7, 10], "percentitl": [7, 10], "under_threshold": [7, 10], "above_threshold": [7, 10], "hard_prun": [7, 10], "direct": [7, 10, 15, 21], "hard": [7, 10, 22, 23, 27], "cuda_pruned_weight": [7, 10], "spars": [7, 10], "field": [7, 10, 26], "admm_initi": [7, 10], "updated_z": [7, 10], "her": [7, 10, 34], "z_u_upd": [7, 10], "batch_idx": [7, 10], "admm_epoch": [7, 10], "z_prev": [7, 10], "equival": [7, 10, 31], "euclidean": [7, 10], "append_admm_loss": [7, 10], "ce_loss": [7, 10], "cross_entropi": [7, 10], "configur": [7, 10], "instanc": [7, 10, 25], "cross": [7, 10, 21, 56, 57], "entropi": [7, 10, 21], "scalar": [7, 10, 15, 21], "origin": [7, 10, 17, 31, 34], "enropi": [7, 10], "admm_loss": [7, 10], "dictionari": [7, 10], "ret_loss": [7, 10], "mix": [7, 10], "overal": [7, 10], "mixed_loss": [7, 10], "admm_adjust_learning_r": [7, 10], "pytorch": [7, 10, 20, 21, 23, 25, 26, 29, 31, 169], "learn": [7, 10, 15, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 34, 169], "decai": [7, 10], "For": [7, 10, 12, 21, 25, 29, 31, 34, 37, 169], "period": [7, 10, 23], "admm_epoch_offset": [7, 10], "admm_step": [7, 10], "roughli": [7, 10], "crossentropylossmaybesmooth": [7, 10], "crossentropyloss": [7, 10, 26], "smooth": [7, 10], "smooth_ep": [7, 10], "contigu": [7, 10, 25, 26], "n_class": [7, 10, 26], "one_hot": [7, 10], "smooth_one_hot": [7, 10], "log_prb": [7, 10], "averagemet": [7, 10], "averag": [7, 10, 26], "over": [7, 10, 34], "top": [7, 10], "maxk": [7, 10], "t": [7, 10, 15, 21, 23, 25, 26, 29, 31, 169], "correct_k": [7, 10], "mul_": [7, 10], "admm_flag": [7, 10], "top1": [7, 10], "idx_loss_dict": [7, 10], "switch": [7, 10], "losss": [7, 10], "acc1": [7, 10], "sgd": [7, 10, 25, 31], "mask_index": [7, 10], "device_mask": [7, 10], "infom": [7, 10], "masked_retrain": [7, 10], "rho_num": [7, 10], "cwd": [7, 10], "alia": [7, 10], "builtin": [7, 10], "silenc": [7, 10], "itself": [7, 10], "safe": [7, 10], "specif": [7, 10], "float64": [7, 9, 10], "detail": [7, 10, 16, 22, 28], "guidanc": [7, 10], "devdoc": [7, 10], "html": [7, 10, 26, 56, 57], "eta_min": [7, 10], "4e": [7, 10], "initial_rho": [7, 10], "current_rho": [7, 10], "intial": [7, 10], "best_prec1": [7, 10], "prec1": [7, 10], "4f": [7, 10, 15], "4000": [7, 10], "9000": [7, 10], "96": [7, 10, 15, 25, 31], "6000": [7, 10], "7000": [7, 10], "8000": [7, 10], "epoch_loss_dict": [7, 10], "testacc": [7, 10], "testdepth": [7, 10], "best_depth1": [7, 10], "best_metrics1": [7, 10], "temp_model": [7, 10], "deepcopi": [7, 10], "depth1": [7, 10], "prec_norm": [7, 10], "depth_norm": [7, 10], "best_model": [7, 10], "3f": [7, 10, 25, 26], "d": [7, 10, 26], "136": [7, 10, 15, 25, 31], "detect": [7, 10], "opposit": [7, 10], "failur": [7, 10], "skip": [7, 10], "doc": [7, 10], "stabl": [7, 10], "900": [7, 10], "deploy": [9, 169], "08it": 9, "0598": 9, "1426": 9, "speedup": 9, "7118": 11, "9570": 11, "2900j": 11, "7167": 11, "9625": 11, "2713j": 11, "7213": 11, "9673": 11, "2537j": 11, "7252": 11, "9712": 11, "2384j": 11, "7282": 11, "9740": 11, "2267j": 11, "7301": 11, "9756": 11, "2194j": 11, "7308": 11, "9763": 11, "2166j": 11, "7306": 11, "9761": 11, "2175j": 11, "7296": 11, "9752": 11, "2212j": 11, "9739": 11, "2268j": 11, "7265": 11, "9723": 11, "2336j": 11, "9705": 11, "2409j": 11, "7227": 11, "9687": 11, "2481j": 11, "7211": 11, "9671": 11, "2545j": 11, "7198": 11, "9657": 11, "2596j": 11, "7188": 11, "9648": 11, "2631j": 11, "7184": 11, "9643": 11, "2648j": 11, "2632j": 11, "7196": 11, "7205": 11, "9665": 11, "2566j": 11, "7216": 11, "9676": 11, "2523j": 11, "9688": 11, "2480j": 11, "7238": 11, "9698": 11, "2440j": 11, "2383j": 11, "7256": 11, "9715": 11, "2370j": 11, "2369j": 11, "7254": 11, "9713": 11, "2378j": 11, "7249": 11, "9709": 11, "2395j": 11, "7243": [11, 15], "9703": 11, "2419j": 11, "7236": 11, "9696": 11, "2446j": 11, "7229": 11, "9689": 11, "2473j": 11, "7223": 11, "9683": 11, "2499j": 11, "7217": 11, "9678": 11, "2519j": 11, "7214": 11, "9674": 11, "2533j": 11, "7212": 11, "9672": 11, "2539j": 11, "2538j": 11, "7215": 11, "9675": 11, "2530j": 11, "7218": 11, "2516j": 11, "7222": 11, "7232": 11, "9692": 11, "2464j": 11, "7235": 11, "9695": 11, "2449j": 11, "2439j": 11, "7239": 11, "2433j": 11, "2438j": 11, "2447j": 11, "7233": 11, "9693": 11, "2458j": 11, "7230": 11, "9690": 11, "2470j": 11, "2482j": 11, "9685": 11, "2491j": 11, "2498j": 11, "9682": 11, "2500j": 11, "9684": 11, "2496j": 11, "2489j": 11, "7231": 11, "9691": 11, "2466j": 11, "2461j": 11, "2457j": 11, "9694": 11, "2459j": 11, "2462j": 11, "2467j": 11, "7228": 11, "2478j": 11, "7226": 11, "2485j": 11, "2486j": 11, "2484j": 11, "2479j": 11, "2475j": 11, "2471j": 11, "2468j": 11, "2469j": 11, "2474j": 11, "2476j": 11, "2477j": 11, "2472j": 11, "0x7fdcc3522e50": 11, "pulse_q0": 11, "pulse_q1": 11, "pulse_q01": 11, "u_0": 11, "u_1": 11, "u_01": 11, "overall_u": 11, "kron": 11, "8438": 11, "5907": 11, "3830j": 11, "2483": 11, "2220j": 11, "4967": 11, "1610j": 11, "3424": 11, "7660j": 11, "7897": 11, "6477": 11, "3753j": 11, "2175": 11, "2493j": 11, "4350": 11, "1261j": 11, "4302": 11, "7507j": 11, "7257": 11, "7031": 11, "3618j": 11, "1861": 11, "3617j": 11, "2660j": 11, "3723": 11, "0958j": 11, "5169": 11, "7235j": 11, "6526": 11, "7560": 11, "3424j": 11, "1550": 11, "3422j": 11, "2721j": 11, "3099": 11, "1549": 11, "0701j": 11, "6011": 11, "6846j": 11, "5722": 11, "8058": 11, "3173j": 11, "1248": 11, "3169j": 11, "2679j": 11, "2495": 11, "3170j": 11, "1247": 11, "0491j": 11, "6810": 11, "6342j": 11, "4868": 11, "8516": 11, "2866j": 11, "0963": 11, "2862j": 11, "1925": 11, "2863j": 11, "0962": 11, "0324j": 11, "7552": 11, "5728j": 11, "3992": 11, "8925": 11, "2508j": 11, "0704": 11, "2503j": 11, "2307j": 11, "1406": 11, "2504j": 11, "0702": [11, 15], "0197j": 11, "8221": 11, "5012j": 11, "3131": 11, "9277": 11, "2104j": 11, "0476": 11, "2100j": 11, "1993j": 11, "0952": 11, "2101j": 11, "0475": 11, "0108j": 11, "8801": 11, "4204j": 11, "2321": 11, "1660j": 11, "0288": 11, "1658j": 11, "1611j": 11, "0576": 11, "1661j": 11, "0050j": 11, "3319j": 11, "1604": 11, "9782": 11, "1187j": 11, "0144": 11, "1189j": 11, "1177j": 11, "0290": 11, "0145": 11, "1195j": 11, "0018j": 11, "9638": 11, "2375j": 11, "1014": 11, "9925": 11, "0694j": 11, "0049": 11, "0703j": 11, "0715j": 11, "0101": 11, "0050": 11, "0719j": 11, "0051": 11, "0004j": 11, "1397j": 11, "0577": 11, "9926e": 11, "9636e": 11, "02j": 11, "2157e": 11, "1453e": 11, "0000e": 11, "5184e": 11, "0360e": 11, "00j": 11, "9509e": 11, "5194e": 11, "4090e": 11, "0629e": 11, "05j": 11, "9884e": 11, "1089e": 11, "0304": 11, "9907e": 11, "9175e": 11, "6065e": 11, "6047e": 11, "8290e": 11, "0118e": 11, "3453e": 11, "8304e": 11, "7723e": 11, "3936e": 11, "9831e": 11, "5223e": 11, "0187": 11, "9930": 11, "0755j": 11, "0054": 11, "0707j": 11, "0560j": 11, "0083": 11, "0043": 11, "0563j": 11, "0040": 11, "0003j": 11, "1462j": 11, "0198": [11, 15], "9828": 11, "1181j": 11, "0133": 11, "1111j": 11, "0856j": 11, "0202": [11, 15], "0104": 11, "0867j": 11, "0012j": 11, "2292j": 11, "0296": 11, "1557j": 11, "0235": 11, "1463j": 11, "1061j": 11, "0338": 11, "0174": 11, "1087j": 11, "0164": 11, "0026j": 11, "9468": 11, "3021j": 11, "0439": 11, "9574": 11, "1879j": 11, "0345": 11, "1757j": 11, "0464": 11, "0240": 11, "1221j": 11, "0224": [11, 15], "0044j": 11, "9229": 11, "3636j": 11, "0588": 11, "9458": 11, "2144j": 11, "0451": 11, "1990j": 11, "1216j": 11, "0558": 11, "0289": 11, "1277j": 11, "0269": 11, "0061j": 11, "9007": 11, "4133j": 11, "0716": 11, "9365": 11, "2351j": 11, "0543": 11, "2163j": 11, "0611": 11, "0318": 11, "1268j": 11, "0293": 11, "0074j": 11, "8822": 11, "4514j": 11, "0805": 11, "9301": 11, "2502j": 11, "0613": 11, "2280j": 11, "1127j": 11, "0620": 11, "0325": 11, "1206j": 11, "0080j": 11, "8688": 11, "4782j": 11, "0847": 11, "9269": 11, "2602j": 11, "0658": 11, "2344j": 11, "1024j": 11, "0310": 11, "1103j": 11, "0279": 11, "0078j": 11, "4946j": 11, "0843": 11, "9266": 11, "2653j": 11, "0676": 11, "2361j": 11, "0896j": 11, "0523": 11, "0277": 11, "0967j": 11, "0246": 11, "0071j": 11, "8590": 11, "5014j": 11, "0798": 11, "9289": 11, "0668": 11, "2334j": 11, "0748j": 11, "0433": 11, "0231": 11, "0806j": 11, "0203": 11, "0058j": 11, "8620": 11, "4994j": 11, "0721": 11, "9333": 11, "2627j": 11, "0638": 11, "0585j": 11, "0329": 11, "0177": 11, "0628j": 11, "0153": 11, "0043j": 11, "8694": 11, "4895j": 11, "0625": 11, "9391": 11, "2558j": 11, "0590": 11, "0412j": 11, "0221": 11, "0120": 11, "0440j": 11, "0028j": 11, "4724j": 11, "0519": 11, "9459": 11, "0529": 11, "2035j": 11, "0234j": 11, "0118": 11, "0064": 11, "0248j": 11, "0053": 11, "0014j": 11, "8930": 11, "4492j": 11, "0416": [11, 15], "9530": 11, "3294e": 11, "01j": 11, "0459": 11, "8789e": 11, "6513e": 11, "03j": 11, "0026": 11, "0015": 11, "9374e": 11, "0012": 11, "8610e": 11, "04j": 11, "9071": 11, "2083e": 11, "9601": 11, "2181j": 11, "0387": 11, "1703j": 11, "0113j": 11, "0027": 11, "0117j": 11, "0021": 11, "0005j": 11, "9214": 11, "3884j": 11, "0250": 11, "9667": 11, "2017j": 11, "0316": 11, "1514j": 11, "0266j": 11, "0057": 11, "0275j": 11, "0009j": 11, "9351": 11, "3532j": 11, "0197": 11, "1846j": 11, "1318j": 11, "0397j": 11, "0132": 11, "0077": 11, "0407j": 11, "0055": 11, "0010j": 11, "9477": 11, "3164j": 11, "9780": 11, "1672j": 11, "0192": 11, "1121j": 11, "0499j": 11, "0087": 11, "0509j": 11, "0058": 11, "9588": 11, "2793j": 11, "0150": 11, "9824": 11, "1504j": 11, "0142": 11, "0929j": 11, "0568j": 11, "0143": 11, "0088": 11, "0577j": 11, "0008j": 11, "0151": 11, "9861": 11, "1346j": 11, "0102": 11, "0749j": 11, "0603j": 11, "0130": 11, "0610j": 11, "0046": 11, "0006j": 11, "9759": 11, "2095j": 11, "0162": 11, "9891": 11, "1204j": 11, "0071": 11, "0605j": 11, "0110": 11, "0074": 11, "0609j": 11, "0036": 11, "9819": 11, "1790j": 11, "0179": 11, "9914": 11, "1083j": 11, "0048": 11, "0442j": 11, "0574j": 11, "0089": 11, "0063": 11, "9866": 11, "1526j": 11, "0986j": 11, "0517j": 11, "0068": 11, "0519j": 11, "0017": 11, "0002j": 11, "1310j": 11, "0212": 11, "1446e": 11, "3124e": 11, "3808e": 11, "3902e": 11, "0010": 11, "3855e": 11, "1457e": 11, "0222": 11, "9547e": 11, "6981e": 11, "4525e": 11, "6623e": 11, "4336e": 11, "5788e": 11, "0045e": 11, "4386e": 11, "7420e": 11, "0172e": 11, "9402e": 11, "0226": 11, "9599e": 11, "5175e": 11, "0987e": 11, "2848e": 11, "3915e": 11, "3563e": 11, "0474e": 11, "3942e": 11, "0884e": 11, "6411e": 11, "9489e": 11, "8023e": 11, "0223": 11, "9614e": 11, "5903e": 11, "0081e": 11, "1690e": 11, "3168e": 11, "2914e": 11, "1367e": 11, "3182e": 11, "5469e": 11, "3340e": 11, "9514e": 11, "7592e": 11, "0215": 11, "9595e": 11, "8953e": 11, "1566e": 11, "2950e": 11, "6917e": 11, "7573e": 11, "4069e": 11, "6949e": 11, "5040e": 11, "1296e": 11, "06j": 11, "9479e": 11, "0190e": 11, "9541e": 11, "4041e": 11, "5451e": 11, "6355e": 11, "9752e": 11, "7479e": 11, "6001e": 11, "9860e": 11, "1478e": 11, "0844e": 11, "9386e": 11, "1040e": 11, "0186": 11, "9455e": 11, "0083e": 11, "1874e": 11, "1576e": 11, "5369e": 11, "8957e": 11, "5615e": 11, "5403e": 11, "3416e": 11, "3877e": 11, "9236e": 11, "2240e": 11, "0169": 11, "9339e": 11, "0893e": 11, "0971e": 11, "8244e": 11, "2127e": 11, "0650e": 11, "4340e": 11, "2196e": 11, "3107e": 11, "9201e": 11, "9029e": 11, "3718e": 11, "0154": 11, "9198e": 11, "1796e": 11, "2766e": 11, "5965e": 11, "7004e": 11, "2250e": 11, "7121e": 11, "8330e": 11, "1692e": 11, "8770e": 11, "5392e": 11, "0140": 11, "9904": 11, "1275j": 11, "0443j": 11, "0299j": 11, "0052": 11, "0039": 11, "0301j": 11, "0013": 11, "9847": 11, "1718j": 11, "9886": 11, "1371j": 11, "0073": 11, "0530j": 11, "0308j": 11, "0060": 11, "0310j": 11, "9813": 11, "1901j": 11, "0123": 11, "9868": 11, "1465j": 11, "0091": 11, "0615j": 11, "0298j": 11, "0045": 11, "0019": 11, "9776": 11, "2080j": 11, "1553j": 11, "0696j": 11, "0272j": 11, "2249j": 11, "9832": 11, "1631j": 11, "0128": 11, "0770j": 11, "0233j": 11, "0236j": 11, "0018": 11, "9704": 11, "2401j": 11, "0122": 11, "9816": 11, "1699j": 11, "0834j": 11, "0184j": 11, "0187j": 11, "0016": 11, "0125": [11, 15], "9803": 11, "7527e": 11, "0159": 11, "8653e": 11, "2877e": 11, "0035": 11, "0023": 11, "3089e": 11, "1163e": 11, "9645": 11, "6392e": 11, "0129": 11, "7926e": 11, "7924e": 11, "6961e": 11, "2665e": 11, "1362e": 11, "0164e": 11, "3292e": 11, "2620e": 11, "8719e": 11, "2578e": 11, "6229e": 11, "7190e": 11, "7855e": 11, "8174e": 11, "7712e": 11, "5370e": 11, "5152e": 11, "3699e": 11, "8660e": 11, "5431e": 11, "7932e": 11, "6084e": 11, "7711e": 11, "0135": 11, "7820e": 11, "8278e": 11, "8083e": 11, "6776e": 11, "6701e": 11, "0686e": 11, "9869e": 11, "7392e": 11, "6993e": 11, "9124e": 11, "6012e": 11, "7956e": 11, "7822e": 11, "8245e": 11, "8081e": 11, "6942e": 11, "1538e": 11, "3727e": 11, "5494e": 11, "3074e": 11, "2326e": 11, "5355e": 11, "6014e": 11, "7939e": 11, "0134": 11, "9786": 11, "8086e": 11, "5972e": 11, "1729e": 11, "0034": 11, "0022": 11, "1945e": 11, "1652e": 11, "9608": 11, "7684e": 11, "0131": 11, "7819e": 11, "0171": 11, "4013e": 11, "4255e": 11, "4508e": 11, "0014": 11, "5346e": 11, "9621": 11, "7220e": 11, "9801": 11, "7462e": 11, "0163": 11, "1238e": 11, "5663e": 11, "0028": 11, "5928e": 11, "6415e": 11, "9639": 11, "6586e": 11, "9812": [11, 15], "7037e": 11, "7845e": 11, "5957e": 11, "6209e": 11, "5197e": 11, "9659": 11, "5822e": 11, "0119": 11, "6568e": 11, "5204e": 11, "5427e": 11, "2258e": 11, "4972e": 11, "0116": 11, "9836": 11, "6077e": 11, "0039e": 11, "3537e": 11, "3719e": 11, "0011": 11, "8249e": 11, "4081e": 11, "0114": 11, "8471e": 11, "5587e": 11, "2037e": 11, "6044e": 11, "1135e": 11, "6548e": 11, "7843e": 11, "1273e": 11, "7052e": 11, "3779e": 11, "7267e": 11, "3191e": 11, "0113": 11, "8576e": 11, "5118e": 11, "1080e": 11, "2248e": 11, "2128e": 11, "8826e": 11, "2738e": 11, "3061e": 11, "0876e": 11, "3361e": 11, "7468e": 11, "2343e": 11, "8669e": 11, "4689e": 11, "0245e": 11, "8818e": 11, "0067e": 11, "1060e": 11, "5318e": 11, "0592e": 11, "5286e": 11, "2531e": 11, "7644e": 11, "1571e": 11, "8746e": 11, "4316e": 11, "5532e": 11, "5896e": 11, "7536e": 11, "7487e": 11, "5671e": 11, "7707e": 11, "1816e": 11, "7131e": 11, "7790e": 11, "0905e": 11, "0115": 11, "8805e": 11, "4009e": 11, "0153e": 11, "3585e": 11, "3232e": 11, "8934e": 11, "3354e": 11, "5937e": 11, "2184e": 11, "7904e": 11, "0367e": 11, "8848e": 11, "3777e": 11, "6348e": 11, "1954e": 11, "0301e": 11, "2145e": 11, "6664e": 11, "0656e": 11, "5481e": 11, "5515e": 11, "7984e": 11, "9972e": 11, "0117": 11, "8874e": 11, "3623e": 11, "4092e": 11, "1034e": 11, "2106e": 11, "2497e": 11, "6304e": 11, "2639e": 11, "8666e": 11, "3274e": 11, "8033e": 11, "9726e": 11, "8885e": 11, "3547e": 11, "3314e": 11, "0815e": 11, "7607e": 11, "5535e": 11, "0722e": 11, "8266e": 11, "8135e": 11, "5942e": 11, "8052e": 11, "9628e": 11, "8882e": 11, "3544e": 11, "3908e": 11, "1258e": 11, "6259e": 11, "7306e": 11, "1916e": 11, "6997e": 11, "3896e": 11, "3823e": 11, "8042e": 11, "9670e": 11, "8866e": 11, "3608e": 11, "5740e": 11, "2291e": 11, "8060e": 11, "7824e": 11, "2227e": 11, "8830e": 11, "5968e": 11, "8009e": 11, "9837e": 11, "8840e": 11, "3729e": 11, "8647e": 11, "3820e": 11, "3477e": 11, "7139e": 11, "1700e": 11, "4232e": 11, "4388e": 11, "5546e": 11, "7953e": 11, "0111e": 11, "8804e": 11, "3895e": 11, "2438e": 11, "5730e": 11, "3411e": 11, "5351e": 11, "0421e": 11, "4105e": 11, "9299e": 11, "9329e": 11, "7880e": 11, "0468e": 11, "8762e": 11, "4093e": 11, "6891e": 11, "7900e": 11, "9058e": 11, "2611e": 11, "5108e": 11, "9643e": 11, "1005e": 11, "8513e": 11, "7793e": 11, "0883e": 11, "8715e": 11, "4310e": 11, "0177e": 11, "0203e": 11, "1827e": 11, "1320e": 11, "1264e": 11, "2263e": 11, "0056e": 11, "3569e": 11, "7698e": 11, "1330e": 11, "0112": 11, "4532e": 11, "0681e": 11, "2515e": 11, "3222e": 11, "1831e": 11, "4578e": 11, "3476e": 11, "7254e": 11, "5413e": 11, "7598e": 11, "1784e": 11, "8617e": 11, "4749e": 11, "1175e": 11, "4723e": 11, "7044e": 11, "1162e": 11, "7583e": 11, "6054e": 11, "3920e": 11, "7500e": 11, "2221e": 11, "8571e": 11, "4948e": 11, "1635e": 11, "6725e": 11, "2387e": 11, "8765e": 11, "9008e": 11, "2535e": 11, "7566e": 11, "4795e": 11, "7408e": 11, "8531e": 11, "5121e": 11, "2038e": 11, "8440e": 11, "6927e": 11, "3536e": 11, "1834e": 11, "7260e": 11, "1701e": 11, "3304e": 11, "7327e": 11, "2965e": 11, "8497e": 11, "5262e": 11, "2366e": 11, "9807e": 11, "8084e": 11, "1011e": 11, "9761e": 11, "8569e": 11, "1250e": 11, "8421e": 11, "7261e": 11, "3242e": 11, "8472e": 11, "5365e": 11, "2606e": 11, "0786e": 11, "5340e": 11, "0934e": 11, "1664e": 11, "7678e": 11, "8793e": 11, "7212e": 11, "3444e": 11, "8457e": 11, "5430e": 11, "2751e": 11, "1361e": 11, "8506e": 11, "1762e": 11, "7015e": 11, "9142e": 11, "0609e": 11, "3642e": 11, "7182e": 11, "3566e": 11, "8452e": 11, "5456e": 11, "2801e": 11, "7713e": 11, "1593e": 11, "5891e": 11, "8341e": 11, "0036e": 11, "2853e": 11, "7172e": 11, "3610e": 11, "8455e": 11, "5445e": 11, "2760e": 11, "1341e": 11, "3365e": 11, "0522e": 11, "8922e": 11, "3934e": 11, "6298e": 11, "7179e": 11, "3579e": 11, "8467e": 11, "5402e": 11, "2640e": 11, "0813e": 11, "6118e": 11, "7257e": 11, "7229e": 11, "6588e": 11, "0028e": 11, "6968e": 11, "7203e": 11, "3483e": 11, "8485e": 11, "5331e": 11, "2455e": 11, "0007e": 11, "6767e": 11, "4227e": 11, "2203e": 11, "7110e": 11, "2024e": 11, "4285e": 11, "7240e": 11, "3332e": 11, "8508e": 11, "5240e": 11, "8990e": 11, "6227e": 11, "8596e": 11, "5420e": 11, "6431e": 11, "3175e": 11, "0384e": 11, "7286e": 11, "3139e": 11, "8534e": 11, "5136e": 11, "1956e": 11, "7833e": 11, "4137e": 11, "2747e": 11, "4179e": 11, "4802e": 11, "3289e": 11, "6494e": 11, "7338e": 11, "2919e": 11, "8561e": 11, "5024e": 11, "1678e": 11, "6608e": 11, "8202e": 11, "1228e": 11, "4360e": 11, "8780e": 11, "7915e": 11, "7797e": 11, "7393e": 11, "2685e": 11, "8587e": 11, "4914e": 11, "1404e": 11, "5384e": 11, "3710e": 11, "1588e": 11, "0983e": 11, "3870e": 11, "0606e": 11, "7447e": 11, "2452e": 11, "8612e": 11, "4811e": 11, "1148e": 11, "0680e": 11, "7159e": 11, "1415e": 11, "0916e": 11, "5744e": 11, "3646e": 11, "7497e": 11, "2233e": 11, "8633e": 11, "4720e": 11, "0923e": 11, "3190e": 11, "8240e": 11, "5624e": 11, "9014e": 11, "8376e": 11, "7541e": 11, "2039e": 11, "8651e": 11, "4646e": 11, "0736e": 11, "2318e": 11, "7528e": 11, "1720e": 11, "1318e": 11, "7831e": 11, "0402e": 11, "0289e": 11, "7577e": 11, "1878e": 11, "8664e": 11, "4592e": 11, "0595e": 11, "1641e": 11, "7281e": 11, "0810e": 11, "7578e": 11, "0025e": 11, "9615e": 11, "7604e": 11, "1756e": 11, "8672e": 11, "4559e": 11, "0503e": 11, "1179e": 11, "4842e": 11, "5163e": 11, "7050e": 11, "5109e": 11, "8113e": 11, "6727e": 11, "7622e": 11, "1677e": 11, "8676e": 11, "4549e": 11, "0459e": 11, "0608e": 11, "5684e": 11, "0710e": 11, "0829e": 11, "4973e": 11, "2077e": 11, "7630e": 11, "1642e": 11, "8674e": 11, "0461e": 11, "0898e": 11, "5077e": 11, "3433e": 11, "2484e": 11, "5239e": 11, "0949e": 11, "6155e": 11, "7628e": 11, "1649e": 11, "4588e": 11, "0505e": 11, "1051e": 11, "8357e": 11, "9635e": 11, "3204e": 11, "9308e": 11, "4311e": 11, "5082e": 11, "7619e": 11, "1693e": 11, "4632e": 11, "0584e": 11, "1366e": 11, "4500e": 11, "6731e": 11, "4766e": 11, "6570e": 11, "7602e": 11, "1769e": 11, "0x7fdcc36be710": 11, "0085": 11, "8648e": 11, "0692e": 11, "1807e": 11, "5304e": 11, "3144e": 11, "5691e": 11, "5980e": 11, "8684e": 11, "7579e": 11, "1869e": 11, "9937": 11, "7513e": 11, "2524e": 11, "9257e": 11, "9367e": 11, "0980e": 11, "2004e": 11, "9242e": 11, "1379e": 11, "0743e": 11, "4256e": 11, "2517e": 11, "4425e": 11, "2581e": 11, "6106e": 11, "4329e": 11, "8735e": 11, "5804e": 11, "0086": 11, "9878": 11, "1363j": 11, "0099": 11, "0224j": 11, "0031": 11, "0227j": 11, "9779": 11, "2079j": 11, "0107": 11, "1461j": 11, "0860j": 11, "0366j": 11, "0371j": 11, "9720": 11, "2320j": 11, "9860": 11, "1401j": 11, "0837j": 11, "0319j": 11, "0323j": 11, "9741": 11, "2239j": 11, "0082": 11, "9892": 11, "2601e": 11, "0092": 11, "2174e": 11, "7145e": 11, "6085e": 11, "9818e": 11, "0080": 11, "9206e": 11, "1110e": 11, "5652e": 11, "8621e": 11, "1941e": 11, "0566e": 11, "3462e": 11, "2021e": 11, "1032e": 11, "9551e": 11, "8549e": 11, "6972e": 11, "9331e": 11, "0263e": 11, "9799e": 11, "7105e": 11, "6385e": 11, "7765e": 11, "7194e": 11, "6201e": 11, "9065e": 11, "8816e": 11, "5243e": 11, "9931": 11, "0359e": 11, "9009e": 11, "5564e": 11, "5696e": 11, "3229e": 11, "9879": 11, "5260e": 11, "9919": 11, "1189e": 11, "4843e": 11, "5200e": 11, "0029": 11, "5358e": 11, "5817e": 11, "9857": 11, "6673e": 11, "9901": 11, "2348e": 11, "0079": 11, "3657e": 11, "7999e": 11, "4433e": 11, "9822": 11, "8714e": 11, "8837e": 11, "3383e": 11, "6427e": 11, "1214e": 11, "5866e": 11, "3799e": 11, "0065e": 11, "6515e": 11, "7925e": 11, "4893e": 11, "7873e": 11, "0504e": 11, "8742e": 11, "3919e": 11, "0452e": 11, "4148e": 11, "2672e": 11, "1502e": 11, "5045e": 11, "3236e": 11, "9976e": 11, "6354e": 11, "7696e": 11, "1334e": 11, "0084": 11, "3842e": 11, "0100": 11, "1558e": 11, "4521e": 11, "4670e": 11, "4897e": 11, "0998e": 11, "9888": 11, "3293e": 11, "4910e": 11, "8901e": 11, "0038": 11, "9069e": 11, "6830e": 11, "9784e": 11, "9903": 11, "2550e": 11, "0072": 11, "6998e": 11, "7773e": 11, "0033": 11, "3060e": 11, "9830": 11, "8250e": 11, "9146e": 11, "1927e": 11, "1332e": 11, "0981e": 11, "2066e": 11, "0849e": 11, "4606e": 11, "2141e": 11, "2430e": 11, "5105e": 11, "8532e": 11, "7026e": 11, "9193e": 11, "1663e": 11, "9156e": 11, "7168e": 11, "3957e": 11, "7385e": 11, "8527e": 11, "1783e": 11, "8615e": 11, "6579e": 11, "9161e": 11, "1814e": 11, "1851e": 11, "1915e": 11, "8586e": 11, "3844e": 11, "8248e": 11, "8891e": 11, "5596e": 11, "0495e": 11, "8542e": 11, "7005e": 11, "9068e": 11, "2259e": 11, "1604e": 11, "7865e": 11, "1319e": 11, "0768e": 11, "4109e": 11, "1401e": 11, "6595e": 11, "2407e": 11, "8352e": 11, "8045e": 11, "2773e": 11, "3371e": 11, "4084e": 11, "8333e": 11, "4204e": 11, "2710e": 11, "1966e": 11, "8123e": 11, "9232e": 11, "8879e": 11, "3116e": 11, "2264e": 11, "9555e": 11, "2783e": 11, "6192e": 11, "7116e": 11, "2903e": 11, "0766e": 11, "2040e": 11, "0072e": 11, "8870e": 11, "4482e": 11, "1096e": 11, "1794e": 11, "6913e": 11, "0975e": 11, "2583e": 11, "9385e": 11, "8918e": 11, "0249e": 11, "8927e": 11, "2840e": 11, "9663e": 11, "9084e": 11, "5920e": 11, "7994e": 11, "2566e": 11, "6309e": 11, "8030e": 11, "9748e": 11, "0078": 11, "9018e": 11, "2351e": 11, "0804e": 11, "4778e": 11, "5491e": 11, "7217e": 11, "5865e": 11, "0005e": 11, "7428e": 11, "8210e": 11, "8829e": 11, "9102e": 11, "1882e": 11, "2178e": 11, "0200e": 11, "0642e": 11, "0947e": 11, "1307e": 11, "5465e": 11, "6500e": 11, "8380e": 11, "7902e": 11, "9148e": 11, "1627e": 11, "7201e": 11, "0620e": 11, "8718e": 11, "2538e": 11, "1799e": 11, "2470e": 11, "8476e": 11, "7357e": 11, "9144e": 11, "1684e": 11, "7336e": 11, "0226e": 11, "5941e": 11, "0705e": 11, "0843e": 11, "2355e": 11, "1698e": 11, "7398e": 11, "9094e": 11, "2013e": 11, "2053e": 11, "9434e": 11, "0022e": 11, "1308e": 11, "1086e": 11, "0388e": 11, "0222e": 11, "6638e": 11, "8373e": 11, "7957e": 11, "9017e": 11, "2468e": 11, "9155e": 11, "2861e": 11, "6474e": 11, "6511e": 11, "0977e": 11, "7171e": 11, "5341e": 11, "9685e": 11, "07j": 11, "8226e": 11, "8754e": 11, "8947e": 11, "2860e": 11, "5683e": 11, "6840e": 11, "2769e": 11, "1406e": 11, "7248e": 11, "1364e": 11, "0762e": 11, "8093e": 11, "9428e": 11, "8916e": 11, "3039e": 11, "7725e": 11, "6549e": 11, "4846e": 11, "5035e": 11, "9544e": 11, "0805e": 11, "8039e": 11, "9694e": 11, "8936e": 11, "2961e": 11, "5103e": 11, "8105e": 11, "5505e": 11, "0321e": 11, "8784e": 11, "1843e": 11, "9471e": 11, "8992e": 11, "2693e": 11, "9600e": 11, "2079e": 11, "7688e": 11, "1104e": 11, "4570e": 11, "8156e": 11, "6470e": 11, "6763e": 11, "8196e": 11, "9053e": 11, "2379e": 11, "3618e": 11, "8909e": 11, "1602e": 11, "0141e": 11, "7198e": 11, "1764e": 11, "2943e": 11, "6175e": 11, "8317e": 11, "8269e": 11, "9090e": 11, "2166e": 11, "0052e": 11, "7057e": 11, "7946e": 11, "2597e": 11, "2190e": 11, "8074e": 11, "0407e": 11, "2777e": 11, "8390e": 11, "7872e": 11, "9091e": 11, "2142e": 11, "0230e": 11, "7317e": 11, "8402e": 11, "7928e": 11, "9731e": 11, "8748e": 11, "8197e": 11, "4550e": 11, "8388e": 11, "9059e": 11, "2292e": 11, "3802e": 11, "9474e": 11, "0907e": 11, "1299e": 11, "6147e": 11, "6842e": 11, "5718e": 11, "8321e": 11, "9012e": 11, "2520e": 11, "8977e": 11, "2459e": 11, "2992e": 11, "0124e": 11, "7545e": 11, "3418e": 11, "3697e": 11, "2609e": 11, "8222e": 11, "8766e": 11, "8974e": 11, "2695e": 11, "3240e": 11, "8926e": 11, "6543e": 11, "7416e": 11, "9171e": 11, "9127e": 11, "4533e": 11, "8142e": 11, "9185e": 11, "8965e": 11, "2724e": 11, "4555e": 11, "5765e": 11, "2610e": 11, "4475e": 11, "9320e": 11, "2805e": 11, "5154e": 11, "9484e": 11, "8120e": 11, "9301e": 11, "8988e": 11, "2593e": 11, "4867e": 11, "9899e": 11, "8116e": 11, "8358e": 11, "0151e": 11, "9758e": 11, "8162e": 11, "9080e": 11, "9028e": 11, "2372e": 11, "8525e": 11, "5218e": 11, "5874e": 11, "6945e": 11, "5580e": 11, "8929e": 11, "6143e": 11, "8243e": 11, "8657e": 11, "9066e": 11, "2175e": 11, "4776e": 11, "0845e": 11, "4110e": 11, "1920e": 11, "4621e": 11, "4446e": 11, "7298e": 11, "3548e": 11, "8318e": 11, "8259e": 11, "9082e": 11, "2100e": 11, "3083e": 11, "9847e": 11, "8268e": 11, "1978e": 11, "4777e": 11, "8478e": 11, "1006e": 11, "8351e": 11, "9070e": 11, "2180e": 11, "4063e": 11, "0240e": 11, "2644e": 11, "8949e": 11, "2824e": 11, "6125e": 11, "2120e": 11, "8329e": 11, "8204e": 11, "9037e": 11, "2371e": 11, "6992e": 11, "1638e": 11, "9006e": 11, "5848e": 11, "3926e": 11, "1922e": 11, "4891e": 11, "8267e": 11, "9001e": 11, "2573e": 11, "0199e": 11, "3149e": 11, "3557e": 11, "4546e": 11, "2966e": 11, "3831e": 11, "1580e": 11, "7406e": 11, "8199e": 11, "8888e": 11, "8981e": 11, "2691e": 11, "1912e": 11, "3884e": 11, "5053e": 11, "8131e": 11, "5319e": 11, "5345e": 11, "2812e": 11, "9250e": 11, "8986e": 11, "2679e": 11, "1263e": 11, "3443e": 11, "4065e": 11, "6632e": 11, "4265e": 11, "5552e": 11, "9920e": 11, "9023e": 11, "9010e": 11, "2560e": 11, "2101e": 11, "5229e": 11, "0554e": 11, "0624e": 11, "5672e": 11, "4918e": 11, "4297e": 11, "9038e": 11, "2411e": 11, "5974e": 11, "3327e": 11, "5051e": 11, "3430e": 11, "2207e": 11, "0302e": 11, "8279e": 11, "8474e": 11, "9055e": 11, "2316e": 11, "4385e": 11, "9827e": 11, "5631e": 11, "2109e": 11, "5825e": 11, "5598e": 11, "9393e": 11, "8311e": 11, "8299e": 11, "4763e": 11, "7422e": 11, "1131e": 11, "4362e": 11, "6769e": 11, "0855e": 11, "8305e": 11, "9035e": 11, "2404e": 11, "1294e": 11, "5678e": 11, "3879e": 11, "1800e": 11, "4779e": 11, "8533e": 11, "9013e": 11, "2509e": 11, "9197e": 11, "2686e": 11, "1622e": 11, "9573e": 11, "3009e": 11, "1958e": 11, "6564e": 11, "3560e": 11, "8221e": 11, "8778e": 11, "9000e": 11, "2567e": 11, "0678e": 11, "3558e": 11, "0784e": 11, "0781e": 11, "3801e": 11, "0872e": 11, "9801e": 11, "8602e": 11, "8193e": 11, "9004e": 11, "2540e": 11, "0454e": 11, "3518e": 11, "0273e": 11, "9003e": 11, "5889e": 11, "0440e": 11, "3113e": 11, "6610e": 11, "8892e": 11, "9021e": 11, "2447e": 11, "8825e": 11, "2707e": 11, "1147e": 11, "0294e": 11, "6795e": 11, "1316e": 11, "3499e": 11, "6969e": 11, "8232e": 11, "9040e": 11, "2344e": 11, "6879e": 11, "1681e": 11, "3797e": 11, "5991e": 11, "7331e": 11, "3905e": 11, "6598e": 11, "0793e": 11, "8271e": 11, "8512e": 11, "9051e": 11, "5769e": 11, "1054e": 11, "7611e": 11, "2964e": 11, "2025e": 11, "7747e": 11, "0939e": 11, "3576e": 11, "8293e": 11, "8398e": 11, "9047e": 11, "2320e": 11, "6049e": 11, "1138e": 11, "9270e": 11, "1275e": 11, "6221e": 11, "8286e": 11, "8434e": 11, "9031e": 11, "2409e": 11, "7421e": 11, "6492e": 11, "1200e": 11, "6622e": 11, "0371e": 11, "2995e": 11, "8257e": 11, "8588e": 11, "2507e": 11, "8961e": 11, "2512e": 11, "5953e": 11, "0466e": 11, "0313e": 11, "6081e": 11, "8225e": 11, "8758e": 11, "2559e": 11, "9697e": 11, "2827e": 11, "0741e": 11, "7409e": 11, "8050e": 11, "3637e": 11, "8209e": 11, "8842e": 11, "2543e": 11, "9224e": 11, "2536e": 11, "3218e": 11, "5926e": 11, "0627e": 11, "3889e": 11, "2986e": 11, "7125e": 11, "8217e": 11, "8797e": 11, "9022e": 11, "2478e": 11, "1839e": 11, "4781e": 11, "8004e": 11, "5533e": 11, "9660e": 11, "5179e": 11, "8662e": 11, "6672e": 11, "1190e": 11, "3439e": 11, "5339e": 11, "6971e": 11, "3681e": 11, "0485e": 11, "8528e": 11, "6235e": 11, "0993e": 11, "1471e": 11, "1568e": 11, "4449e": 11, "1560e": 11, "1191e": 11, "8983e": 11, "2400e": 11, "6822e": 11, "1354e": 11, "9186e": 11, "2067e": 11, "9570e": 11, "0709e": 11, "8536e": 11, "9025e": 11, "2451e": 11, "7995e": 11, "2029e": 11, "0925e": 11, "1170e": 11, "9525e": 11, "4551e": 11, "8654e": 11, "9016e": 11, "2493e": 11, "2600e": 11, "0394e": 11, "7258e": 11, "1497e": 11, "1121e": 11, "7608e": 11, "8753e": 11, "2496e": 11, "9183e": 11, "2745e": 11, "0586e": 11, "0229e": 11, "3467e": 11, "0671e": 11, "7623e": 11, "8223e": 11, "2458e": 11, "8546e": 11, "2434e": 11, "4518e": 11, "4186e": 11, "4498e": 11, "5113e": 11, "7360e": 11, "9582e": 11, "8236e": 11, "8701e": 11, "2406e": 11, "7570e": 11, "1923e": 11, "3947e": 11, "6399e": 11, "7610e": 11, "4057e": 11, "7898e": 11, "8255e": 11, "8598e": 11, "2374e": 11, "6920e": 11, "1562e": 11, "8626e": 11, "7366e": 11, "9443e": 11, "6788e": 11, "9036e": 11, "2384e": 11, "6984e": 11, "1564e": 11, "1689e": 11, "0295e": 11, "2329e": 11, "1178e": 11, "3998e": 11, "8541e": 11, "2427e": 11, "7648e": 11, "4620e": 11, "7606e": 11, "7778e": 11, "8597e": 11, "0985e": 11, "8252e": 11, "9020e": 11, "2475e": 11, "8406e": 11, "4016e": 11, "9382e": 11, "9196e": 11, "4634e": 11, "1036e": 11, "8699e": 11, "2499e": 11, "8730e": 11, "2370e": 11, "4954e": 11, "6647e": 11, "3188e": 11, "3069e": 11, "0486e": 11, "8229e": 11, "8736e": 11, "9019e": 11, "2487e": 11, "8426e": 11, "2192e": 11, "4302e": 11, "0340e": 11, "4735e": 11, "4378e": 11, "3352e": 11, "8235e": 11, "8706e": 11, "9026e": 11, "7751e": 11, "1833e": 11, "2732e": 11, "5073e": 11, "7656e": 11, "2245e": 11, "3121e": 11, "8635e": 11, "9032e": 11, "2421e": 11, "7197e": 11, "1551e": 11, "8207e": 11, "1133e": 11, "0936e": 11, "8585e": 11, "0197e": 11, "8260e": 11, "2413e": 11, "7135e": 11, "1539e": 11, "0195e": 11, "7043e": 11, "1394e": 11, "0903e": 11, "6487e": 11, "0803e": 11, "8261e": 11, "8567e": 11, "2431e": 11, "7571e": 11, "0617e": 11, "7993e": 11, "0859e": 11, "9256e": 11, "4172e": 11, "8253e": 11, "2457e": 11, "8168e": 11, "2138e": 11, "2297e": 11, "9390e": 11, "6312e": 11, "2713e": 11, "3078e": 11, "1611e": 11, "8241e": 11, "8671e": 11, "2338e": 11, "0587e": 11, "0395e": 11, "0192e": 11, "8022e": 11, "8704e": 11, "2460e": 11, "2286e": 11, "1068e": 11, "0080e": 11, "6722e": 11, "1236e": 11, "3358e": 11, "6808e": 11, "8238e": 11, "8689e": 11, "9027e": 11, "2435e": 11, "7919e": 11, "2050e": 11, "2851e": 11, "4382e": 11, "6265e": 11, "2953e": 11, "8247e": 11, "8640e": 11, "2414e": 11, "7490e": 11, "1819e": 11, "7505e": 11, "7384e": 11, "7801e": 11, "3597e": 11, "9579e": 11, "8256e": 11, "8595e": 11, "1752e": 11, "1913e": 11, "9282e": 11, "2941e": 11, "2243e": 11, "6341e": 11, "3012e": 11, "2429e": 11, "7659e": 11, "5794e": 11, "2630e": 11, "5998e": 11, "6244e": 11, "9024e": 11, "2454e": 11, "2064e": 11, "1741e": 11, "2301e": 11, "4884e": 11, "4171e": 11, "3287e": 11, "08j": 11, "8661e": 11, "8283e": 11, "2165e": 11, "5070e": 11, "7686e": 11, "1822e": 11, "5270e": 11, "5864e": 11, "9978e": 11, "8239e": 11, "8686e": 11, "2466e": 11, "8175e": 11, "2097e": 11, "5537e": 11, "3746e": 11, "1791e": 11, "7433e": 11, "2449e": 11, "7840e": 11, "1919e": 11, "6042e": 11, "9409e": 11, "2997e": 11, "6248e": 11, "6412e": 11, "0632e": 11, "8641e": 11, "2432e": 11, "7547e": 11, "6250e": 11, "0654e": 11, "1176e": 11, "6694e": 11, "5363e": 11, "4396e": 11, "8609e": 11, "2428e": 11, "7510e": 11, "1760e": 11, "5648e": 11, "9630e": 11, "9794e": 11, "5772e": 11, "8362e": 11, "2345e": 11, "8254e": 11, "8604e": 11, "7739e": 11, "1895e": 11, "7132e": 11, "1439e": 11, "4346e": 11, "7346e": 11, "7092e": 11, "1468e": 11, "8627e": 11, "0x7fdcc38f2310": 11, "level": [12, 37, 169], "check": [12, 23, 29, 37, 169], "qnn": [12, 15, 20, 21, 37, 169], "convolut": [12, 18, 37, 169], "quanvolut": [12, 18, 37, 169], "regress": [12, 22, 23, 37, 169], "intermedi": [12, 26, 37, 169], "clifford": [12, 37, 169], "paulisum": [12, 37, 169], "expert": [12, 37, 169], "vqa": [12, 37, 169], "prune": [12, 18, 37, 169], "vqe": [12, 37], "preprat": [12, 37, 169], "seri": [12, 37], "paper": [12, 37], "reproduc": [12, 37, 169], "hesit": [12, 37], "contact": [12, 37], "forum": [12, 37, 169], "hanrui": [13, 14, 15, 20, 21, 22, 23, 25, 26, 28, 29, 34, 169], "wang": [13, 14, 15, 20, 21, 22, 23, 25, 26, 28, 29, 34, 169], "gokul": 13, "subramanian": 13, "ravi": 13, "4ry": 13, "4rz": 13, "pixel": 13, "still": 13, "advantang": 13, "exponenti": 13, "mnist_clifford_qnn": 13, "868": [13, 29], "660": [13, 15], "straight": 13, "sse": 13, "722": [13, 15], "582": 13, "zirui": [14, 15, 20, 21, 22, 23, 28, 29, 169], "li": [14, 15, 20, 21, 22, 23, 28, 29, 31, 169], "referec": [14, 20, 22, 28], "toward": [14, 20], "neural": [14, 24, 25, 26, 169], "introduct": [14, 21, 23], "tutori": [15, 20, 21, 22, 23, 25, 26, 27, 28, 29, 34, 169], "bug": [15, 21], "stuck": 15, "torchquantum": [15, 17, 19, 22, 25, 26, 28, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 170], "fix": [15, 21], "By": [15, 31], "carefulli": 15, "investig": 15, "small": 15, "tend": 15, "variat": [15, 24, 25, 28, 29, 169], "wrong": 15, "under": [15, 23, 31], "nois": [15, 19, 21, 29, 32, 169], "especi": [15, 24, 25], "magnitud": 15, "opportun": 15, "boost": 15, "robust": [15, 169], "propos": [15, 33, 34], "separ": 15, "There": [15, 26], "hyper": 15, "\ud835\udc64\ud835\udc4e": 15, "\ud835\udc5f": 15, "\ud835\udc64\ud835\udc5d": 15, "inform": [15, 17, 26, 32, 33, 34, 36], "exempt": 15, "trend": 15, "confid": 15, "tune": 15, "balanc": 15, "varianc": [15, 23], "caus": 15, "perturb": 15, "thu": 15, "frac": [15, 21, 31], "1": [15, 16, 17, 21, 23, 24, 25, 26, 29, 30, 31, 32, 33, 169], "2": [15, 17, 20, 23, 25, 26, 29, 31, 32, 33, 169], "usual": [15, 21, 29], "work": [15, 26, 29], "tar": [15, 21, 23, 29, 31, 34], "manylinux2010_x86_64": [15, 21, 23, 29, 31, 34], "manylinux_2_12_x86_64": [15, 21, 23, 29, 31, 34], "237": [15, 21, 23, 25, 29], "igni": [15, 21, 23, 29], "qiskit_igni": [15, 21, 23, 29], "aqua": [15, 21, 23, 29], "qiskit_aqua": [15, 21, 23, 29], "quandl": [15, 21, 23, 29], "dlx": [15, 21, 23, 29], "yfinanc": [15, 21, 23, 29], "fastdtw": [15, 21, 23, 29], "docplex": [15, 21, 23, 29], "requests_ntlm": [15, 21, 23, 29, 31, 34], "websocket_cli": [15, 21, 23, 29], "jsonschema": [15, 21, 23, 29], "943": [15, 21, 23, 29], "bz2": [15, 21, 23, 29], "fastjsonschema": [15, 21, 23, 29], "attr": [15, 21, 23, 29], "pyrsist": [15, 21, 23, 29], "resourc": [15, 21, 23, 29], "2021": [15, 21, 23, 29], "ntlm_auth": [15, 21, 23, 29], "cp36": [15, 21, 23, 29], "abi3": [15, 21, 23, 29, 31], "manylinux_2_24_x86_64": [15, 21, 23, 29], "lxml": [15, 21, 23, 29], "multitask": [15, 21, 23, 29], "2018": [15, 21, 23, 29], "inflect": [15, 21, 23, 29], "itertool": [15, 21, 23, 29], "setup": [15, 21, 23, 29, 31, 34], "11777": [15, 21, 23, 29], "sha256": [15, 21, 23, 29, 31, 34], "0da44b2b1281b0ae4c6e2615fcd1db002c7b2a0f27dfff24fc5292884896d11f": 15, "0f": [15, 21, 23, 29], "0a": [15, 21, 23, 29], "c53eda1ead41c137c47c9730bc2771a8367b1ce00fb64e8cc6": [15, 21, 23, 29], "5718": [15, 21, 23, 29], "f4189a2cdf623b2017d93227cacb73900731558a0f4c543a681229a95f7a2dda": 15, "c8": [15, 21, 23, 29], "dc61e772445a566b7608a476d151e9dcaf4e092b01b0c4bc3c": [15, 21, 23, 29], "662847": 15, "06dfed71b2318068e88b361dbfd3d66d11303eb17ed9f9c8988e0d606f30fcf": 15, "a7": 15, "c9": 15, "fb": 15, "cee5a89f304e77a39c466e625ac2830434b76eb8384999d116": 15, "python_constraint": [15, 21, 23, 29], "24081": [15, 21, 23, 29], "fffdc1553687d0239ea846797253de00732d5239d91b239e0fe3423ffec55084": 15, "db": [15, 21, 23, 29], "1222c80eb1e431f3d2199c12569cb1cac60f562a451fe30479": [15, 21, 23, 29], "datasci": [15, 21, 23, 29], "folium": [15, 21, 23, 29], "zhijian": 15, "liu": [15, 169], "3924": 15, "217": [15, 25], "210": [15, 21, 25], "3595": 15, "1012": 15, "kib": 15, "2521": 15, "cu111": [15, 21, 23, 29], "34632": 15, "6e05974cb0c985fbc1e541043be80ee7da98c12608ff883943ee70843656c42a": 15, "tmp": 15, "ephem": 15, "njdff8xi": 15, "1a": 15, "b8f5a127071f807be5ee14d3d364b428a891ad020a962af415": 15, "repo": [15, 21, 23, 29], "10990": 15, "7782": 15, "3963": 15, "3911": 15, "3410": 15, "3208": [15, 21, 23, 29], "81": [15, 21, 23, 25, 29, 31, 34], "899": 15, "develop": [15, 21, 23, 25, 26, 27, 29, 31, 34], "albument": [15, 21, 23, 29], "imgaug": [15, 21, 23, 29], "pythonpath": [15, 21, 23, 29, 34], "env": [15, 21, 23, 29, 34], "like": [15, 21, 23, 29, 31], "meanabsoluteerror": 15, "minsav": 15, "saverrestor": 15, "legalinferencerunn": 15, "subnetinferencerunn": 15, "trainerrestor": 15, "addnoiseinferencerunn": 15, "gradrestor": 15, "fix_qiskit_parameter": [15, 21], "train_with_config": 15, "probabilistic_gradient_prun": 15, "jsonl": 15, "qmultifcmodel0": 15, "use_qiskit_train": 15, "use_qiskit_valid": 15, "paramsshifttrain": 15, "set_use_qiskit": 15, "num_forward": 15, "accu": [15, 29], "json_fil": 15, "json_list": 15, "json_str": 15, "kei": [15, 26], "num_forward1": 15, "accu1": 15, "924": 15, "996": 15, "awar": [15, 21, 29, 169], "594": 15, "roll": 15, "494": [15, 21], "16eed591": 15, "b4a6": 15, "4540": 15, "88ba": 15, "fa352954d776": 15, "n_node": 15, "node_arch": 15, "barren_0": 15, "act_norm": 15, "gradient_based_prun": 15, "accumulation_window_s": 15, "pruning_window_s": 15, "pruning_ratio": 15, "q_multifc0": 15, "368": [15, 25], "933": [15, 21, 25], "flexibl": [15, 21], "regist": [15, 21], "compat": [15, 21, 31, 34], "rh": [15, 21], "195": [15, 25, 31], "truncat": 15, "0478": 15, "545": 15, "906": 15, "cz": 15, "876": 15, "655": [15, 21], "117": [15, 25, 31], "728": 15, "784": 15, "307": 15, "367": 15, "419": 15, "541": 15, "616": [15, 21, 25], "814": [15, 29], "83": [15, 25, 31], "940": 15, "002": 15, "407": [15, 21], "2940": 15, "408": [15, 25], "1162": 15, "0443": 15, "1153": 15, "047839": 15, "hour": 15, "418": [15, 25], "420": [15, 25], "0452": 15, "859": 15, "301": 15, "766": 15, "840": 15, "909": 15, "400": [15, 21, 26], "476": [15, 25], "994": 15, "453": [15, 25], "985": 15, "050": [15, 21, 25], "044": [15, 25], "656": 15, "124": [15, 25, 31], "665": 15, "738": 15, "739": 15, "798": 15, "669": 15, "677": 15, "3932": 15, "0286": 15, "0648": 15, "704": 15, "706": 15, "0417": 15, "712": 15, "170": [15, 25, 31], "239": [15, 25], "98": [15, 25, 31], "716": [15, 25], "908": [15, 25], "979": [15, 21], "429": 15, "555": 15, "626": [15, 21], "066": [15, 25], "439": [15, 21], "326": [15, 21], "369": [15, 21], "4924": 15, "371": 15, "0742": 15, "0121": 15, "0645": 15, "041728": 15, "374": [15, 21], "0375": 15, "708": [15, 21], "104": [15, 25, 31], "184": [15, 25, 31], "247": [15, 25], "314": [15, 21, 25], "132": [15, 21, 25, 31, 34], "684": 15, "747": [15, 21], "205": [15, 21, 25], "715": 15, "780": [15, 21], "245": [15, 25], "758": [15, 31], "826": 15, "886": 15, "952": 15, "430": [15, 21, 25], "992": 15, "444": 15, "510": [15, 21], "953": 15, "771": [15, 29], "474": 15, "489": 15, "5880": 15, "491": [15, 25], "0234": 15, "0777": 15, "493": 15, "934": 15, "0327": 15, "866": 15, "265": [15, 25], "791": 15, "663": 15, "729": 15, "794": 15, "862": [15, 21], "916": 15, "437": [15, 21], "625": [15, 21, 25], "063": [15, 21, 25], "131": [15, 25, 31], "808": 15, "870": 15, "825": [15, 21], "890": 15, "344": 15, "399": [15, 25], "156": [15, 25, 31], "171": [15, 25, 31], "6872": 15, "9337": 15, "0683": 15, "032725": 15, "178": [15, 25, 31], "0276": 15, "89": [15, 25, 31], "898": 15, "308": [15, 21, 25], "832": 15, "897": 15, "750": 15, "844": 15, "986": 15, "440": [15, 21], "520": 15, "965": 15, "039": [15, 25], "488": [15, 21], "557": 15, "064": [15, 25], "575": 15, "023": 15, "092": [15, 21, 25], "612": 15, "895": [15, 21, 23, 25, 29], "976": 15, "034": [15, 25], "622": [15, 21], "7864": 15, "95734": 15, "99281": 15, "0654": 15, "027613": 15, "348": 15, "350": [15, 25], "352": 15, "877": 15, "020": [15, 25], "096": [15, 25], "446": 15, "911": 15, "989": [15, 25, 26], "455": 15, "531": [15, 25], "809": 15, "889": 15, "853": [15, 25], "920": [15, 21], "973": [15, 25], "058": [15, 21, 25], "115": [15, 21, 25, 31], "179": [15, 25, 31], "142": [15, 25, 31], "211": [15, 25], "727": [15, 21], "169": [15, 21, 25, 31], "292": [15, 25], "051": [15, 25], "057": [15, 21, 25], "072": [15, 21, 25], "8820": 15, "96125": 15, "0689": 15, "022387": 15, "080": [15, 25], "0173": 15, "385": [15, 21], "774": 15, "325": [15, 21], "756": [15, 21], "452": 15, "188": [15, 21, 25, 31], "243": [15, 21, 25, 26], "414": [15, 21, 25], "496": [15, 21], "937": 15, "012": [15, 31], "542": [15, 21], "067": [15, 25], "126": [15, 25, 31], "723": 15, "450": 15, "0284": 15, "98941": 15, "0661": 15, "017275": 15, "456": [15, 26], "942": 15, "038": [15, 25], "434": 15, "892": [15, 21], "982": 15, "134": [15, 21, 25, 31, 34], "573": [15, 25], "638": 15, "714": 15, "790": 15, "335": 15, "025": [15, 25], "113": [15, 21, 25, 31], "707": [15, 25], "782": 15, "018": 15, "021": 15, "10804": 15, "045": [15, 25], "94174": 15, "98321": 15, "059": [15, 25], "047": [15, 25], "052": [15, 21, 25], "00827": 15, "839": 15, "343": [15, 25], "884": [15, 26], "548": [15, 21, 25], "635": 15, "470": 15, "544": [15, 26], "026": [15, 21, 25], "103": [15, 25, 31], "718": 15, "793": [15, 21], "271": [15, 25], "807": 15, "144": [15, 21, 25, 31], "11760": 15, "87124": 15, "98594": 15, "0628": 15, "0082717": 15, "165": [15, 25, 31], "00477": 15, "913": [15, 26], "514": 15, "423": [15, 25, 34], "033": [15, 21, 25], "569": 15, "516": 15, "658": [15, 21], "032": [15, 25], "109": [15, 25, 31], "634": [15, 21, 23, 25, 29], "620": 15, "12752": 15, "621": 15, "97094": 15, "98713": 15, "0617": 15, "0047746": 15, "624": 15, "00216": 15, "485": 15, "947": 15, "393": [15, 21], "978": [15, 21, 25], "061": [15, 25], "797": [15, 21], "865": 15, "829": [15, 25], "424": 15, "858": 15, "373": [15, 21, 25], "441": [15, 26], "130": [15, 25, 31], "847": 15, "13744": 15, "0415": 15, "98499": 15, "0606": 15, "0021614": 15, "867": [15, 25], "869": 15, "894": 15, "000546": 15, "504": 15, "959": 15, "581": [15, 25], "631": 15, "159": [15, 21, 25, 31], "759": [15, 21], "075": [15, 25], "768": 15, "536": 15, "564": [15, 25], "14700": 15, "89366": 15, "98533": 15, "0605": 15, "00054631": 15, "num_forward2": 15, "accu2": 15, "Not": 15, "645": 15, "234": [15, 25], "583": 15, "742": 15, "818": 15, "773": [15, 21], "850": 15, "290": [15, 25], "362": [15, 25], "824": 15, "935": 15, "513": 15, "833": 15, "10220": 15, "98833": 15, "370": [15, 21, 25], "883": [15, 21], "614": 15, "079": [15, 21, 25], "757": 15, "835": 15, "288": [15, 25], "879": 15, "413": 15, "483": [15, 25], "936": 15, "526": [15, 21], "508": 15, "037": [15, 21, 25], "105": [15, 25, 31], "11680": 15, "96974": 15, "98923": 15, "0744": 15, "360": [15, 25], "925": 15, "993": 15, "74": [15, 25, 31, 34], "751": [15, 21], "822": [15, 21], "291": [15, 21, 25], "359": [15, 25], "811": 15, "878": 15, "251": [15, 21, 25], "13140": 15, "98214": 15, "0687": 15, "944": [15, 25], "914": [15, 25], "421": [15, 25, 26], "515": [15, 25], "054": [15, 25], "172": [15, 25, 31], "691": 15, "283": [15, 25], "341": 15, "519": [15, 21], "593": 15, "14600": 15, "94449": 15, "98667": 15, "0679": 15, "921": [15, 25], "984": [15, 25], "416": [15, 25], "006": [15, 21], "576": 15, "627": [15, 21], "694": [15, 21], "896": [15, 21], "692": [15, 21], "16060": 15, "697": 15, "0701": 15, "98661": 15, "0738": 15, "938": 15, "016": [15, 21], "509": 15, "048": [15, 21, 25], "487": [15, 21], "746": [15, 21], "525": 15, "837": [15, 25], "17520": 15, "838": 15, "97979": 15, "98503": 15, "0691": 15, "851": 15, "852": [15, 21], "941": 15, "995": [15, 25], "720": 15, "912": [15, 21], "204": [15, 25], "611": 15, "18980": 15, "98411": 15, "98492": 15, "0692": 15, "574": 15, "342": [15, 21, 25], "388": 15, "451": 15, "116": [15, 25, 29, 31], "091": [15, 25], "427": [15, 25], "20440": 15, "0041": 15, "98459": 15, "0707": 15, "431": [15, 21, 25], "433": [15, 21], "670": [15, 25], "334": [15, 21, 25], "404": [15, 25], "560": 15, "086": [15, 25], "040": [15, 25], "546": 15, "668": 15, "21900": 15, "752": [15, 21], "91464": 15, "98475": 15, "0677": 15, "up": [16, 23, 34, 169], "unstructur": 16, "problem": [16, 22, 23], "quadrat": 16, "amplif": 16, "walkthrough": 16, "grover_example_sudoku": 16, "solv": [16, 22, 23], "sudoku": 16, "puzzl": 16, "2x2": [16, 29], "lov": 16, "mechan": 16, "databas": 16, "symposium": [16, 169], "theori": 16, "1996": [16, 33, 34], "circ1": 17, "hadamard_grad": 17, "expval1": 17, "qdev1": 17, "expval": [17, 31, 169], "op_histori": [17, 169], "8776": 17, "selectbackward0": 17, "oppauliexp": 17, "coeff": 17, "yxix": 17, "facilit": 17, "v0": [17, 169], "manual": 17, "extrac": 17, "histori": 17, "bit": [17, 33, 34], "zzzz": 17, "47942554": 17, "vast": 17, "palmer": 17, "home": 17, "grace": 17, "dl2276": 17, "allproject": 17, "func_controlled_unitari": 17, "4794": 17, "probabilist": 18, "iri": 18, "superdens": 18, "refer": 18, "mnist_exampl": [19, 169], "around": [19, 31], "previous": [20, 21], "wa": [20, 21, 31, 33, 34], "did": [20, 21], "computaion": [20, 21], "node": [20, 21, 31], "revers": [20, 21, 23], "outlin": [21, 23], "As": [21, 29], "know": [21, 31, 34], "imposs": 21, "offer": 21, "techniqu": [21, 24, 25, 33, 34], "minu": 21, "multipli": 21, "workflow": 21, "suppos": 21, "theta_1": 21, "cdot": 21, "theta_i": 21, "theta_n": 21, "repres": [21, 34], "langl": [21, 31], "psi": [21, 31], "dagger": [21, 31], "widehat": 21, "rangl": [21, 22, 23, 31], "quad": 21, "mathbb": 21, "whose": 21, "notat": 21, "simplic": 21, "absorb": 21, "fuse": 21, "written": [21, 25, 26], "form": [21, 23], "hermitian": 21, "uniqu": [21, 25], "eigenvalu": [21, 31], "align": 21, "partial": 21, "big": [21, 29], "theta_": 21, "neg": [21, 23, 29], "fundament": 21, "numer": 21, "deriv": 21, "equat": 21, "exact": [21, 31], "softmax": [21, 25, 26], "mathcal": 21, "texttt": 21, "sum_": 21, "t_j": 21, "p_j": 21, "f_j": 21, "backpropag": [21, 29, 35], "differenti": 21, "framework": [21, 169], "tensorflow": 21, "assum": [21, 22, 23, 31], "r_x": [21, 31], "infti": 21, "kx": 21, "2k": 21, "pm": 21, "mp": 21, "ix": 21, "beta": 21, "xr_x": 21, "dag": 21, "hold": 21, "yy": 21, "213": [21, 23, 25, 29], "c8dd0aa33407d766de6e21a79c560a28d3aaed47ab5efde37ac60f61f0fc3275": 21, "88e879a69472bf6f871793f7a320337f70c30e734a308266be28dd0b5eb1d388": 21, "696882": [21, 23, 29], "8a296841fded71c4005ec13d2237a5fcd0dc925f2debdbb6d9198745aa27fd30": 21, "6b": [21, 23, 29], "1375c68a5b7ff94c40263b151c86f58bd72200bf0c465b5ba3": [21, 23, 29], "1e63dc909ecdff23baaaf9c6950a9f43558f4cbfddb001c3cb6eae6209ba594c": 21, "10900": 21, "7692": 21, "3901": 21, "3851": 21, "7185": 21, "3382": 21, "5818": 21, "msgpack_numpi": [21, 23, 29, 31, 34], "51a2a5d55d3e1d9683ab4f135fe6fbb84ecf3221765e19adb408699d43c6eaa238265059c3c2955ba59328634ffbd88ba14d5386c947d22eb9a826e40811d626": 21, "843": 21, "6572614107883817": 21, "6472271680831909": 21, "004945369001834514": [21, 29], "7103734439834025": 21, "6162570714950562": 21, "004783863644106502": [21, 29], "7369294605809129": 21, "5867344737052917": 21, "0045225424859373685": [21, 29], "7551867219917012": 21, "5621022582054138": 21, "0041728265158971455": [21, 29], "7701244813278009": 21, "5444782972335815": 21, "00375": [21, 29], "7775933609958506": 21, "5322179794311523": 21, "0032725424859373687": [21, 29], "779253112033195": 21, "5243480205535889": 21, "002761321158169134": [21, 29], "7800829875518672": 21, "5192304849624634": 21, "002238678841830867": [21, 29], "5155690312385559": 21, "7809128630705394": 21, "5131878852844238": 21, "0012500000000000007": [21, 29], "5115664005279541": 21, "0008271734841028553": [21, 29], "7817427385892116": 21, "5105563402175903": 21, "00047745751406263163": [21, 29], "7825726141078838": 21, "5099871754646301": 21, "00021613635589349755": [21, 29], "5097272396087646": 21, "463099816548578e": [21, 29], "5096644759178162": 21, "8064024390243902": 21, "48410049080848694": 21, "183": [21, 25, 31], "472": 21, "885": 21, "220": [21, 25], "755": 21, "114": [21, 25, 31], "137": [21, 25, 31], "741": 21, "672": 21, "463": 21, "349": 21, "252": [21, 25], "991": 21, "779": [21, 25], "675": 21, "009": 21, "556": [21, 25], "083": [21, 25], "783": 21, "361": 21, "387": [21, 25], "366": [21, 25], "743": 21, "724": 21, "029": [21, 25], "094": [21, 25], "090": [21, 25], "218": [21, 25], "272": [21, 25], "345": [21, 34], "425": [21, 25], "351": 21, "099": [21, 25], "069": [21, 25], "073": [21, 25], "819": 21, "945": 21, "666": 21, "690": 21, "258": [21, 25], "303": 21, "781": 21, "812": 21, "365": [21, 25], "445": [21, 25], "161": [21, 25, 31], "657": 21, "9494949494949495": 21, "47831726414734255": 21, "068": [21, 25], "129": [21, 25, 31, 34], "522": 21, "403": 21, "615": 21, "640": 21, "185": [21, 25, 31], "187": [21, 25, 31], "689": [21, 25], "713": 21, "974": 21, "566702274514434": 21, "411": 21, "810": 21, "233": [21, 25], "964": 21, "988": 21, "987": 21, "014": 21, "206": [21, 25], "112": [21, 25, 31, 34], "801": 21, "video": [22, 28], "explan": [22, 28], "supervis": 22, "svm": [22, 23], "op_name_dict": [22, 23], "func_name_dict": [22, 23], "pattern": [22, 23], "analysi": [22, 23, 27], "thei": [22, 23, 25, 26, 28, 29, 31], "linear": [22, 23, 24, 25, 26, 29], "classifi": [22, 23], "emploi": [22, 23, 34], "vector": [22, 23, 25, 26, 27, 29, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "often": [22, 23], "trick": [22, 23, 24, 25], "boundari": [22, 23], "possibl": [22, 23, 25, 29, 31], "dimens": [22, 23, 25, 26, 28, 29], "inner": [22, 23, 28, 29], "product": [22, 23, 28, 29], "transpos": [22, 25, 26, 29], "conjug": 22, "behind": [22, 23], "fall": [22, 23], "cdots0": [22, 23], "hilbert": [23, 28, 29], "distanc": 23, "16a15d5cc4c9bdab55b6da049c7e58a7c58cd02e22ecc9044718a27788244262": 23, "a8f563a7d9277a099dc3b0dc15762e4def17093a161e6fbf4d733b6b0b2f1c2a": 23, "57bb12d24c9ce9789526ae87226c1d3a0e9c1f65f4c3dab2072c2c4fe4a86a1d": 23, "ed53d7d29290e0b27910e22334e2833b1157a35ce940f011456cb4aace39c774": 23, "10724": 23, "7516": 23, "3769": 23, "3756": 23, "7069": 23, "3343": 23, "5723": 23, "50054": 23, "svc": 23, "load_iri": 23, "famou": 23, "standardscal": 23, "scale": [23, 169], "unit": 23, "train_test_split": 23, "accuracy_scor": 23, "correctli": [23, 25], "veri": 23, "plai": [23, 34], "central": 23, "role": [23, 34], "These": [23, 26], "thing": [23, 31], "sklearn": 23, "preprocess": 23, "model_select": 23, "2\u03c0": 23, "\u03c0": 23, "return_x_i": 23, "scaler": 23, "x_scale": 23, "y_scale": 23, "x_train": 23, "x_test": 23, "y_train": 23, "y_test": 23, "kernelansatz": 23, "entri": [23, 25, 26, 29], "didn": 23, "forget": [23, 25], "perspect": 23, "invert": 23, "tail": 23, "counteract": 23, "sequenc": [23, 25, 31], "flip": [23, 31, 34], "kernalansatz": 23, "num_param": 23, "mention": 23, "flatten": 23, "absolut": 23, "pretti": 23, "kernel_funct": 23, "kernel_matrix": 23, "rise": [24, 25], "recurr": [24, 25], "long": [24, 25], "short": [24, 25], "term": [24, 25, 27], "memori": [24, 25, 26], "were": [24, 25], "success": [24, 25, 32], "analyz": [24, 25, 26], "sequenti": [24, 25, 26, 27], "relev": [24, 25], "enhanc": [24, 25, 26, 27], "qlstm": [24, 25], "wf": [24, 25], "wi": [24, 25], "wc": [24, 25], "wo": [24, 25], "hybrid": [24, 25, 169], "compon": [24, 25], "consist": [24, 25, 26, 29, 169], "sandwich": [24, 25], "mohammadrezatavasoli": [24, 27], "chen": [24, 25, 26], "samuel": [24, 25, 26], "yen": [24, 25, 26], "chi": [24, 25, 26], "shinja": 24, "yoo": 24, "yao": 24, "lung": 24, "fang": 24, "icassp": [24, 25, 26], "ieee": [24, 25, 26, 169], "confer": [24, 25, 26], "acoust": [24, 25, 26], "speech": [24, 25, 26], "mohammadreza": [25, 26, 169], "tavasoli": [25, 26, 169], "naeini": [25, 26], "advisor": [25, 26, 34], "trochquantum": [25, 26, 28, 29], "librari": [25, 26, 27, 34, 56, 57, 169], "notebook": [25, 26], "excerpt": [25, 26], "rdisipio": [25, 26], "riccardo": [25, 26], "di": [25, 26], "sipio": [25, 26], "user": [25, 26], "mohammad": [25, 26], "miniforge3": [25, 26], "site": [25, 26], "typic": [25, 26, 28, 29], "entangl": [25, 26, 33], "qlayer_forget": 25, "rx1": [25, 26], "rx2": [25, 26], "rx3": [25, 26], "qdev": [25, 31, 34, 169], "qlayer_input": 25, "qlayer_upd": 25, "qlayer_output": 25, "input_s": 25, "hidden_s": 25, "n_qlayer": [25, 26], "batch_first": [25, 26], "return_sequ": 25, "return_st": 25, "n_input": 25, "concat_s": 25, "basica": 25, "clayer_in": 25, "vqc": 25, "clayer_out": 25, "init_st": 25, "seq_length": 25, "feature_s": 25, "recurrent_activ": 25, "sigmoid": [25, 26], "activ": [25, 28, 29], "tanh": 25, "features_s": 25, "hidden_seq": 25, "h_t": 25, "hidden": 25, "c_t": 25, "fact": 25, "multipl": [25, 28, 29, 31, 34, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 169], "rnn": [25, 26, 34], "element": [25, 32], "tupl": 25, "seq": 25, "x_t": 25, "concaten": 25, "v_t": 25, "match": [25, 26], "y_t": 25, "f_t": 25, "i_t": 25, "g_t": 25, "o_t": 25, "tag": 25, "determin": [25, 31, 34], "noun": 25, "verb": 25, "tag_to_ix": 25, "det": 25, "v": [25, 26], "ix_to_tag": 25, "sentenc": 25, "word": [25, 26], "prepare_sequ": 25, "to_ix": 25, "training_data": 25, "dog": 25, "ate": 25, "appl": 25, "everybodi": 25, "book": 25, "word_to_ix": 25, "yet": 25, "vocabulari": 25, "entiti": 25, "idea": [25, 28, 29], "h_0": 25, "h_1": 25, "h_2": 25, "h_3": 25, "h_4": 25, "lstmtagger": 25, "embedding_dim": 25, "hidden_dim": 25, "vocab_s": [25, 26], "tagset_s": 25, "word_embed": 25, "embed": [25, 26], "dimension": 25, "tagger": 25, "hidden2tag": 25, "emb": [25, 26], "lstm_out": 25, "tag_logit": 25, "tag_scor": 25, "model_class": 25, "websit": [25, 169], "loss_funct": 25, "rememb": [25, 29], "accumul": 25, "turn": [25, 29], "sentence_in": 25, "prob": 25, "avg_loss": 25, "history_class": 25, "089": 25, "049": 25, "013": 25, "956": 25, "950": 25, "939": 25, "888": 25, "881": 25, "845": 25, "813": 25, "805": 25, "788": 25, "744": 25, "725": 25, "698": 25, "607": 25, "539": [25, 26], "523": 25, "468": 25, "438": 25, "327": 25, "106": [25, 31], "285": 25, "257": 25, "223": 25, "209": 25, "127": [25, 26, 31], "128": [25, 31, 34], "182": [25, 31], "133": [25, 31, 34], "168": [25, 31], "164": [25, 31], "158": [25, 31], "149": [25, 31], "143": [25, 31], "146": [25, 31], "145": [25, 31], "147": [25, 31], "148": [25, 31], "154": [25, 31], "163": [25, 31], "166": [25, 31], "097": 25, "093": 25, "087": 25, "082": 25, "077": 25, "071": 25, "070": 25, "056": 25, "055": 25, "216": 25, "046": 25, "224": 25, "043": 25, "231": 25, "042": 25, "246": 25, "249": 25, "253": 25, "035": 25, "254": 25, "255": [25, 26], "031": [25, 26], "030": 25, "028": 25, "286": 25, "299": 25, "print_result": 25, "input_sent": 25, "tag_id": 25, "tag_label": 25, "model_quantum": 25, "history_quantum": 25, "428": 25, "406": 25, "392": [25, 34], "389": 25, "337": 25, "311": 25, "095": 25, "085": 25, "plot_histori": 25, "loss_c": 25, "acc_c": 25, "loss_q": 25, "acc_q": 25, "x_epoch": 25, "ax1": [25, 29], "orang": 25, "linestyl": 25, "dash": 25, "red": 25, "solid": 25, "ax2": [25, 29], "twinx": 25, "steelblu": 25, "blue": 25, "training__torch": 25, "ylim": 25, "upper": 25, "bbox_to_anchor": 25, "bbox_transform": 25, "transax": 25, "savefig": 25, "pos_training_torch": 25, "pdf": 25, "png": 25, "decreas": 25, "due": 25, "complex": [25, 28, 29], "took": 25, "mere": 25, "jia": [25, 26], "hong": [25, 26], "huang": [25, 26], "stefano": [25, 26], "mangini": [25, 26], "marcel": [25, 26], "wor": [25, 26], "dawn": [25, 26], "languag": [25, 26], "enc": [25, 26], "page": [25, 26], "8612": [25, 26], "8616": [25, 26], "qtransform": 26, "nowadai": [26, 27], "domin": [26, 27], "effieci": 26, "therfor": 26, "stonish": 26, "translat": 26, "anayl": 26, "howev": [26, 31], "embbed": 26, "too": 26, "furthermor": 26, "trnasform": 26, "attat": 26, "mechanisem": 26, "multi": [26, 61, 62, 63, 169], "attet": 26, "atteat": 26, "diffrent": 26, "wq": 26, "wk": 26, "wv": 26, "represent": 26, "queri": 26, "varitin": 26, "11649": 26, "6472": 26, "trash": 26, "2010": 26, "torchtext": 26, "pad_sequ": [26, 34], "legaci": 26, "vocab": 26, "multiheadattentionbas": 26, "embed_dim": 26, "num_head": 26, "dropout": 26, "use_bia": 26, "divis": 26, "d_k": 26, "k_linear": 26, "q_linear": 26, "v_linear": 26, "combine_head": 26, "attn_weight": 26, "separate_head": 26, "seq_len": 26, "mult": 26, "straightforward": 26, "matmul": 26, "tensorchief": 26, "dlday2018": 26, "einsum": [26, 31, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "bijh": 26, "bkjh": 26, "bikh": 26, "masked_fil": 26, "1e9": 26, "attn": 26, "downstream": 26, "multiheadattentionclass": 26, "bia": 26, "multiheadattentionquantum": 26, "rx4": 26, "rx5": 26, "rx6": 26, "rx7": 26, "dress": 26, "feedforwardbas": 26, "ffn_dim": 26, "linear_1": 26, "linear_2": 26, "feedforwardclass": 26, "relu": 26, "feedforward": 26, "feedforwardquantum": 26, "ql": 26, "q_l": 26, "transformerblockbas": 26, "ff_dim": 26, "n_qubits_transform": 26, "n_qubits_ffn": 26, "ffn": 26, "dropout1": 26, "dropout2": 26, "norm1": 26, "layernorm": 26, "norm2": 26, "attn_output": 26, "ff_output": 26, "transformerblockclass": 26, "transformerblockquantum": 26, "positionalencod": 26, "max_seq_len": 26, "512": 26, "constant": 26, "pe": 26, "po": 26, "10000": 26, "register_buff": 26, "larger": 26, "textclassifi": 26, "num_block": 26, "num_class": 26, "token_embed": 26, "pos_embed": 26, "transformer_block": 26, "class_logit": 26, "1d": 26, "count_paramet": 26, "binary_accuraci": 26, "round": 26, "closest": 26, "integ": 26, "rounded_pr": 26, "epoch_loss": 26, "epoch_acc": 26, "set_detect_anomali": 26, "longtensor": 26, "epoch_tim": 26, "start_tim": 26, "end_tim": 26, "elapsed_min": 26, "elapsed_sec": 26, "__name__": 26, "__main__": 26, "20000": 26, "n_transformer_block": 26, "n_head": 26, "dropout_r": 26, "include_length": 26, "labelfield": 26, "train_data": 26, "test_data": 26, "imdb": 26, "build_vocab": 26, "max_siz": 26, "exclud": 26, "unk": 26, "pad": 26, "train_it": 26, "test_it": 26, "bucketiter": 26, "bcewithlogitsloss": 26, "logit": 26, "loop": [26, 29], "best_valid_loss": 26, "inf": 26, "iepoch": 26, "train_loss": 26, "train_acc": 26, "valid_loss": 26, "valid_acc": 26, "epoch_min": 26, "epoch_sec": 26, "ttrain": 26, "25000": 26, "0m": 26, "671": 26, "50000": 26, "ashish": 26, "vaswani": 26, "noam": 26, "shazeer": 26, "niki": 26, "parmar": 26, "jakob": 26, "uszkoreit": 26, "llion": 26, "jone": 26, "aidan": 26, "gomez": 26, "\u0142ukasz": 26, "kaiser": 26, "illia": 26, "polosukhin": 26, "advanc": [26, 29], "5998": 26, "6008": 26, "ubiquit": 27, "gpt": 27, "hundr": 27, "billion": 27, "hand": [27, 31], "articl": 27, "advantag": [27, 33, 34], "deploi": [27, 169], "wrote": 27, "se": 28, "power": 28, "recognit": 28, "filter": 28, "genr": [28, 29], "mostli": [28, 29], "anyl": [28, 29], "visual": [28, 29], "known": [28, 29], "frobeniu": [28, 29], "slide": [28, 29], "along": [28, 29], "One": [28, 29], "higher": [28, 29], "therefor": [28, 29], "tradit": [28, 29], "911365fec91e5c648d2569b156af429c0aff7c3d95d453a7d24e6bf8d7d1a315": 29, "cb913d8c2b19d87e8784f4220a02752c4858e3ebe531b0e80ab22c5625c1bd0b": 29, "192bab0a2587503608ce12a090c9f129f2a6b0e88f3a41e568c07ca585b4e3ff": 29, "77684dcb7c666715267053a0114cf933c5c52cb7af9a30645de961f9af12c323": 29, "10737": 29, "7529": 29, "3777": 29, "3765": 29, "7076": 29, "3348": 29, "5732": 29, "50055": 29, "cosin": 29, "anneal": 29, "channel": [29, 33, 34], "next": [29, 31], "data_list": 29, "stride": 29, "window": 29, "caten": 29, "quanvolutionfilt": 29, "full": 29, "14x14": 29, "At": 29, "Its": 29, "hybridmodel": 29, "qf": 29, "hybridmodel_without_qf": 29, "folder": [29, 32], "model_without_qf": 29, "likelihood": 29, "don": 29, "accu_list1": 29, "loss_list1": 29, "accu_list2": 29, "loss_list2": 29, "8066666666666666": 29, "6323180794715881": 29, "7766666666666666": 29, "5900668501853943": 29, "8466666666666667": 29, "48249581456184387": 29, "8133333333333334": 29, "5225163698196411": 29, "8033333333333333": 29, "6009621620178223": 29, "8333333333333334": 29, "44394049048423767": 29, "4330306053161621": 29, "8366666666666667": 29, "45171523094177246": 29, "8633333333333333": 29, "4244077205657959": 29, "40085339546203613": 29, "8533333333333334": 29, "40397733449935913": 29, "3975270986557007": 29, "8566666666666667": 29, "4006715416908264": 29, "8666666666666667": 29, "39790403842926025": 29, "3979119062423706": 29, "7733333333333333": 29, "6043258905410767": 29, "8166666666666667": 29, "5571645498275757": 29, "46128183603286743": 29, "5158915519714355": 29, "45338067412376404": 29, "4563254714012146": 29, "4633018374443054": 29, "46147480607032776": 29, "45319321751594543": 29, "46221110224723816": 29, "4611275792121887": 29, "4614029824733734": 29, "4610340893268585": 29, "46056315302848816": 29, "4606676697731018": 29, "set_ylim": 29, "n_channel": 29, "after_quanv": 29, "realli": 29, "prioriti": 29, "That": 29, "section": 29, "consid": [29, 31], "variou": 29, "nearli": 29, "trainal": 29, "model1": 29, "fulli": 29, "u3cu3layer0": 29, "qfc": 29, "model3": 29, "model4": 29, "trainablequanvfilt": 29, "quantumclassifi": 29, "linear1": 29, "linear2": 29, "model_list": 29, "off": 30, "qubit_rot": 30, "josh": 31, "izaac": 31, "wish": [31, 34], "phi_1": 31, "sigma_x": 31, "bmatrix": 31, "r_y": 31, "phi_2": 31, "sigma_i": 31, "\u03c8": 31, "\u03c3_z": 31, "sigma_z": 31, "\u03d5_1": 31, "\u03d5_2": 31, "mid": 31, "easili": 31, "13551": 31, "1822": 31, "1085": 31, "1640": 31, "11729": [31, 34], "7442": 31, "cu118": [31, 34], "torchdiffeq": 31, "eta": [31, 34], "cp310": [31, 34], "contourpi": [31, 34], "could": [31, 34], "py310": [31, 34], "filelock": [31, 34], "jinja2": [31, 34], "triton": [31, 34], "cmake": [31, 34], "lit": [31, 34], "py39": [31, 34], "2023": 31, "markupsaf": [31, 34], "manylinux_2_28_x86_64": 31, "pyspnego": [31, 34], "rustworkx": [31, 34], "12128": [31, 34], "7a54933fa9c2e1b1caffdc6129aa17723a1f8a19655b68eb148d3b916a542664": 31, "9c": [31, 34], "b0": [31, 34], "d6281e20610c76a5f88c9b931c6b338410f70b4ba6561453bc": [31, 34], "136820": [31, 34], "087f5465344ad90f93c062a3e9d3224bf3afdb393350b74383207ecbe6a0509b": 31, "d3": [31, 34], "8b": [31, 34], "e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5": [31, 34], "must": 31, "restart": 31, "device_nam": 31, "record_op": [31, 169], "accept": 31, "explor": 31, "few": 31, "belong": 31, "qibit": 31, "quantumgraph": [31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "bmm": [31, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "expval_joint_analyt": [31, 169], "expval_joint_sampl": [31, 169], "joint": 31, "analyt": [31, 169], "statevector": [31, 38, 39, 169], "bistr": 31, "shot": 31, "exp_a": 31, "exp_": 31, "8515": 31, "8184": 31, "increas": 31, "ad": 31, "afterward": 31, "5104": 31, "1027": 31, "eigenvector": 31, "\u03bb": 31, "fashion": 31, "optimizationmodel": 31, "produc": 31, "outcom": 31, "bound": 31, "descent": 31, "entir": 31, "012099898420274258": 31, "013199898414313793": 31, "013309753499925137": 31, "014519752934575081": 31, "014640549197793007": 31, "015971548855304718": 31, "01610436476767063": 31, "017568465322256088": 31, "01771448366343975": 31, "01932499371469021": 31, "019485509023070335": 31, "02125706896185875": 31, "021433496847748756": 31, "023382212966680527": 31, "023576095700263977": 31, "02571968361735344": 31, "025932706892490387": 31, "028290653601288795": 31, "028524650260806084": 31, "03111839108169079": 31, "9992638230323792": 31, "031375348567962646": 31, "03422846272587776": 31, "0345105305314064": 31, "03764895722270012": 31, "037958454340696335": 31, "041410721838474274": 31, "04175013676285744": 31, "04554762691259384": 31, "04591960832476616": 31, "050096847116947174": 31, "05050419643521309": 31, "055099159479141235": 31, "05554480850696564": 31, "06059926748275757": 31, "06108624115586281": 31, "06664614379405975": 31, "06717751175165176": 31, "07329340279102325": 31, "07387219369411469": 31, "08059966564178467": 31, "9950657486915588": 31, "08122873306274414": 31, "08862894773483276": 31, "08931083232164383": 31, "09745106101036072": 31, "09818772971630096": 31, "10714197158813477": 31, "10793451964855194": 31, "11778417229652405": 31, "11863239109516144": 31, "12946699559688568": 31, "13036876916885376": 31, "14228680729866028": 31, "14323736727237701": 31, "15634718537330627": 31, "15733805298805237": 31, "17175881564617157": 31, "172776460647583": 31, "18863925337791443": 31, "18966329097747803": 31, "20711229741573334": 31, "9676356315612793": 31, "20811320841312408": 31, "2273070216178894": 31, "2282431572675705": 31, "2493562251329422": 31, "2501700222492218": 31, "27339422702789307": 31, "2740074098110199": 31, "29955384135246277": 31, "2998615801334381": 31, "32796236872673035": 31, "32782599329948425": 31, "35873648524284363": 31, "3579748272895813": 31, "39197587966918945": 31, "3903552293777466": 31, "427755743265152": 31, "42497843503952026": 31, "46611812710762024": 31, "4618101119995117": 31, "5070626139640808": 31, "8138567805290222": 31, "5007606744766235": 31, "5505368709564209": 31, "5416762828826904": 31, "5964280366897583": 31, "5843320488929749": 31, "6445562839508057": 31, "6284285187721252": 31, "6946715116500854": 31, "6735928058624268": 31, "7464552521705627": 31, "7193858623504639": 31, "7995281219482422": 31, "7653157711029053": 31, "8534636497497559": 31, "8108565211296082": 31, "9078077673912048": 31, "8554709553718567": 31, "9621021151542664": 31, "8986347317695618": 31, "0159088373184204": 31, "3750203549861908": 31, "9398593902587891": 31, "0688340663909912": 31, "9787107706069946": 31, "1205471754074097": 31, "0148218870162964": 31, "1707944869995117": 31, "0478986501693726": 31, "2194054126739502": 31, "0777196884155273": 31, "2662931680679321": 31, "1041301488876343": 31, "311449408531189": 31, "127032995223999": 31, "354935884475708": 31, "1463772058486938": 31, "3968735933303833": 31, "1621465682983398": 31, "4374314546585083": 31, "1743487119674683": 31, "4768157005310059": 31, "052838265895843506": 31, "1830050945281982": 31, "5152597427368164": 31, "1881437301635742": 31, "553015947341919": 31, "1897931098937988": 31, "590348243713379": 31, "1879782676696777": 31, "6275262832641602": 31, "1827187538146973": 31, "6648198366165161": 31, "1740283966064453": 31, "702493667602539": 31, "1619168519973755": 31, "7408030033111572": 31, "146392583847046": 31, "7799879312515259": 31, "1274679899215698": 31, "820267915725708": 31, "1051654815673828": 31, "8618348836898804": 31, "10590392351150513": 31, "0795255899429321": 31, "9048453569412231": 31, "0506160259246826": 31, "9494123458862305": 31, "018541693687439": 31, "9955958127975464": 31, "9834545850753784": 31, "043394088745117": 31, "9455628991127014": 31, "0927350521087646": 31, "9051381945610046": 31, "1434707641601562": 31, "8625186085700989": 31, "1953752040863037": 31, "8181073665618896": 31, "2481465339660645": 31, "7723652124404907": 31, "30141544342041": 31, "7257967591285706": 31, "354759931564331": 31, "4779837727546692": 31, "6789312362670898": 31, "4077253341674805": 31, "6322994232177734": 31, "459847927093506": 31, "5864096879959106": 31, "5106801986694336": 31, "5417252779006958": 31, "5598134994506836": 31, "4986463487148285": 31, "6068966388702393": 31, "4574976861476898": 31, "6516494750976562": 31, "4185234606266022": 31, "6938676834106445": 31, "38188809156417847": 31, "7334227561950684": 31, "34768232703208923": 31, "770256519317627": 31, "31593260169029236": 31, "8043713569641113": 31, "876086413860321": 31, "28661224246025085": 31, "835820436477661": 31, "25965315103530884": 31, "8646953105926514": 31, "23495660722255707": 31, "891116142272949": 31, "21240299940109253": 31, "915221691131592": 31, "1918598860502243": 31, "937161445617676": 31, "1731884628534317": 31, "957089900970459": 31, "156248539686203": 31, "97516131401062": 31, "14090220630168915": 31, "991525888442993": 31, "12701639533042908": 31, "0063281059265137": 31, "11446458846330643": 31, "019704818725586": 31, "9828835129737854": 31, "1031278446316719": 31, "0317838191986084": 31, "09289533644914627": 31, "042684316635132": 31, "08366449177265167": 31, "052516460418701": 31, "07534093409776688": 31, "0613811016082764": 31, "0678381696343422": 31, "069370985031128": 31, "06107722595334053": 31, "0765702724456787": 31, "054986197501420975": 31, "0830557346343994": 31, "0494997613132": 31, "088897228240967": 31, "04455867409706116": 31, "0941579341888428": 31, "040109291672706604": 31, "0988948345184326": 31, "997883677482605": 31, "03610309213399887": 31, "1031599044799805": 31, "03249623253941536": 31, "106999635696411": 31, "029249126091599464": 31, "1104564666748047": 31, "026326047256588936": 31, "1135683059692383": 31, "023694779723882675": 31, "1163694858551025": 31, "021326277405023575": 31, "1188907623291016": 31, "019194360822439194": 31, "1211602687835693": 31, "01727544330060482": 31, "1232030391693115": 31, "015548276714980602": 31, "1250417232513428": 31, "013993724249303341": 31, "1266965866088867": 31, "9997422099113464": 31, "012594552710652351": 31, "128185987472534": 31, "011335243470966816": 31, "1295266151428223": 31, "010201825760304928": 31, "130733013153076": 31, "00918172113597393": 31, "131819009780884": 31, "008263605646789074": 31, "132796287536621": 31, "0074372864328324795": 31, "1336758136749268": 31, "006693588104099035": 31, "134467363357544": 31, "006024251226335764": 31, "1351797580718994": 31, "005421841982752085": 31, "1358211040496826": 31, "004879669286310673": 31, "1363983154296875": 31, "9999685883522034": 31, "004391710739582777": 31, "13691782951355": 31, "0039525460451841354": 31, "137385368347168": 31, "0035572960041463375": 31, "1378061771392822": 31, "003201569663360715": 31, "1381847858428955": 31, "0028814151883125305": 31, "1385254859924316": 31, "0025932753924280405": 31, "1388320922851562": 31, "002333949087187648": 31, "139108180999756": 31, "002100554993376136": 31, "1393566131591797": 31, "0018905001925304532": 31, "139580249786377": 31, "0017014506738632917": 31, "1397814750671387": 31, "9999963045120239": 31, "001531305955722928": 31, "139962673187256": 31, "0013781756861135364": 31, "1401257514953613": 31, "0012403583386912942": 31, "140272378921509": 31, "0011163227027282119": 31, "140404462814331": 31, "0010046905372291803": 31, "1405231952667236": 31, "0009042215533554554": 31, "1406302452087402": 31, "0008137994445860386": 31, "1407265663146973": 31, "0007324195466935635": 31, "140813112258911": 31, "0006591776036657393": 31, "1408910751342773": 31, "0005932598724029958": 31, "140961170196533": 31, "9999995231628418": 31, "0005339339259080589": 31, "141024351119995": 31, "00048054056242108345": 31, "1410810947418213": 31, "000432486500358209": 31, "141132354736328": 31, "00038923785905353725": 31, "1411783695220947": 31, "00035031407605856657": 31, "1412198543548584": 31, "0003152826684527099": 31, "1412570476531982": 31, "0002837544016074389": 31, "1412906646728516": 31, "0002553789527155459": 31, "1413209438323975": 31, "00022984105453360826": 31, "141348123550415": 31, "00020685694471467286": 31, "1413726806640625": 31, "0001861712516983971": 31, "14139461517334": 31, "0001675541279837489": 31, "1414144039154053": 31, "00015079871809575707": 31, "141432285308838": 31, "00013571884483098984": 31, "1414482593536377": 31, "0001221469574375078": 31, "141462802886963": 31, "00010993226169375703": 31, "1414756774902344": 31, "893903188640252e": 31, "1414873600006104": 31, "904512651497498e": 31, "141497850418091": 31, "014061313588172e": 31, "141507387161255": 31, "212655327748507e": 31, "1415159702301025": 31, "491389649454504e": 31, "141523599624634": 31, "8422505389899015e": 31, "1415305137634277": 31, "258025339571759e": 31, "1415367126464844": 31, "732222805614583e": 31, "1415421962738037": 31, "2590003431541845e": 31, "141547203063965": 31, "833100345218554e": 31, "1415517330169678": 31, "4497901651775464e": 31, "1415557861328125": 31, "10481118503958e": 31, "141559362411499": 31, "794330066535622e": 31, "1415627002716064": 31, "5148970962618478e": 31, "1415657997131348": 31, "263407441205345e": 31, "141568422317505": 31, "0370667698443867e": 31, "141570806503296": 31, "83336014742963e": 31, "141572952270508": 31, "6500242054462433e": 31, "1415748596191406": 31, "485021766711725e": 31, "1415765285491943": 31, "3365195627557114e": 31, "141578197479248": 31, "2028675882902462e": 31, "1415796279907227": 31, "0825808203662746e": 31, "141580820083618": 31, "743227565195411e": 31, "1415820121765137": 31, "76890499057481e": 31, "14158296585083": 31, "89201476436574e": 31, "1415839195251465": 31, "1028134698281065e": 31, "141584873199463": 31, "392532213794766e": 31, "1415855884552": 31, "753278855991084e": 31, "1415863037109375": 31, "177951152290916e": 31, "141587018966675": 31, "660155809688149e": 31, "141587495803833": 31, "194140274194069e": 31, "141587972640991": 31, "7747263377241325e": 31, "1415884494781494": 31, "3972537494264543e": 31, "1415889263153076": 31, "057528374483809e": 31, "141589403152466": 31, "substitut": 31, "theoret": 31, "inde": 31, "huge": 32, "qasm": [32, 169], "pickl": 32, "trial": 32, "effect": 32, "ablat": 32, "layer1": 32, "layer3": 32, "onlygf": 32, "wogateerror": 32, "wogateindex": 32, "wogatetyp": 32, "wogf": 32, "woqubitindex": 32, "wot1t2": 32, "t1": 32, "t2": 32, "geometr": 32, "commun": [33, 34], "protocol": [33, 34], "transmiss": [33, 34], "abil": [33, 34], "superposit": [33, 34], "charl": [33, 34], "bennett": [33, 34], "stephen": [33, 34], "wiesner": [33, 34], "1970": [33, 34], "though": [33, 34], "1992": [33, 34], "experiment": [33, 34], "realis": [33, 34], "klau": [33, 34], "mattl": [33, 34], "harald": [33, 34], "weinfurt": [33, 34], "paul": [33, 34], "kwiat": [33, 34], "anton": [33, 34], "zeiling": [33, 34], "utilis": [33, 34], "photon": [33, 34], "soham": [33, 34], "bopardikar": [33, 34], "brassard": [33, 34], "cr\u00e9peau": [33, 34], "jozsa": [33, 34], "pere": [33, 34], "wootter": [33, 34], "1993": [33, 34], "teleport": [33, 34], "unknown": [33, 34], "dual": [33, 34], "einstein": [33, 34], "podolski": [33, 34], "rosen": [33, 34], "review": [33, 34], "letter": [33, 34], "1895": [33, 34], "particl": [33, 34], "2881": [33, 34], "q0": 34, "sender": 34, "q1": 34, "conduct": 34, "bob": 34, "alic": 34, "leftmost": 34, "he": 34, "serv": 34, "rightmost": 34, "eventu": 34, "crucial": 34, "12494": 34, "6780": 34, "4f7f0a0ad10fc979b9d35c9ab5851f0edc5c4661e807161ab1b13170575857c8": 34, "27ea7bd84314063cf13f0bc9b2890f6314fa9969d41ba1bd4ac5be1c7ccae66c": 34, "bell_pair": 34, "encrypt": 34, "transmit": 34, "encode_messag": 34, "issubset": 34, "valueerror": 34, "invalid": 34, "she": 34, "correspond": 34, "hi": 34, "decode_messag": 34, "togeth": 34, "collaps": 34, "wikipedia": 34, "predefin": 35, "ininti": 35, "train_state_prep": 35, "h2": 36, "simple_vq": [36, 169], "toffoli": [40, 41], "cu1": 43, "echo": [56, 57], "reson": [56, 57], "stub": [56, 57], "ecrgat": [56, 57], "phaseshift": [58, 64], "xcnot": 63, "excit": 83, "rzx": 96, "scalabl": 169, "come": 169, "soon": 169, "research": 169, "tersor": 169, "slack": 169, "contribut": 169, "question": 169, "qmlsy": 169, "goe": 169, "onlin": 169, "edu": 169, "op_history2qasm": 169, "stochast": 169, "doabl": 169, "expval_sampl": 169, "zx": 169, "qaoa": 169, "encoder_g": 169, "domain": 169, "quito": 169, "script": 169, "simple_mnist": 169, "descript": 169, "templat": 169, "convertor": 169, "ensur": 169, "common": 169, "mistak": 169, "codebas": 169, "enabl": 169, "hpca": 169, "quantumna": 169, "search": 169, "dac": 169, "quantumnat": 169, "inject": 169, "quantiz": 169, "qce": 169, "liang": 169, "iccad": 169, "hu": 169, "quest": 169, "icml": 169, "workshop": 169, "yun": 169, "slimmabl": 169, "feder": 169, "icdc": 169, "reinforc": 169, "manuscript": 169, "baek": 169, "3d": 169, "cloud": 169, "meta": 169, "concurr": 169, "configargpars": 169, "nvidia": 169, "jiannan": 169, "cao": 169, "jessica": 169, "ding": 169, "jiai": 169, "gu": 169, "song": 169, "zhirui": 169, "zhide": 169, "pengyu": 169, "yilian": 169, "zhepeng": 169, "zhuoyang": 169, "ye": 169, "inproceed": 169, "hanruiwang2022quantumna": 169, "yongshan": 169, "jiaqi": 169, "lin": 169, "yujun": 169, "pan": 169, "david": 169, "chong": 169, "freder": 169, "booktitl": 169, "28th": 169, "year": 169}, "objects": {"": [[3, 0, 0, "-", "torchquantum"]], "torchquantum": [[97, 0, 0, "-", "functional"]], "torchquantum.functional": [[38, 1, 1, "", "apply_unitary_bmm"], [39, 1, 1, "", "apply_unitary_einsum"], [40, 1, 1, "", "ccnot"], [41, 1, 1, "", "ccx"], [42, 1, 1, "", "cnot"], [43, 1, 1, "", "cp"], [44, 1, 1, "", "crot"], [45, 1, 1, "", "crx"], [46, 1, 1, "", "cry"], [47, 1, 1, "", "crz"], [48, 1, 1, "", "cswap"], [49, 1, 1, "", "cu"], [50, 1, 1, "", "cu1"], [51, 1, 1, "", "cu2"], [52, 1, 1, "", "cu3"], [53, 1, 1, "", "cx"], [54, 1, 1, "", "cy"], [55, 1, 1, "", "cz"], [56, 1, 1, "", "echoedcrossresonance"], [57, 1, 1, "", "ecr"], [58, 1, 1, "", "gate_wrapper"], [59, 1, 1, "", "hadamard"], [60, 1, 1, "", "i"], [61, 1, 1, "", "multicnot"], [62, 1, 1, "", "multirz"], [63, 1, 1, "", "multixcnot"], [64, 1, 1, "", "p"], [65, 1, 1, "", "paulix"], [66, 1, 1, "", "pauliy"], [67, 1, 1, "", "pauliz"], [68, 1, 1, "", "phaseshift"], [69, 1, 1, "", "qubitunitary"], [70, 1, 1, "", "qubitunitaryfast"], [71, 1, 1, "", "qubitunitarystrict"], [72, 1, 1, "", "reset"], [73, 1, 1, "", "rot"], [74, 1, 1, "", "rx"], [75, 1, 1, "", "rxx"], [76, 1, 1, "", "ry"], [77, 1, 1, "", "ryy"], [78, 1, 1, "", "rz"], [79, 1, 1, "", "rzx"], [80, 1, 1, "", "rzz"], [81, 1, 1, "", "s"], [82, 1, 1, "", "shadamard"], [83, 1, 1, "", "singleexcitation"], [84, 1, 1, "", "sswap"], [85, 1, 1, "", "swap"], [86, 1, 1, "", "sx"], [87, 1, 1, "", "t"], [88, 1, 1, "", "toffoli"], [89, 1, 1, "", "u"], [90, 1, 1, "", "u1"], [91, 1, 1, "", "u2"], [92, 1, 1, "", "u3"], [93, 1, 1, "", "x"], [94, 1, 1, "", "y"], [95, 1, 1, "", "z"], [96, 1, 1, "", "zx"], [97, 1, 1, "", "zz"]]}, "objtypes": {"0": "py:module", "1": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "method", "Python method"]}, "titleterms": {"torchquantum": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 21, 23, 29, 31, 37, 169], "function": [0, 7, 10, 21], "layer": [1, 26, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114], "oper": [2, 5, 9, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168], "class": [2, 7, 10], "iccad": 4, "2022": [4, 8], "tutori": [4, 7, 8, 10, 17, 30, 31], "slide": [4, 8], "section": [4, 8], "1": [4, 5, 6, 7, 8, 9, 10, 11, 34], "basic": [4, 5, 8, 9, 169], "usag": [4, 8, 36, 169], "2": [4, 5, 6, 7, 8, 9, 10, 11, 13, 21, 34], "us": [4, 6, 8, 21, 169], "puls": [4, 6, 8, 11], "level": [4, 6, 7, 8, 10, 11], "optim": [4, 6, 8, 11, 31], "3": [4, 5, 7, 8, 9, 10, 11, 34], "gate": [4, 7, 8, 10], "setup": [5, 6, 7, 9, 10, 11, 25, 26], "state": [5, 9, 34, 35], "prepar": [5, 9, 34, 35], "circuit": [5, 7, 9, 10, 17, 23, 31, 35], "4": [5, 7, 9, 34], "vqe": [5, 6, 9, 11, 36, 169], "5": [5, 9, 10], "qnn": [5, 7, 9, 10, 13, 14, 19], "section2": 6, "quantum": [6, 11, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "control": [6, 11], "variat": [6, 11], "learn": [6, 11], "nativ": [6, 11], "build": [6, 7, 10, 11, 21, 23, 25, 26, 29], "up": [6, 11, 17], "model": [6, 7, 10, 11, 13, 21, 26, 29], "usa": [7, 10], "quantumna": [7, 10], "search": [7, 10, 16], "prune": [7, 10, 14, 15], "part": [7, 10], "best": [7, 10], "gene": [7, 10], "quantumnat": [7, 10], "nois": [7, 10], "awar": [7, 10, 13], "param": [7, 10], "train": [7, 10, 13, 14, 19, 20, 21, 25, 26, 29, 35], "compress": [7, 10], "lut": [7, 10], "construct": [7, 10, 31], "test": [7, 10, 17], "script": [7, 10], "reconstruct": [7, 10], "gener": [7, 10], "dataset": [7, 10, 23, 29], "reconstrut": [7, 10], "admm": [7, 10], "input": [7, 10], "mask": [7, 10], "retrain": [7, 10], "finetun": [7, 10, 13], "qce": 8, "section3_us": 11, "exampl": [12, 18, 32, 36, 37, 169], "welcom": [12, 37, 169], "contribut": [12, 37], "clifford": 13, "mnist": [13, 19, 28, 29, 169], "classif": [13, 21, 23, 28, 29], "todo": 13, "float": 13, "perform": 13, "static": 13, "quantiz": 13, "probabilist": [14, 15], "gradient": [14, 15, 17, 21, 31], "effici": 14, "outlin": [14, 15, 20, 22, 28, 29], "introduct": [15, 20, 22, 26, 28, 29], "accumul": 15, "window": 15, "import": [15, 31, 34], "modul": [15, 34], "plot": [15, 21, 25], "compar": [15, 21, 29], "accuraci": 15, "curv": 15, "grover": 16, "": [16, 81, 155], "algorithm": 16, "refer": [16, 33, 34], "hadamard": [17, 59, 131], "base": 17, "estim": 17, "set": 17, "run": 17, "simpl": [19, 21, 36], "On": 20, "chip": 20, "neural": [20, 28, 29], "network": [20, 28, 29], "paramet": [20, 21], "shift": [20, 21], "rule": [20, 21], "back": 20, "propag": 20, "appli": 21, "A": 21, "qubit": [21, 30, 31, 34], "task": 21, "kernel": [22, 23], "method": [22, 23], "how": 22, "evalu": [22, 29], "distanc": 22, "hilbert": 22, "space": 22, "iri": 23, "ansatz": 23, "consist": 23, "unitari": 23, "its": 23, "transpos": 23, "conjug": 23, "whole": [23, 26, 29], "lstm": [24, 25], "author": [24, 27, 33], "instal": [25, 26, 29, 34, 169, 170], "pos_tag": 25, "histori": 25, "refrenc": [25, 26], "transform": [26, 27], "multihead": 26, "attent": 26, "feedforwrad": 26, "hybrid": [26, 29], "classic": [26, 29], "convolut": [28, 29], "quanvolut": [28, 29], "imag": [28, 29], "step": [29, 34], "filter": 29, "load": 29, "real": 29, "comput": 29, "trainabl": 29, "rotat": [30, 31], "The": 31, "creat": 31, "devic": 31, "calcul": 31, "predict_quantum_acc": 32, "data_set": 32, "albat": 32, "studi": 32, "environ": 32, "superdens": [33, 34], "code": [33, 34, 169], "entangl": 34, "bell": 34, "pair": 34, "encod": 34, "messag": 34, "decod": 34, "measur": 34, "apply_unitary_bmm": 38, "apply_unitary_einsum": 39, "ccnot": 40, "ccx": 41, "cnot": [42, 117], "cp": 43, "crot": [44, 121], "crx": [45, 118], "cry": [46, 119], "crz": [47, 120], "cswap": [48, 122], "cu": 49, "cu1": [50, 123], "cu2": [51, 124], "cu3": [52, 125], "cx": 53, "cy": [54, 126], "cz": [55, 127], "echoedcrossreson": [56, 130], "ecr": [57, 129], "gate_wrapp": 58, "i": [60, 132], "multicnot": [61, 133], "multirz": [62, 134], "multixcnot": [63, 135], "p": 64, "paulix": [65, 140], "paulii": [66, 141], "pauliz": [67, 142], "phaseshift": [68, 143], "qubitunitari": [69, 144], "qubitunitaryfast": [70, 145], "qubitunitarystrict": 71, "reset": [72, 153], "rot": [73, 154], "rx": [74, 146], "rxx": [75, 147], "ry": [76, 148], "ryi": [77, 149], "rz": [78, 150], "rzx": [79, 151], "rzz": [80, 152], "shadamard": [82, 156], "singleexcit": [83, 160], "sswap": [84, 157], "swap": [85, 158], "sx": [86, 159], "t": [87, 161], "toffoli": [88, 162], "u": 89, "u1": [90, 165], "u2": [91, 166], "u3": [92, 167], "x": 93, "y": 94, "z": 95, "zx": 96, "zz": 97, "cxcxcxlayer": 98, "cxlayer": 99, "classicalinopal": 100, "fixedopal": 101, "op1qalllay": 102, "op2qalllay": 103, "op2qbutterflylay": 104, "op2qdenselay": 105, "qftlayer": 106, "quantummodulefromop": 107, "rxyzcxlayer0": 108, "randomlay": 109, "randomlayeralltyp": 110, "randomop1al": 111, "swapswaplay": 112, "trainableopal": 113, "twoqal": 114, "allwir": 115, "anywir": 116, "diagonaloper": 128, "nparamsenum": 136, "observ": 137, "trainableunitari": 163, "trainableunitarystrict": 164, "wiresenum": 168, "api": 169, "what": 169, "doe": 169, "who": 169, "benefit": 169, "differ": 169, "from": 169, "qiskit": 169, "pennylan": 169, "new": 169, "featur": 169, "guid": 169, "file": 169, "style": 169, "paper": 169, "depend": 169, "contact": 169, "contributor": 169, "citat": 169}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "nbsphinx": 4, "sphinx": 60}, "alltitles": {"torchquantum.functional": [[0, "module-torchquantum.functional"]], "Functions": [[0, "functions"]], "torchquantum.layers": [[1, "torchquantum-layers"]], "Layers": [[1, "layers"]], "torchquantum.operators": [[2, "torchquantum-operators"]], "Classes": [[2, "classes"]], "torchquantum": [[3, "module-torchquantum"]], "ICCAD 2022 Tutorial [slides]": [[4, "iccad-2022-tutorial-slides"]], "Section 1: TorchQuantum Basic Usage: ": [[4, "section-1-torchquantum-basic-usage"], [8, "section-1-torchquantum-basic-usage"]], "Section 2: Use TorchQuantum on Pulse Level Optimizations: ": [[4, "section-2-use-torchquantum-on-pulse-level-optimizations"]], "Section 3: Use TorchQuantum on Gate Level Optimizations: ": [[4, "section-3-use-torchquantum-on-gate-level-optimizations"]], "Setup": [[5, "Setup"], [6, "Setup"], [7, "Setup"], [7, "id1"], [7, "id2"], [7, "id4"], [9, "Setup"], [10, "Setup"], [10, "id1"], [10, "id2"], [10, "id4"], [11, "Setup"], [25, "Setup"], [26, "Setup"]], "1. TorchQuantum basic operations": [[5, "1.-TorchQuantum-basic-operations"], [9, "1.-TorchQuantum-basic-operations"]], "1.2 TorchQuantum Operations": [[5, "1.2-TorchQuantum-Operations"], [9, "1.2-TorchQuantum-Operations"]], "1.3 TorchQuantum for state preparation circuit": [[5, "1.3-TorchQuantum-for-state-preparation-circuit"], [9, "1.3-TorchQuantum-for-state-preparation-circuit"]], "1.4 TorchQuantum for VQE circuit": [[5, "1.4-TorchQuantum-for-VQE-circuit"], [9, "1.4-TorchQuantum-for-VQE-circuit"]], "1.5 TorchQuantum for QNN circuit": [[5, "1.5-TorchQuantum-for-QNN-circuit"], [9, "1.5-TorchQuantum-for-QNN-circuit"]], "Section2 Use Torchquantum on Pulse Level": [[6, "Section2-Use-Torchquantum-on-Pulse-Level"]], "2.1 Quantum Optimal Control": [[6, "2.1-Quantum-Optimal-Control"]], "2.2 Variational Pulse Learning": [[6, "2.2-Variational-Pulse-Learning"]], "Native Pulse Build-up": [[6, "Native-Pulse-Build-up"], [11, "Native-Pulse-Build-up"]], "VQE Model Setup": [[6, "VQE-Model-Setup"], [11, "VQE-Model-Setup"]], "3. Usa TorchQuantum on the gate level": [[7, "3.-Usa-TorchQuantum-on-the-gate-level"]], "3.1 QuantumNAS: Circuit Search and Pruning": [[7, "3.1-QuantumNAS:-Circuit-Search-and-Pruning"]], "Part 1: Search for the best gene": [[7, "Part-1:-Search-for-the-best-gene"], [10, "Part-1:-Search-for-the-best-gene"]], "3.2 QuantumNAT: Noise Aware Param Training": [[7, "3.2-QuantumNAT:-Noise-Aware-Param-Training"]], "Tutorial 1.4: QNN Compression": [[7, "Tutorial-1.4:-QNN-Compression"]], "Tutorial 1.4.1: LUT Construction": [[7, "Tutorial-1.4.1:-LUT-Construction"]], "Test Script": [[7, "Test-Script"], [7, "id3"], [10, "Test-Script"], [10, "id3"]], "Tutorial 1.4.2: LUT Reconstruction": [[7, "Tutorial-1.4.2:-LUT-Reconstruction"]], "Generate dataset": [[7, "Generate-dataset"], [10, "Generate-dataset"]], "Class: Build a model": [[7, "Class:-Build-a-model"], [10, "Class:-Build-a-model"]], "Function: Test on a dataset": [[7, "Function:-Test-on-a-dataset"], [10, "Function:-Test-on-a-dataset"]], "Functions for LUT reconstrution": [[7, "Functions-for-LUT-reconstrution"], [10, "Functions-for-LUT-reconstrution"]], "Tutorial 1.4.3: ADMM Training and compression": [[7, "Tutorial-1.4.3:-ADMM-Training-and-compression"]], "Class: ADMM": [[7, "Class:-ADMM"], [10, "Class:-ADMM"]], "Function: ADMM train and test": [[7, "Function:-ADMM-train-and-test"], [10, "Function:-ADMM-train-and-test"]], "Input for ADMM training": [[7, "Input-for-ADMM-training"], [10, "Input-for-ADMM-training"]], "ADMM training": [[7, "ADMM-training"], [10, "ADMM-training"]], "Masked retraining (finetuning)": [[7, "Masked-retraining-(finetuning)"], [10, "Masked-retraining-(finetuning)"]], "QCE 2022 Tutorial [slides]": [[8, "qce-2022-tutorial-slides"]], "Section 2: Use TorchQuantum on Gate Level Optimizations: ": [[8, "section-2-use-torchquantum-on-gate-level-optimizations"]], "Section 3: Use TorchQuantum on Pulse Level Optimizations: ": [[8, "section-3-use-torchquantum-on-pulse-level-optimizations"]], "2. Usa TorchQuantum on the gate level": [[10, "2.-Usa-TorchQuantum-on-the-gate-level"]], "2.1 QuantumNAS: Circuit Search and Pruning": [[10, "2.1-QuantumNAS:-Circuit-Search-and-Pruning"]], "2.2 QuantumNAT: Noise Aware Param Training": [[10, "2.2-QuantumNAT:-Noise-Aware-Param-Training"]], "Tutorial 2.5: QNN Compression": [[10, "Tutorial-2.5:-QNN-Compression"]], "Tutorial 2.5.1: LUT Construction": [[10, "Tutorial-2.5.1:-LUT-Construction"]], "Tutorial 2.5.2: LUT Reconstruction": [[10, "Tutorial-2.5.2:-LUT-Reconstruction"]], "Tutorial 2.5.3: ADMM Training and compression": [[10, "Tutorial-2.5.3:-ADMM-Training-and-compression"]], "Section3_Use Torchquantum on Pulse Level": [[11, "Section3_Use-Torchquantum-on-Pulse-Level"]], "3.1 Quantum Optimal Control": [[11, "3.1-Quantum-Optimal-Control"]], "3.2 Variational Pulse Learning": [[11, "3.2-Variational-Pulse-Learning"]], "TorchQuantum Examples": [[12, "torchquantum-examples"], [18, "torchquantum-examples"], [37, "torchquantum-examples"]], "Welcome to contribute!": [[12, "welcome-to-contribute"], [37, "welcome-to-contribute"]], "Clifford QNN for MNIST-2 classification": [[13, "clifford-qnn-for-mnist-2-classification"]], "TODOs": [[13, "todos"]], "Train the model in floating and then perform static quantization:": [[13, "train-the-model-in-floating-and-then-perform-static-quantization"]], "Train the model in floating and then perform quantization-aware finetuning:": [[13, "train-the-model-in-floating-and-then-perform-quantization-aware-finetuning"]], "Probabilistic Gradient Pruning for Efficient QNN Training": [[14, "probabilistic-gradient-pruning-for-efficient-qnn-training"]], "Outline": [[14, "outline"], [15, "Outline"], [20, "outline"], [22, "outline"], [28, "outline"], [29, "Outline"]], "Probabilistic gradient pruning": [[15, "Probabilistic-gradient-pruning"]], "Introduction to probabilistic gradient pruning": [[15, "Introduction-to-probabilistic-gradient-pruning"]], "Accumulation Window and Pruning Window": [[15, "Accumulation-Window-and-Pruning-Window"]], "Import modules": [[15, "Import-modules"]], "Plot and compare the accuracy curves": [[15, "Plot-and-compare-the-accuracy-curves"]], "Grover\u2019s Search Algorithm": [[16, "grover-s-search-algorithm"]], "References": [[16, "references"], [33, "references"]], "Tutorial on Hadamard Test Based Gradient Estimation": [[17, "Tutorial-on-Hadamard-Test-Based-Gradient-Estimation"]], "Set Up": [[17, "Set-Up"]], "Run Circuit": [[17, "Run-Circuit"]], "Gradient Estimation": [[17, "Gradient-Estimation"]], "Simple QNN for MNIST Training": [[19, "simple-qnn-for-mnist-training"]], "On-chip Training of Quantum Neural Networks with parameter shift": [[20, "on-chip-training-of-quantum-neural-networks-with-parameter-shift"]], "Introduction to Parameters Shift Rules": [[20, "introduction-to-parameters-shift-rules"]], "Back Propagation": [[20, "back-propagation"]], "Parameters Shift Rules": [[20, "parameters-shift-rules"]], "Apply parameters shift rules to train quantum model using TorchQuantum.": [[21, "Apply-parameters-shift-rules-to-train-quantum-model-using-TorchQuantum."]], "Build a quantum model": [[21, "Build-a-quantum-model"]], "Build the function of parameters shift rules": [[21, "Build-the-function-of-parameters-shift-rules"]], "Plot and compare the gradients": [[21, "Plot-and-compare-the-gradients"]], "A simple 2 qubit model for a simple 2 classification task": [[21, "A-simple-2-qubit-model-for-a-simple-2-classification-task"]], "Quantum Kernel Method": [[22, "quantum-kernel-method"]], "Introduction to Quantum Kernel Methods.": [[22, "introduction-to-quantum-kernel-methods"]], "Kernel Methods": [[22, "kernel-methods"]], "Quantum Kernel": [[22, "quantum-kernel"]], "How to evaluate the distance in Hilbert space?": [[22, "how-to-evaluate-the-distance-in-hilbert-space"]], "Quantum Kernel Methods for IRIS dataset classification with TorchQuantum.": [[23, "Quantum-Kernel-Methods-for-IRIS-dataset-classification-with-TorchQuantum."]], "Build the Ansatz, consist of a unitary and its transpose conjugation.": [[23, "Build-the-Ansatz,-consist-of-a-unitary-and-its-transpose-conjugation."]], "Build the whole quantum circuit": [[23, "Build-the-whole-quantum-circuit"]], "Quantum LSTM": [[24, "quantum-lstm"]], "Authors": [[24, "authors"], [27, "authors"]], "Build and train a Quantum LSTM.": [[25, "Build-and-train-a-Quantum-LSTM."]], "Installation": [[25, "Installation"], [26, "Installation"], [29, "Installation"], [34, "Installation"], [169, "installation"], [170, "installation"]], "Build Quantum LSTM": [[25, "Build-Quantum-LSTM"]], "POS_tagging": [[25, "POS_tagging"]], "Training": [[25, "Training"]], "Plot the training history": [[25, "Plot-the-training-history"]], "Refrences": [[25, "Refrences"], [26, "Refrences"]], "Introduction to Transformer": [[26, "Introduction-to-Transformer"]], "Quantum Transformer": [[26, "Quantum-Transformer"], [27, "quantum-transformer"]], "Build and train a Quantum Transformer.": [[26, "Build-and-train-a-Quantum-Transformer."]], "Build MultiHead Attention": [[26, "Build-MultiHead-Attention"]], "Build FeedForwrad Layer": [[26, "Build-FeedForwrad-Layer"]], "Build the whole hybrid transformer model.": [[26, "Build-the-whole-hybrid-transformer-model."]], "Training Classical transformer": [[26, "Training-Classical-transformer"]], "Training Quantum transformer": [[26, "Training-Quantum-transformer"]], "Quantum Convolution": [[28, "quantum-convolution"]], "Quantum Convolution (Quanvolution) for MNIST image classification": [[28, "quantum-convolution-quanvolution-for-mnist-image-classification"]], "Introduction to Quanvolutional Neural Network.": [[28, "introduction-to-quanvolutional-neural-network"], [29, "Introduction-to-Quanvolutional-Neural-Network."]], "Convolutional Neural Network": [[28, "convolutional-neural-network"], [29, "Convolutional-Neural-Network"]], "Quantum convolution": [[28, "id1"], [29, "Quantum-convolution"]], "Quanvolution (Quantum convolution) for MNIST image classification with TorchQuantum.": [[29, "Quanvolution-(Quantum-convolution)-for-MNIST-image-classification-with-TorchQuantum."]], "Build and train a Quanvolutional Neural Network.": [[29, "Build-and-train-a-Quanvolutional-Neural-Network."]], "Step": [[29, "Step"]], "Build a quanvolutional filter": [[29, "Build-a-quanvolutional-filter"]], "Build the whole hybrid model.": [[29, "Build-the-whole-hybrid-model."]], "Load the dataset MNIST": [[29, "Load-the-dataset-MNIST"]], "Train the model.": [[29, "Train-the-model."]], "Compare Quanvolutional Neural Network with classical model.": [[29, "Compare-Quanvolutional-Neural-Network-with-classical-model."]], "Evaluate on real quantum computer.": [[29, "Evaluate-on-real-quantum-computer."]], "Trainable Quanvolutional Filter": [[29, "Trainable-Quanvolutional-Filter"]], "Qubit Rotation Tutorial": [[30, "qubit-rotation-tutorial"]], "TorchQuantum Qubit Rotation Tutorial": [[31, "TorchQuantum-Qubit-Rotation-Tutorial"]], "The quantum circuit": [[31, "The-quantum-circuit"]], "Importing TorchQuantum": [[31, "Importing-TorchQuantum"]], "Creating a device": [[31, "Creating-a-device"]], "Constructing the Circuit": [[31, "Constructing-the-Circuit"]], "Calculating quantum gradients": [[31, "Calculating-quantum-gradients"]], "Optimization": [[31, "Optimization"]], "predict_quantum_acc": [[32, "predict-quantum-acc"]], "Example": [[32, "example"]], "Data_set": [[32, "data-set"]], "Albation Studies": [[32, "albation-studies"]], "Environment": [[32, "environment"]], "Superdense Coding": [[33, "superdense-coding"], [34, "Superdense-Coding"]], "Author": [[33, "author"]], "Step 1 - Preparing the entangled state/ 2 qubit bell pair.": [[34, "Step-1---Preparing-the-entangled-state/-2-qubit-bell-pair."]], "Step 2 - Encoding the message": [[34, "Step-2---Encoding-the-message"]], "Step 3 - Decoding the message": [[34, "Step-3---Decoding-the-message"], [34, "id2"]], "Step 4 - Measurement": [[34, "Step-4---Measurement"], [34, "id3"]], "Importing modules": [[34, "Importing-modules"]], "Step 2: Encoding the message": [[34, "Step-2:-Encoding-the-message"]], "References:": [[34, "References:"]], "Train a state preparation circuit": [[35, "train-a-state-preparation-circuit"]], "Simple VQE example": [[36, "simple-vqe-example"]], "Usage": [[36, "usage"], [169, null], [169, "usage"]], "apply_unitary_bmm": [[38, "apply-unitary-bmm"]], "apply_unitary_einsum": [[39, "apply-unitary-einsum"]], "ccnot": [[40, "ccnot"]], "ccx": [[41, "ccx"]], "cnot": [[42, "cnot"]], "cp": [[43, "cp"]], "crot": [[44, "crot"]], "crx": [[45, "crx"]], "cry": [[46, "cry"]], "crz": [[47, "crz"]], "cswap": [[48, "cswap"]], "cu": [[49, "cu"]], "cu1": [[50, "cu1"]], "cu2": [[51, "cu2"]], "cu3": [[52, "cu3"]], "cx": [[53, "cx"]], "cy": [[54, "cy"]], "cz": [[55, "cz"]], "echoedcrossresonance": [[56, "echoedcrossresonance"]], "ecr": [[57, "ecr"]], "gate_wrapper": [[58, "gate-wrapper"]], "hadamard": [[59, "hadamard"]], "i": [[60, "i"]], "multicnot": [[61, "multicnot"]], "multirz": [[62, "multirz"]], "multixcnot": [[63, "multixcnot"]], "p": [[64, "p"]], "paulix": [[65, "paulix"]], "pauliy": [[66, "pauliy"]], "pauliz": [[67, "pauliz"]], "phaseshift": [[68, "phaseshift"]], "qubitunitary": [[69, "qubitunitary"]], "qubitunitaryfast": [[70, "qubitunitaryfast"]], "qubitunitarystrict": [[71, "qubitunitarystrict"]], "reset": [[72, "reset"]], "rot": [[73, "rot"]], "rx": [[74, "rx"]], "rxx": [[75, "rxx"]], "ry": [[76, "ry"]], "ryy": [[77, "ryy"]], "rz": [[78, "rz"]], "rzx": [[79, "rzx"]], "rzz": [[80, "rzz"]], "s": [[81, "s"]], "shadamard": [[82, "shadamard"]], "singleexcitation": [[83, "singleexcitation"]], "sswap": [[84, "sswap"]], "swap": [[85, "swap"]], "sx": [[86, "sx"]], "t": [[87, "t"]], "toffoli": [[88, "toffoli"]], "u": [[89, "u"]], "u1": [[90, "u1"]], "u2": [[91, "u2"]], "u3": [[92, "u3"]], "x": [[93, "x"]], "y": [[94, "y"]], "z": [[95, "z"]], "zx": [[96, "zx"]], "zz": [[97, "zz"]], "layers.CXCXCXLayer": [[98, "layers-cxcxcxlayer"]], "layers.CXLayer": [[99, "layers-cxlayer"]], "layers.ClassicalInOpAll": [[100, "layers-classicalinopall"]], "layers.FixedOpAll": [[101, "layers-fixedopall"]], "layers.Op1QAllLayer": [[102, "layers-op1qalllayer"]], "layers.Op2QAllLayer": [[103, "layers-op2qalllayer"]], "layers.Op2QButterflyLayer": [[104, "layers-op2qbutterflylayer"]], "layers.Op2QDenseLayer": [[105, "layers-op2qdenselayer"]], "layers.QFTLayer": [[106, "layers-qftlayer"]], "layers.QuantumModuleFromOps": [[107, "layers-quantummodulefromops"]], "layers.RXYZCXLayer0": [[108, "layers-rxyzcxlayer0"]], "layers.RandomLayer": [[109, "layers-randomlayer"]], "layers.RandomLayerAllTypes": [[110, "layers-randomlayeralltypes"]], "layers.RandomOp1All": [[111, "layers-randomop1all"]], "layers.SWAPSWAPLayer": [[112, "layers-swapswaplayer"]], "layers.TrainableOpAll": [[113, "layers-trainableopall"]], "layers.TwoQAll": [[114, "layers-twoqall"]], "AllWires": [[115, "allwires"]], "AnyWires": [[116, "anywires"]], "operators.CNOT": [[117, "operators-cnot"]], "operators.CRX": [[118, "operators-crx"]], "operators.CRY": [[119, "operators-cry"]], "operators.CRZ": [[120, "operators-crz"]], "operators.CRot": [[121, "operators-crot"]], "operators.CSWAP": [[122, "operators-cswap"]], "operators.CU1": [[123, "operators-cu1"]], "operators.CU2": [[124, "operators-cu2"]], "operators.CU3": [[125, "operators-cu3"]], "operators.CY": [[126, "operators-cy"]], "operators.CZ": [[127, "operators-cz"]], "operators.DiagonalOperation": [[128, "operators-diagonaloperation"]], "operators.ECR": [[129, "operators-ecr"]], "operators.EchoedCrossResonance": [[130, "operators-echoedcrossresonance"]], "operators.Hadamard": [[131, "operators-hadamard"]], "operators.I": [[132, "operators-i"]], "operators.MultiCNOT": [[133, "operators-multicnot"]], "operators.MultiRZ": [[134, "operators-multirz"]], "operators.MultiXCNOT": [[135, "operators-multixcnot"]], "operators.NParamsEnum": [[136, "operators-nparamsenum"]], "operators.Observable": [[137, "operators-observable"]], "operators.Operation": [[138, "operators-operation"]], "operators.Operator": [[139, "operators-operator"]], "operators.PauliX": [[140, "operators-paulix"]], "operators.PauliY": [[141, "operators-pauliy"]], "operators.PauliZ": [[142, "operators-pauliz"]], "operators.PhaseShift": [[143, "operators-phaseshift"]], "operators.QubitUnitary": [[144, "operators-qubitunitary"]], "operators.QubitUnitaryFast": [[145, "operators-qubitunitaryfast"]], "operators.RX": [[146, "operators-rx"]], "operators.RXX": [[147, "operators-rxx"]], "operators.RY": [[148, "operators-ry"]], "operators.RYY": [[149, "operators-ryy"]], "operators.RZ": [[150, "operators-rz"]], "operators.RZX": [[151, "operators-rzx"]], "operators.RZZ": [[152, "operators-rzz"]], "operators.Reset": [[153, "operators-reset"]], "operators.Rot": [[154, "operators-rot"]], "operators.S": [[155, "operators-s"]], "operators.SHadamard": [[156, "operators-shadamard"]], "operators.SSWAP": [[157, "operators-sswap"]], "operators.SWAP": [[158, "operators-swap"]], "operators.SX": [[159, "operators-sx"]], "operators.SingleExcitation": [[160, "operators-singleexcitation"]], "operators.T": [[161, "operators-t"]], "operators.Toffoli": [[162, "operators-toffoli"]], "operators.TrainableUnitary": [[163, "operators-trainableunitary"]], "operators.TrainableUnitaryStrict": [[164, "operators-trainableunitarystrict"]], "operators.U1": [[165, "operators-u1"]], "operators.U2": [[166, "operators-u2"]], "operators.U3": [[167, "operators-u3"]], "operators.WiresEnum": [[168, "operators-wiresenum"]], "API": [[169, null]], "\ud83d\udc4b Welcome": [[169, "welcome"]], "What it does": [[169, "what-it-does"]], "Who will benefit": [[169, "who-will-benefit"]], "Differences from Qiskit/Pennylane": [[169, "differences-from-qiskit-pennylane"]], "News": [[169, "news"]], "Features": [[169, "features"]], "Basic Usage": [[169, "basic-usage"]], "Guide to the examples": [[169, "guide-to-the-examples"]], "VQE Example": [[169, "vqe-example"]], "MNIST Example": [[169, "mnist-example"]], "Files": [[169, "files"]], "Coding Style": [[169, "coding-style"]], "Papers using TorchQuantum": [[169, "papers-using-torchquantum"]], "Dependencies": [[169, "dependencies"]], "Contact": [[169, "contact"]], "Contributors": [[169, "contributors"]], "Citation": [[169, "citation"]]}, "indexentries": {"module": [[0, "module-torchquantum.functional"], [3, "module-torchquantum"], [38, "module-torchquantum.functional"], [39, "module-torchquantum.functional"], [40, "module-torchquantum.functional"], [41, "module-torchquantum.functional"], [42, "module-torchquantum.functional"], [43, "module-torchquantum.functional"], [44, "module-torchquantum.functional"], [45, "module-torchquantum.functional"], [46, "module-torchquantum.functional"], [47, "module-torchquantum.functional"], [48, "module-torchquantum.functional"], [49, "module-torchquantum.functional"], [50, "module-torchquantum.functional"], [51, "module-torchquantum.functional"], [52, "module-torchquantum.functional"], [53, "module-torchquantum.functional"], [54, "module-torchquantum.functional"], [55, "module-torchquantum.functional"], [56, "module-torchquantum.functional"], [57, "module-torchquantum.functional"], [58, "module-torchquantum.functional"], [59, "module-torchquantum.functional"], [60, "module-torchquantum.functional"], [61, "module-torchquantum.functional"], [62, "module-torchquantum.functional"], [63, "module-torchquantum.functional"], [64, "module-torchquantum.functional"], [65, "module-torchquantum.functional"], [66, "module-torchquantum.functional"], [67, "module-torchquantum.functional"], [68, "module-torchquantum.functional"], [69, "module-torchquantum.functional"], [70, "module-torchquantum.functional"], [71, "module-torchquantum.functional"], [72, "module-torchquantum.functional"], [73, "module-torchquantum.functional"], [74, "module-torchquantum.functional"], [75, "module-torchquantum.functional"], [76, "module-torchquantum.functional"], [77, "module-torchquantum.functional"], [78, "module-torchquantum.functional"], [79, "module-torchquantum.functional"], [80, "module-torchquantum.functional"], [81, "module-torchquantum.functional"], [82, "module-torchquantum.functional"], [83, "module-torchquantum.functional"], [84, "module-torchquantum.functional"], [85, "module-torchquantum.functional"], [86, "module-torchquantum.functional"], [87, "module-torchquantum.functional"], [88, "module-torchquantum.functional"], [89, "module-torchquantum.functional"], [90, "module-torchquantum.functional"], [91, "module-torchquantum.functional"], [92, "module-torchquantum.functional"], [93, "module-torchquantum.functional"], [94, "module-torchquantum.functional"], [95, "module-torchquantum.functional"], [96, "module-torchquantum.functional"], [97, "module-torchquantum.functional"]], "torchquantum.functional": [[0, "module-torchquantum.functional"], [38, "module-torchquantum.functional"], [39, "module-torchquantum.functional"], [40, "module-torchquantum.functional"], [41, "module-torchquantum.functional"], [42, "module-torchquantum.functional"], [43, "module-torchquantum.functional"], [44, "module-torchquantum.functional"], [45, "module-torchquantum.functional"], [46, "module-torchquantum.functional"], [47, "module-torchquantum.functional"], [48, "module-torchquantum.functional"], [49, "module-torchquantum.functional"], [50, "module-torchquantum.functional"], [51, "module-torchquantum.functional"], [52, "module-torchquantum.functional"], [53, "module-torchquantum.functional"], [54, "module-torchquantum.functional"], [55, "module-torchquantum.functional"], [56, "module-torchquantum.functional"], [57, "module-torchquantum.functional"], [58, "module-torchquantum.functional"], [59, "module-torchquantum.functional"], [60, "module-torchquantum.functional"], [61, "module-torchquantum.functional"], [62, "module-torchquantum.functional"], [63, "module-torchquantum.functional"], [64, "module-torchquantum.functional"], [65, "module-torchquantum.functional"], [66, "module-torchquantum.functional"], [67, "module-torchquantum.functional"], [68, "module-torchquantum.functional"], [69, "module-torchquantum.functional"], [70, "module-torchquantum.functional"], [71, "module-torchquantum.functional"], [72, "module-torchquantum.functional"], [73, "module-torchquantum.functional"], [74, "module-torchquantum.functional"], [75, "module-torchquantum.functional"], [76, "module-torchquantum.functional"], [77, "module-torchquantum.functional"], [78, "module-torchquantum.functional"], [79, "module-torchquantum.functional"], [80, "module-torchquantum.functional"], [81, "module-torchquantum.functional"], [82, "module-torchquantum.functional"], [83, "module-torchquantum.functional"], [84, "module-torchquantum.functional"], [85, "module-torchquantum.functional"], [86, "module-torchquantum.functional"], [87, "module-torchquantum.functional"], [88, "module-torchquantum.functional"], [89, "module-torchquantum.functional"], [90, "module-torchquantum.functional"], [91, "module-torchquantum.functional"], [92, "module-torchquantum.functional"], [93, "module-torchquantum.functional"], [94, "module-torchquantum.functional"], [95, "module-torchquantum.functional"], [96, "module-torchquantum.functional"], [97, "module-torchquantum.functional"]], "torchquantum": [[3, "module-torchquantum"]], "apply_unitary_bmm() (torchquantum.functional method)": [[38, "torchquantum.functional.apply_unitary_bmm"]], "apply_unitary_einsum() (torchquantum.functional method)": [[39, "torchquantum.functional.apply_unitary_einsum"]], "ccnot() (torchquantum.functional method)": [[40, "torchquantum.functional.ccnot"]], "ccx() (torchquantum.functional method)": [[41, "torchquantum.functional.ccx"]], "cnot() (torchquantum.functional method)": [[42, "torchquantum.functional.cnot"]], "cp() (torchquantum.functional method)": [[43, "torchquantum.functional.cp"]], "crot() (torchquantum.functional method)": [[44, "torchquantum.functional.crot"]], "crx() (torchquantum.functional method)": [[45, "torchquantum.functional.crx"]], "cry() (torchquantum.functional method)": [[46, "torchquantum.functional.cry"]], "crz() (torchquantum.functional method)": [[47, "torchquantum.functional.crz"]], "cswap() (torchquantum.functional method)": [[48, "torchquantum.functional.cswap"]], "cu() (torchquantum.functional method)": [[49, "torchquantum.functional.cu"]], "cu1() (torchquantum.functional method)": [[50, "torchquantum.functional.cu1"]], "cu2() (torchquantum.functional method)": [[51, "torchquantum.functional.cu2"]], "cu3() (torchquantum.functional method)": [[52, "torchquantum.functional.cu3"]], "cx() (torchquantum.functional method)": [[53, "torchquantum.functional.cx"]], "cy() (torchquantum.functional method)": [[54, "torchquantum.functional.cy"]], "cz() (torchquantum.functional method)": [[55, "torchquantum.functional.cz"]], "echoedcrossresonance() (torchquantum.functional method)": [[56, "torchquantum.functional.echoedcrossresonance"]], "ecr() (torchquantum.functional method)": [[57, "torchquantum.functional.ecr"]], "gate_wrapper() (torchquantum.functional method)": [[58, "torchquantum.functional.gate_wrapper"]], "hadamard() (torchquantum.functional method)": [[59, "torchquantum.functional.hadamard"]], "i() (torchquantum.functional method)": [[60, "torchquantum.functional.i"]], "multicnot() (torchquantum.functional method)": [[61, "torchquantum.functional.multicnot"]], "multirz() (torchquantum.functional method)": [[62, "torchquantum.functional.multirz"]], "multixcnot() (torchquantum.functional method)": [[63, "torchquantum.functional.multixcnot"]], "p() (torchquantum.functional method)": [[64, "torchquantum.functional.p"]], "paulix() (torchquantum.functional method)": [[65, "torchquantum.functional.paulix"]], "pauliy() (torchquantum.functional method)": [[66, "torchquantum.functional.pauliy"]], "pauliz() (torchquantum.functional method)": [[67, "torchquantum.functional.pauliz"]], "phaseshift() (torchquantum.functional method)": [[68, "torchquantum.functional.phaseshift"]], "qubitunitary() (torchquantum.functional method)": [[69, "torchquantum.functional.qubitunitary"]], "qubitunitaryfast() (torchquantum.functional method)": [[70, "torchquantum.functional.qubitunitaryfast"]], "qubitunitarystrict() (torchquantum.functional method)": [[71, "torchquantum.functional.qubitunitarystrict"]], "reset() (torchquantum.functional method)": [[72, "torchquantum.functional.reset"]], "rot() (torchquantum.functional method)": [[73, "torchquantum.functional.rot"]], "rx() (torchquantum.functional method)": [[74, "torchquantum.functional.rx"]], "rxx() (torchquantum.functional method)": [[75, "torchquantum.functional.rxx"]], "ry() (torchquantum.functional method)": [[76, "torchquantum.functional.ry"]], "ryy() (torchquantum.functional method)": [[77, "torchquantum.functional.ryy"]], "rz() (torchquantum.functional method)": [[78, "torchquantum.functional.rz"]], "rzx() (torchquantum.functional method)": [[79, "torchquantum.functional.rzx"]], "rzz() (torchquantum.functional method)": [[80, "torchquantum.functional.rzz"]], "s() (torchquantum.functional method)": [[81, "torchquantum.functional.s"]], "shadamard() (torchquantum.functional method)": [[82, "torchquantum.functional.shadamard"]], "singleexcitation() (torchquantum.functional method)": [[83, "torchquantum.functional.singleexcitation"]], "sswap() (torchquantum.functional method)": [[84, "torchquantum.functional.sswap"]], "swap() (torchquantum.functional method)": [[85, "torchquantum.functional.swap"]], "sx() (torchquantum.functional method)": [[86, "torchquantum.functional.sx"]], "t() (torchquantum.functional method)": [[87, "torchquantum.functional.t"]], "toffoli() (torchquantum.functional method)": [[88, "torchquantum.functional.toffoli"]], "u() (torchquantum.functional method)": [[89, "torchquantum.functional.u"]], "u1() (torchquantum.functional method)": [[90, "torchquantum.functional.u1"]], "u2() (torchquantum.functional method)": [[91, "torchquantum.functional.u2"]], "u3() (torchquantum.functional method)": [[92, "torchquantum.functional.u3"]], "x() (torchquantum.functional method)": [[93, "torchquantum.functional.x"]], "y() (torchquantum.functional method)": [[94, "torchquantum.functional.y"]], "z() (torchquantum.functional method)": [[95, "torchquantum.functional.z"]], "zx() (torchquantum.functional method)": [[96, "torchquantum.functional.zx"]], "zz() (torchquantum.functional method)": [[97, "torchquantum.functional.zz"]]}})