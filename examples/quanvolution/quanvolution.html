<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Superdense Coding" href="../superdense_coding/superdense_coding_torchquantum.html" /><link rel="prev" title="Quantum Kernel Methods for IRIS dataset classification with TorchQuantum." href="../quantum_kernel_method/quantum_kernel_method.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2023.09.10 -->
        <title>Quanvolution (Quantum convolution) for MNIST image classification with TorchQuantum. - TorchQuantum 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=362ab14a" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">TorchQuantum 0.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">TorchQuantum 0.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_torchquantum.html">torchquantum</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api_functional.html">torchquantum.functional</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of torchquantum.functional</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.apply_unitary_einsum.html">apply_unitary_einsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.apply_unitary_bmm.html">apply_unitary_bmm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.gate_wrapper.html">gate_wrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.reset.html">reset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.hadamard.html">hadamard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.shadamard.html">shadamard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.paulix.html">paulix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.pauliy.html">pauliy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.pauliz.html">pauliz</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.i.html">i</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.s.html">s</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.t.html">t</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.sx.html">sx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cnot.html">cnot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cz.html">cz</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cy.html">cy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.rx.html">rx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.ry.html">ry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.rz.html">rz</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.rxx.html">rxx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.ryy.html">ryy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.rzz.html">rzz</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.zz.html">zz</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.rzx.html">rzx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.zx.html">zx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.swap.html">swap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.sswap.html">sswap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cswap.html">cswap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.toffoli.html">toffoli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.phaseshift.html">phaseshift</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.p.html">p</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cp.html">cp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.rot.html">rot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.multirz.html">multirz</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.crx.html">crx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cry.html">cry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.crz.html">crz</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.crot.html">crot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.u1.html">u1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.u2.html">u2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.u3.html">u3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.u.html">u</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cu1.html">cu1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cu2.html">cu2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cu3.html">cu3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cu.html">cu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.qubitunitary.html">qubitunitary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.qubitunitaryfast.html">qubitunitaryfast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.qubitunitarystrict.html">qubitunitarystrict</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.multicnot.html">multicnot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.multixcnot.html">multixcnot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.x.html">x</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.y.html">y</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.z.html">z</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.zz.html">zz</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.cx.html">cx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.ccnot.html">ccnot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.ccx.html">ccx</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.reset.html">reset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.singleexcitation.html">singleexcitation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.ecr.html">ecr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.functional.echoedcrossresonance.html">echoedcrossresonance</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api_operators.html">torchquantum.operators</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of torchquantum.operators</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.WiresEnum.html">operators.WiresEnum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.NParamsEnum.html">operators.NParamsEnum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.AllWires.html">AllWires</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.AnyWires.html">AnyWires</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.Operator.html">operators.Operator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.Observable.html">operators.Observable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.Operation.html">operators.Operation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.DiagonalOperation.html">operators.DiagonalOperation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.Hadamard.html">operators.Hadamard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.SHadamard.html">operators.SHadamard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.PauliX.html">operators.PauliX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.PauliY.html">operators.PauliY</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.PauliZ.html">operators.PauliZ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.I.html">operators.I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.S.html">operators.S</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.T.html">operators.T</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.SX.html">operators.SX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CNOT.html">operators.CNOT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CZ.html">operators.CZ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CY.html">operators.CY</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.RX.html">operators.RX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.RY.html">operators.RY</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.RZ.html">operators.RZ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.RXX.html">operators.RXX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.RYY.html">operators.RYY</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.RZZ.html">operators.RZZ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.RZX.html">operators.RZX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.SWAP.html">operators.SWAP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.SSWAP.html">operators.SSWAP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CSWAP.html">operators.CSWAP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.Toffoli.html">operators.Toffoli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.PhaseShift.html">operators.PhaseShift</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.Rot.html">operators.Rot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.MultiRZ.html">operators.MultiRZ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CRX.html">operators.CRX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CRY.html">operators.CRY</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CRZ.html">operators.CRZ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CRot.html">operators.CRot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.U1.html">operators.U1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.U2.html">operators.U2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.U3.html">operators.U3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CU1.html">operators.CU1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CU2.html">operators.CU2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.CU3.html">operators.CU3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.QubitUnitary.html">operators.QubitUnitary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.QubitUnitaryFast.html">operators.QubitUnitaryFast</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.TrainableUnitary.html">operators.TrainableUnitary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.TrainableUnitaryStrict.html">operators.TrainableUnitaryStrict</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.MultiCNOT.html">operators.MultiCNOT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.MultiXCNOT.html">operators.MultiXCNOT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.Reset.html">operators.Reset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.SingleExcitation.html">operators.SingleExcitation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.EchoedCrossResonance.html">operators.EchoedCrossResonance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.operators.ECR.html">operators.ECR</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api_layers.html">torchquantum.layers</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of torchquantum.layers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.QuantumModuleFromOps.html">layers.QuantumModuleFromOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.TrainableOpAll.html">layers.TrainableOpAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.ClassicalInOpAll.html">layers.ClassicalInOpAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.FixedOpAll.html">layers.FixedOpAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.TwoQAll.html">layers.TwoQAll</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.RandomLayer.html">layers.RandomLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.RandomLayerAllTypes.html">layers.RandomLayerAllTypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.Op1QAllLayer.html">layers.Op1QAllLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.RandomOp1All.html">layers.RandomOp1All</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.Op2QAllLayer.html">layers.Op2QAllLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.Op2QButterflyLayer.html">layers.Op2QButterflyLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.Op2QDenseLayer.html">layers.Op2QDenseLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.CXLayer.html">layers.CXLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.CXCXCXLayer.html">layers.CXCXCXLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.SWAPSWAPLayer.html">layers.SWAPSWAPLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.RXYZCXLayer0.html">layers.RXYZCXLayer0</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../generated/torchquantum.layers.QFTLayer.html">layers.QFTLayer</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../usage_installation.html">Installation</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">TorchQuantum Examples</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of TorchQuantum Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../gradient_pruning/probabilistic_gradient_pruning.html">Probabilistic gradient pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../param_shift_onchip_training/param_shift_onchip_training.html">Apply parameters shift rules to train quantum model using TorchQuantum.</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quantum_kernel_method/quantum_kernel_method.html">Quantum Kernel Methods for IRIS dataset classification with TorchQuantum.</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Quanvolution (Quantum convolution) for MNIST image classification with TorchQuantum.</a></li>
<li class="toctree-l2"><a class="reference internal" href="../superdense_coding/superdense_coding_torchquantum.html">Superdense Coding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../superdense_coding/superdense_coding_torchquantum.html#References:">References:</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="Quanvolution-(Quantum-convolution)-for-MNIST-image-classification-with-TorchQuantum.">
<h1>Quanvolution (Quantum convolution) for MNIST image classification with <a class="reference external" href="https://github.com/mit-han-lab/torchquantum">TorchQuantum</a>.<a class="headerlink" href="#Quanvolution-(Quantum-convolution)-for-MNIST-image-classification-with-TorchQuantum." title="Link to this heading">#</a></h1>
<p align="left"><p><img alt="torchquantum Logo" class="no-scaled-link" src="https://github.com/mit-han-lab/torchquantum/blob/master/torchquantum_logo.jpg?raw=true" style="width: 250px;" /></p>
</p><p>Tutorial Author: Zirui Li, Hanrui Wang</p>
<section id="Outline">
<h2>Outline<a class="headerlink" href="#Outline" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Introduction to Quanvolutional Neural Network.</p></li>
<li><p>Build and train a Quanvolutional Neural Network.</p></li>
</ol>
<ul class="simple">
<li><ol class="loweralpha simple">
<li><p>Compare Quanvolutional Neural Network with a classic model.</p></li>
</ol>
</li>
<li><ol class="loweralpha simple" start="2">
<li><p>Evaluate on real quantum computer.</p></li>
</ol>
</li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Compare multiple models with or without a trainable quanvolutional filter.</p></li>
</ol>
<p>In this tutorial, we use <code class="docutils literal notranslate"><span class="pre">tq.QuantumDevice</span></code>, <code class="docutils literal notranslate"><span class="pre">tq.GeneralEncoder</span></code>, <code class="docutils literal notranslate"><span class="pre">tq.RandomLayer</span></code>, <code class="docutils literal notranslate"><span class="pre">tq.MeasureAll</span></code>, <code class="docutils literal notranslate"><span class="pre">tq.PauliZ</span></code> class from TrochQuantum.</p>
<p>You can learn how to build, train and evaluate a quanvolutional filter using TorchQuantum in this tutorial.</p>
<section id="Introduction-to-Quanvolutional-Neural-Network.">
<h3>Introduction to Quanvolutional Neural Network.<a class="headerlink" href="#Introduction-to-Quanvolutional-Neural-Network." title="Link to this heading">#</a></h3>
</section>
</section>
<section id="Convolutional-Neural-Network">
<h2>Convolutional Neural Network<a class="headerlink" href="#Convolutional-Neural-Network" title="Link to this heading">#</a></h2>
<p>Convolutional neural network is a classic neural network genre, mostly applied to anylize visual images. They are known for their convolutional layers that perform convolution. Typically the convolution operation is the Frobenius inner product of the convolution filter with the input image followed by an activation function. The convolution filter slides along the input image and generates a feature map. We can use the feature map for classification.</p>
<div align="center"><p><img alt="conv-full-layer" class="no-scaled-link" src="https://github.com/mit-han-lab/torchquantum/blob/master/figs/conv-full-layer.gif?raw=true" style="width: 300px;" /></p>
</div></section>
<section id="Quantum-convolution">
<h2>Quantum convolution<a class="headerlink" href="#Quantum-convolution" title="Link to this heading">#</a></h2>
<p>One can extend the same idea also to the context of quantum variational circuits. Replace the classical convolution filters with variational quantum circuits and we get quanvolutional neural networks with quanvolutional filters. The quanvolutional filters perform more complex operations in a higher dimension Hilbert space than Frobenius inner product. Therefore, quanvolutional filters have more potential than traditional convolution filters.</p>
<div align="center"><p><img alt="conv-full-layer" class="no-scaled-link" src="https://github.com/mit-han-lab/torchquantum/blob/master/figs/hybridmodel.png?raw=true" style="width: 800px;" /></p>
</div><section id="Build-and-train-a-Quanvolutional-Neural-Network.">
<h3>Build and train a Quanvolutional Neural Network.<a class="headerlink" href="#Build-and-train-a-Quanvolutional-Neural-Network." title="Link to this heading">#</a></h3>
</section>
</section>
<section id="Installation">
<h2>Installation<a class="headerlink" href="#Installation" title="Link to this heading">#</a></h2>
<p>Install torchquantum and all the libs we need.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">qiskit</span><span class="o">==</span><span class="mf">0.32.1</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Collecting qiskit==0.32.1
  Downloading qiskit-0.32.1.tar.gz (13 kB)
Collecting qiskit-terra==0.18.3
  Downloading qiskit_terra-0.18.3-cp37-cp37m-manylinux2010_x86_64.whl (6.1 MB)
     |████████████████████████████████| 6.1 MB 4.1 MB/s
Collecting qiskit-aer==0.9.1
  Downloading qiskit_aer-0.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (17.9 MB)
     |████████████████████████████████| 17.9 MB 633 kB/s
Collecting qiskit-ibmq-provider==0.18.1
  Downloading qiskit_ibmq_provider-0.18.1-py3-none-any.whl (237 kB)
     |████████████████████████████████| 237 kB 73.3 MB/s
Collecting qiskit-ignis==0.6.0
  Downloading qiskit_ignis-0.6.0-py3-none-any.whl (207 kB)
     |████████████████████████████████| 207 kB 65.4 MB/s
Collecting qiskit-aqua==0.9.5
  Downloading qiskit_aqua-0.9.5-py3-none-any.whl (2.1 MB)
     |████████████████████████████████| 2.1 MB 60.5 MB/s
Requirement already satisfied: scipy&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.9.1-&gt;qiskit==0.32.1) (1.4.1)
Requirement already satisfied: numpy&gt;=1.16.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.9.1-&gt;qiskit==0.32.1) (1.21.5)
Requirement already satisfied: h5py&lt;3.3.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (3.1.0)
Collecting quandl
  Downloading Quandl-3.7.0-py2.py3-none-any.whl (26 kB)
Requirement already satisfied: scikit-learn&gt;=0.20.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (1.0.2)
Collecting yfinance&gt;=0.1.62
  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)
Requirement already satisfied: psutil&gt;=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (5.4.8)
Collecting docplex&gt;=2.21.207
  Downloading docplex-2.22.213.tar.gz (634 kB)
     |████████████████████████████████| 634 kB 68.2 MB/s
Requirement already satisfied: setuptools&gt;=40.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (57.4.0)
Requirement already satisfied: sympy&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (1.7.1)
Collecting retworkx&gt;=0.8.0
  Downloading retworkx-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
     |████████████████████████████████| 1.6 MB 21.6 MB/s
Requirement already satisfied: fastdtw&lt;=0.3.4 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (0.3.4)
Collecting dlx&lt;=1.0.4
  Downloading dlx-1.0.4.tar.gz (5.5 kB)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (1.3.5)
Requirement already satisfied: urllib3&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (1.24.3)
Requirement already satisfied: python-dateutil&gt;=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (2.8.2)
Collecting requests-ntlm&gt;=1.1.0
  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)
Requirement already satisfied: requests&gt;=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (2.23.0)
Collecting websocket-client&gt;=1.0.1
  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)
     |████████████████████████████████| 53 kB 2.7 MB/s
Collecting python-constraint&gt;=1.4
  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)
Collecting fastjsonschema&gt;=2.10
  Downloading fastjsonschema-2.15.3-py3-none-any.whl (22 kB)
Collecting symengine&gt;0.7
  Downloading symengine-0.8.1-cp37-cp37m-manylinux2010_x86_64.whl (38.2 MB)
     |████████████████████████████████| 38.2 MB 116 kB/s
Collecting tweedledum&lt;2.0,&gt;=1.1
  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)
     |████████████████████████████████| 943 kB 22.1 MB/s
Collecting ply&gt;=3.10
  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)
     |████████████████████████████████| 49 kB 8.3 MB/s
Requirement already satisfied: dill&gt;=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3-&gt;qiskit==0.32.1) (0.3.4)
Requirement already satisfied: jsonschema&gt;=2.6 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3-&gt;qiskit==0.32.1) (4.3.3)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from docplex&gt;=2.21.207-&gt;qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (1.15.0)
Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py&lt;3.3.0-&gt;qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (1.5.2)
Requirement already satisfied: importlib-resources&gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit==0.32.1) (5.4.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit==0.32.1) (3.10.0.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit==0.32.1) (21.4.0)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit==0.32.1) (4.11.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit==0.32.1) (0.18.1)
Requirement already satisfied: zipp&gt;=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources&gt;=1.4.0-&gt;jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit==0.32.1) (3.7.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (2021.10.8)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (2.10)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (3.0.4)
Collecting cryptography&gt;=1.3
  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)
     |████████████████████████████████| 3.6 MB 31.3 MB/s
Collecting ntlm-auth&gt;=1.0.2
  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)
Requirement already satisfied: cffi&gt;=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography&gt;=1.3-&gt;requests-ntlm&gt;=1.1.0-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (1.15.0)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=1.3-&gt;requests-ntlm&gt;=1.1.0-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (2.21)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.20.0-&gt;qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.20.0-&gt;qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (3.1.0)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy&gt;=1.3-&gt;qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (1.2.1)
Collecting requests&gt;=2.19
  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)
     |████████████████████████████████| 63 kB 814 kB/s
Requirement already satisfied: multitasking&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance&gt;=0.1.62-&gt;qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (0.0.10)
Collecting lxml&gt;=4.5.1
  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)
     |████████████████████████████████| 6.4 MB 30.3 MB/s
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (2018.9)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit==0.32.1) (2.0.11)
Collecting inflection&gt;=0.3.1
  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)
Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from quandl-&gt;qiskit-aqua==0.9.5-&gt;qiskit==0.32.1) (8.12.0)
Building wheels for collected packages: qiskit, dlx, docplex, python-constraint
  Building wheel for qiskit (setup.py) ... done
  Created wheel for qiskit: filename=qiskit-0.32.1-py3-none-any.whl size=11777 sha256=911365fec91e5c648d2569b156af429c0aff7c3d95d453a7d24e6bf8d7d1a315
  Stored in directory: /root/.cache/pip/wheels/0f/62/0a/c53eda1ead41c137c47c9730bc2771a8367b1ce00fb64e8cc6
  Building wheel for dlx (setup.py) ... done
  Created wheel for dlx: filename=dlx-1.0.4-py3-none-any.whl size=5718 sha256=cb913d8c2b19d87e8784f4220a02752c4858e3ebe531b0e80ab22c5625c1bd0b
  Stored in directory: /root/.cache/pip/wheels/78/55/c8/dc61e772445a566b7608a476d151e9dcaf4e092b01b0c4bc3c
  Building wheel for docplex (setup.py) ... done
  Created wheel for docplex: filename=docplex-2.22.213-py3-none-any.whl size=696882 sha256=192bab0a2587503608ce12a090c9f129f2a6b0e88f3a41e568c07ca585b4e3ff
  Stored in directory: /root/.cache/pip/wheels/90/69/6b/1375c68a5b7ff94c40263b151c86f58bd72200bf0c465b5ba3
  Building wheel for python-constraint (setup.py) ... done
  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24081 sha256=77684dcb7c666715267053a0114cf933c5c52cb7af9a30645de961f9af12c323
  Stored in directory: /root/.cache/pip/wheels/07/27/db/1222c80eb1e431f3d2199c12569cb1cac60f562a451fe30479
Successfully built qiskit dlx docplex python-constraint
Installing collected packages: tweedledum, symengine, retworkx, python-constraint, ply, fastjsonschema, requests, qiskit-terra, ntlm-auth, lxml, inflection, cryptography, yfinance, websocket-client, requests-ntlm, quandl, qiskit-ignis, docplex, dlx, qiskit-ibmq-provider, qiskit-aqua, qiskit-aer, qiskit
  Attempting uninstall: requests
    Found existing installation: requests 2.23.0
    Uninstalling requests-2.23.0:
      Successfully uninstalled requests-2.23.0
  Attempting uninstall: lxml
    Found existing installation: lxml 4.2.6
    Uninstalling lxml-4.2.6:
      Successfully uninstalled lxml-4.2.6
<span class="ansi-red-fg">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.
datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.</span>
Successfully installed cryptography-36.0.1 dlx-1.0.4 docplex-2.22.213 fastjsonschema-2.15.3 inflection-0.5.1 lxml-4.7.1 ntlm-auth-1.5.0 ply-3.11 python-constraint-1.4.0 qiskit-0.32.1 qiskit-aer-0.9.1 qiskit-aqua-0.9.5 qiskit-ibmq-provider-0.18.1 qiskit-ignis-0.6.0 qiskit-terra-0.18.3 quandl-3.7.0 requests-2.27.1 requests-ntlm-1.1.0 retworkx-0.11.0 symengine-0.8.1 tweedledum-1.1.1 websocket-client-1.2.3 yfinance-0.1.70
</pre></div></div>
</div>
<p>Download and cd to the repo.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">mit</span><span class="o">-</span><span class="n">han</span><span class="o">-</span><span class="n">lab</span><span class="o">/</span><span class="n">torchquantum</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Cloning into &#39;torchquantum&#39;...
remote: Enumerating objects: 10737, done.
remote: Counting objects: 100% (7529/7529), done.
remote: Compressing objects: 100% (3777/3777), done.
remote: Total 10737 (delta 3765), reused 7076 (delta 3348), pack-reused 3208
Receiving objects: 100% (10737/10737), 3.19 MiB | 12.92 MiB/s, done.
Resolving deltas: 100% (5732/5732), done.
Checking out files: 100% (50055/50055), done.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">cd</span> <span class="n">torchquantum</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
/content/torchquantum
</pre></div></div>
</div>
<p>Install torch-quantum.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">editable</span> <span class="o">.</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Obtaining file:///content/torchquantum
Requirement already satisfied: numpy&gt;=1.19.2 in /usr/local/lib/python3.7/dist-packages (from torchquantum==0.1.0) (1.21.5)
Requirement already satisfied: torchvision&gt;=0.9.0.dev20210130 in /usr/local/lib/python3.7/dist-packages (from torchquantum==0.1.0) (0.11.1+cu111)
Requirement already satisfied: tqdm&gt;=4.56.0 in /usr/local/lib/python3.7/dist-packages (from torchquantum==0.1.0) (4.62.3)
Requirement already satisfied: setuptools&gt;=52.0.0 in /usr/local/lib/python3.7/dist-packages (from torchquantum==0.1.0) (57.4.0)
Requirement already satisfied: torch&gt;=1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchquantum==0.1.0) (1.10.0+cu111)
Collecting torchpack&gt;=0.3.0
  Downloading torchpack-0.3.1-py3-none-any.whl (34 kB)
Requirement already satisfied: qiskit&gt;=0.32.0 in /usr/local/lib/python3.7/dist-packages (from torchquantum==0.1.0) (0.32.1)
Collecting matplotlib&gt;=3.3.2
  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
     |████████████████████████████████| 11.2 MB 6.5 MB/s
Collecting pathos&gt;=0.2.7
  Downloading pathos-0.2.8-py2.py3-none-any.whl (81 kB)
     |████████████████████████████████| 81 kB 12.1 MB/s
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.3.2-&gt;torchquantum==0.1.0) (2.8.2)
Requirement already satisfied: pyparsing&gt;=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.3.2-&gt;torchquantum==0.1.0) (3.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.3.2-&gt;torchquantum==0.1.0) (0.11.0)
Collecting fonttools&gt;=4.22.0
  Downloading fonttools-4.29.1-py3-none-any.whl (895 kB)
     |████████████████████████████████| 895 kB 55.2 MB/s
Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.3.2-&gt;torchquantum==0.1.0) (7.1.2)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.3.2-&gt;torchquantum==0.1.0) (1.3.2)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib&gt;=3.3.2-&gt;torchquantum==0.1.0) (21.3)
Collecting ppft&gt;=1.6.6.4
  Downloading ppft-1.6.6.4-py3-none-any.whl (65 kB)
     |████████████████████████████████| 65 kB 4.1 MB/s
Collecting pox&gt;=0.3.0
  Downloading pox-0.3.0-py2.py3-none-any.whl (30 kB)
Requirement already satisfied: multiprocess&gt;=0.70.12 in /usr/local/lib/python3.7/dist-packages (from pathos&gt;=0.2.7-&gt;torchquantum==0.1.0) (0.70.12.2)
Requirement already satisfied: dill&gt;=0.3.4 in /usr/local/lib/python3.7/dist-packages (from pathos&gt;=0.2.7-&gt;torchquantum==0.1.0) (0.3.4)
Requirement already satisfied: six&gt;=1.7.3 in /usr/local/lib/python3.7/dist-packages (from ppft&gt;=1.6.6.4-&gt;pathos&gt;=0.2.7-&gt;torchquantum==0.1.0) (1.15.0)
Requirement already satisfied: qiskit-ibmq-provider==0.18.1 in /usr/local/lib/python3.7/dist-packages (from qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.18.1)
Requirement already satisfied: qiskit-aqua==0.9.5 in /usr/local/lib/python3.7/dist-packages (from qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.9.5)
Requirement already satisfied: qiskit-aer==0.9.1 in /usr/local/lib/python3.7/dist-packages (from qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.9.1)
Requirement already satisfied: qiskit-ignis==0.6.0 in /usr/local/lib/python3.7/dist-packages (from qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.6.0)
Requirement already satisfied: qiskit-terra==0.18.3 in /usr/local/lib/python3.7/dist-packages (from qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.18.3)
Requirement already satisfied: scipy&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.9.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.4.1)
Requirement already satisfied: quandl in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (3.7.0)
Requirement already satisfied: scikit-learn&gt;=0.20.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.0.2)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.3.5)
Requirement already satisfied: h5py&lt;3.3.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (3.1.0)
Requirement already satisfied: fastdtw&lt;=0.3.4 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.3.4)
Requirement already satisfied: dlx&lt;=1.0.4 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.0.4)
Requirement already satisfied: retworkx&gt;=0.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.11.0)
Requirement already satisfied: sympy&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.7.1)
Requirement already satisfied: docplex&gt;=2.21.207 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (2.22.213)
Requirement already satisfied: yfinance&gt;=0.1.62 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.1.70)
Requirement already satisfied: psutil&gt;=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (5.4.8)
Requirement already satisfied: urllib3&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.24.3)
Requirement already satisfied: requests-ntlm&gt;=1.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.1.0)
Requirement already satisfied: websocket-client&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.2.3)
Requirement already satisfied: requests&gt;=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (2.27.1)
Requirement already satisfied: symengine&gt;0.7 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.8.1)
Requirement already satisfied: fastjsonschema&gt;=2.10 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (2.15.3)
Requirement already satisfied: ply&gt;=3.10 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (3.11)
Requirement already satisfied: python-constraint&gt;=1.4 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.4.0)
Requirement already satisfied: jsonschema&gt;=2.6 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (4.3.3)
Requirement already satisfied: tweedledum&lt;2.0,&gt;=1.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.1.1)
Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py&lt;3.3.0-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.5.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (21.4.0)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (4.11.0)
Requirement already satisfied: importlib-resources&gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (5.4.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.18.1)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (3.10.0.2)
Requirement already satisfied: zipp&gt;=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources&gt;=1.4.0-&gt;jsonschema&gt;=2.6-&gt;qiskit-terra==0.18.3-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (3.7.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (2.10)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (2.0.11)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.19-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (2021.10.8)
Requirement already satisfied: cryptography&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from requests-ntlm&gt;=1.1.0-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (36.0.1)
Requirement already satisfied: ntlm-auth&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-ntlm&gt;=1.1.0-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.5.0)
Requirement already satisfied: cffi&gt;=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography&gt;=1.3-&gt;requests-ntlm&gt;=1.1.0-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.15.0)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=1.3-&gt;requests-ntlm&gt;=1.1.0-&gt;qiskit-ibmq-provider==0.18.1-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (2.21)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.20.0-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.20.0-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (3.1.0)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy&gt;=1.3-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (1.2.1)
Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (2.8.0)
Collecting toml
  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)
Collecting tensorpack
  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)
     |████████████████████████████████| 296 kB 57.1 MB/s
Collecting multimethod
  Downloading multimethod-1.7-py3-none-any.whl (9.5 kB)
Collecting loguru
  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)
     |████████████████████████████████| 58 kB 2.6 MB/s
Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (3.13)
Requirement already satisfied: multitasking&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance&gt;=0.1.62-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.0.10)
Requirement already satisfied: lxml&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance&gt;=0.1.62-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (4.7.1)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (2018.9)
Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from quandl-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (8.12.0)
Requirement already satisfied: inflection&gt;=0.3.1 in /usr/local/lib/python3.7/dist-packages (from quandl-&gt;qiskit-aqua==0.9.5-&gt;qiskit&gt;=0.32.0-&gt;torchquantum==0.1.0) (0.5.1)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (3.3.6)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (1.8.1)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (1.0.0)
Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (1.43.0)
Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (0.37.1)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (0.4.6)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (1.35.0)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (0.6.1)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (1.0.1)
Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (3.17.3)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (0.2.8)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (4.2.4)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (4.8)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (1.3.1)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (0.4.8)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (3.2.0)
Requirement already satisfied: msgpack&gt;=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (1.0.3)
Requirement already satisfied: pyzmq&gt;=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (22.3.0)
Collecting msgpack-numpy&gt;=0.4.4.2
  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)
Requirement already satisfied: tabulate&gt;=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (0.8.9)
Requirement already satisfied: termcolor&gt;=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack-&gt;torchpack&gt;=0.3.0-&gt;torchquantum==0.1.0) (1.1.0)
Installing collected packages: msgpack-numpy, toml, tensorpack, ppft, pox, multimethod, loguru, fonttools, torchpack, pathos, matplotlib, torchquantum
  Attempting uninstall: matplotlib
    Found existing installation: matplotlib 3.2.2
    Uninstalling matplotlib-3.2.2:
      Successfully uninstalled matplotlib-3.2.2
  Running setup.py develop for torchquantum
<span class="ansi-red-fg">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
albumentations 0.1.12 requires imgaug&lt;0.2.7,&gt;=0.2.5, but you have imgaug 0.2.9 which is incompatible.</span>
Successfully installed fonttools-4.29.1 loguru-0.6.0 matplotlib-3.5.1 msgpack-numpy-0.4.7.1 multimethod-1.7 pathos-0.2.8 pox-0.3.0 ppft-1.6.6.4 tensorpack-0.11 toml-0.10.2 torchpack-0.3.1 torchquantum-0.1.0
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="admonition warning">
<p>Data type cannot be displayed: application/vnd.colab-display-data+json</p>
</div>
</div>
</div>
<p>Change PYTHONPATH and install other packages.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">env</span> <span class="n">PYTHONPATH</span><span class="o">=.</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
env: PYTHONPATH=.
</pre></div></div>
</div>
<p>Run the following code to store a qiskit token. You can replace it with your own token from your IBMQ account if you like.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">qiskit</span> <span class="kn">import</span> <span class="n">IBMQ</span>
<span class="c1"># IBMQ.save_account(&#39;&#39;, overwrite=True)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">matplotlib</span><span class="o">==</span><span class="mf">3.1.3</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Collecting matplotlib==3.1.3
  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)
     |████████████████████████████████| 13.1 MB 4.3 MB/s
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (3.0.7)
Requirement already satisfied: numpy&gt;=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.21.5)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.11.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.2)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.3.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib==3.1.3) (1.15.0)
Installing collected packages: matplotlib
  Attempting uninstall: matplotlib
    Found existing installation: matplotlib 3.5.1
    Uninstalling matplotlib-3.5.1:
      Successfully uninstalled matplotlib-3.5.1
<span class="ansi-red-fg">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
torchquantum 0.1.0 requires matplotlib&gt;=3.3.2, but you have matplotlib 3.1.3 which is incompatible.
albumentations 0.1.12 requires imgaug&lt;0.2.7,&gt;=0.2.5, but you have imgaug 0.2.9 which is incompatible.</span>
Successfully installed matplotlib-3.1.3
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="admonition warning">
<p>Data type cannot be displayed: application/vnd.colab-display-data+json</p>
</div>
</div>
</div>
</section>
<section id="Step">
<h2>Step<a class="headerlink" href="#Step" title="Link to this heading">#</a></h2>
<p>Our code requires torchquantum lib, mnist dataset, pytorch and numpy. We need torch and the logsoftmax function from <code class="docutils literal notranslate"><span class="pre">torch.nn.functional</span></code>, optimizers(<code class="docutils literal notranslate"><span class="pre">optim</span></code>), <code class="docutils literal notranslate"><span class="pre">torchquantum</span></code> module, MNIST dataset(<code class="docutils literal notranslate"><span class="pre">MNIST</span></code>), cosine annealing learning rate(<code class="docutils literal notranslate"><span class="pre">CosineAnnealingLR</span></code>).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torchquantum</span> <span class="k">as</span> <span class="nn">tq</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">from</span> <span class="nn">torchquantum.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">CosineAnnealingLR</span>
</pre></div>
</div>
</div>
</section>
<section id="Build-a-quanvolutional-filter">
<h2>Build a quanvolutional filter<a class="headerlink" href="#Build-a-quanvolutional-filter" title="Link to this heading">#</a></h2>
<p>Our quanvolution model is a hybrid model. It consists of two parts, the quanvolutional filter part and the classical layer part. To build the model, firstly we define our quanvolutional filter.</p>
<p>Our quanvolutional filter’s structure is the same as the figure described above. It has four qubits. The <code class="docutils literal notranslate"><span class="pre">tq.QuantumDevice</span></code> module stores the state vector. Usually a Quantum Neural Network module consists of three parts: encoder, ansatz and measurement. We can create an encoder by passing a list of gates to <code class="docutils literal notranslate"><span class="pre">tq.GeneralEncoder</span></code>. Each entry in the list contains <code class="docutils literal notranslate"><span class="pre">input_idx</span></code>, <code class="docutils literal notranslate"><span class="pre">func</span></code>, and <code class="docutils literal notranslate"><span class="pre">wires</span></code>. Here, each qubit has a rotation-Y gate. 4 RY gates in total. They can encode the 2x2 input
data to the quantum state. Then we decide our ansatz to be a random layer. We call <code class="docutils literal notranslate"><span class="pre">tq.RandomLayer</span></code> to create an ansatz composed by 8 basic gates with no more than 8 trainable parameters. And finally we perform Pauli-Z measurements on each qubit by creating a <code class="docutils literal notranslate"><span class="pre">tq.MeasureAll</span></code> module and passing <code class="docutils literal notranslate"><span class="pre">tq.PauliZ</span></code> to it. The measure function will return four expectation values from four qubits. The four results go to four channels.</p>
<p>Next look at how quanvolutional filter works. We get the batch size. Our image is 28x28. So we reshape our input data to <code class="docutils literal notranslate"><span class="pre">(bsz,</span> <span class="pre">28,</span> <span class="pre">28)</span></code>.</p>
<p>We initialize the <code class="docutils literal notranslate"><span class="pre">data_list</span></code>. The list stores the outputs in each stride.</p>
<p>The double loop is to iterate all the possible positions that the quanvolutional filter window may stride in. Here the stride is 2.</p>
<p>Then we catenate the data in the 2x2 window. Here we catenate four lists to one big list, so we need to reshape the list to <code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">bsz)</span></code> and transpose it to <code class="docutils literal notranslate"><span class="pre">(bsz,</span> <span class="pre">4)</span></code>.</p>
<p>Next if you want to use qiskit’s remote noise model or real quantum machine, you can set <code class="docutils literal notranslate"><span class="pre">use_qiskit=True</span></code> and pass these 5 parameters: <code class="docutils literal notranslate"><span class="pre">q_device</span></code>, <code class="docutils literal notranslate"><span class="pre">encoder</span></code>, <code class="docutils literal notranslate"><span class="pre">q_layer</span></code>, <code class="docutils literal notranslate"><span class="pre">measure</span></code>, and <code class="docutils literal notranslate"><span class="pre">data</span></code>. The <code class="docutils literal notranslate"><span class="pre">qiskit_processor</span></code> will receive these parameters, put the data in the encoder, run the while circuits and return the measurement result. Remember only when the model is doing an inference can you use qiskit remote.</p>
<p>If you are training or not using qiskit remote, you can run the three parts one by one on google colab’s GPU.</p>
<p>After each stride, we append the measurement result to <code class="docutils literal notranslate"><span class="pre">data_list</span></code>.</p>
<p>Finally, we catenate the <code class="docutils literal notranslate"><span class="pre">data_list</span></code> along dimension 1 and return the result.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">QuanvolutionFilter</span><span class="p">(</span><span class="n">tq</span><span class="o">.</span><span class="n">QuantumModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_device</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">QuantumDevice</span><span class="p">(</span><span class="n">n_wires</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">GeneralEncoder</span><span class="p">(</span>
        <span class="p">[</span>   <span class="p">{</span><span class="s1">&#39;input_idx&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="s1">&#39;ry&#39;</span><span class="p">,</span> <span class="s1">&#39;wires&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]},</span>
            <span class="p">{</span><span class="s1">&#39;input_idx&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="s1">&#39;ry&#39;</span><span class="p">,</span> <span class="s1">&#39;wires&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]},</span>
            <span class="p">{</span><span class="s1">&#39;input_idx&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="s1">&#39;ry&#39;</span><span class="p">,</span> <span class="s1">&#39;wires&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">]},</span>
            <span class="p">{</span><span class="s1">&#39;input_idx&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="s1">&#39;ry&#39;</span><span class="p">,</span> <span class="s1">&#39;wires&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">]},])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">RandomLayer</span><span class="p">(</span><span class="n">n_ops</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">MeasureAll</span><span class="p">(</span><span class="n">tq</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">bsz</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">size</span> <span class="o">=</span> <span class="mi">28</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

        <span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">[:,</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">r</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">r</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">bsz</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">use_qiskit</span><span class="p">:</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qiskit_processor</span><span class="o">.</span><span class="n">process_parameterized</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">)</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">)</span>

                <span class="n">data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">result</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="Build-the-whole-hybrid-model.">
<h2>Build the whole hybrid model.<a class="headerlink" href="#Build-the-whole-hybrid-model." title="Link to this heading">#</a></h2>
<p>Then we look at the whole model. The whole model consists of a <code class="docutils literal notranslate"><span class="pre">QuanvolutionFilter</span></code> and full connect layer(<code class="docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code>). The size of input is 4*14*14 because a 28x28 image after quanvolutional filter turns into a 4 channel 14x14 feature. As the task is MNIST 10 digits classification, the size of output is 10. At last the model perform <code class="docutils literal notranslate"><span class="pre">F.logsoftmax</span></code> to the result for classification.</p>
<div align="center"><p><img alt="conv-full-layer" class="no-scaled-link" src="https://github.com/mit-han-lab/torchquantum/blob/master/figs/hybridmodel.png?raw=true" style="width: 800px;" /></p>
</div><p>Here, we also has a model without quanvolutional filters used for comparison. Its full connect layer’s input size is simple 28x28.</p>
<div align="center"><p><img alt="conv-full-layer" class="no-scaled-link" src="https://github.com/mit-han-lab/torchquantum/blob/master/figs/classicalmodel.png?raw=true" style="width: 400px;" /></p>
</div><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HybridModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qf</span> <span class="o">=</span> <span class="n">QuanvolutionFilter</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="mi">14</span><span class="o">*</span><span class="mi">14</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
          <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">HybridModel_without_qf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Load-the-dataset-MNIST">
<h2>Load the dataset MNIST<a class="headerlink" href="#Load-the-dataset-MNIST" title="Link to this heading">#</a></h2>
<p>We use MNIST classification dataset(10 digits and 1000 training samples).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">root</span></code> is the folder that stores the dataset. If there’s no MNIST dataset in root, it will automatically download MNIST. Next, we set the <code class="docutils literal notranslate"><span class="pre">train_valid_split_ratio</span></code>, <code class="docutils literal notranslate"><span class="pre">n_test_samples</span></code>, and <code class="docutils literal notranslate"><span class="pre">n_train_samples</span></code>.</p>
<p>The dataset now contains three splits, ‘train’, ‘valid’ and ‘test’. For each split, we create a dataloader with a random sampler, <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is 10, <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> is 8 and <code class="docutils literal notranslate"><span class="pre">pin_memory</span></code> is true.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;./mnist_data&#39;</span><span class="p">,</span>
    <span class="n">train_valid_split_ratio</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="n">n_test_samples</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">n_train_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">dataflow</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="n">sampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])</span>
    <span class="n">dataflow</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ddcca6cc591f45a887f80bcc5d27ce13", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "23dbd6346f684afebcc4ea0d3e72a67e", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f314f3212d8f49468ccce3ad1cb8af6e", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ae65786c8b1e4e789ecb72bcd6b9b211", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[2022-02-16 04:00:40.771] Only use the front 500 images as TRAIN set.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
[2022-02-16 04:00:40.868] Only use the front 300 images as TEST set.
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
</pre></div></div>
</div>
<p>Then we set use_cuda, it depends on whether cuda is available.</p>
<p>Create a device.</p>
<p>Initialize the model, <code class="docutils literal notranslate"><span class="pre">n_epochs</span></code> to 15, Adam optimizer and cosine annealing learning rate scheduler.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">use_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">HybridModel</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model_without_qf</span> <span class="o">=</span> <span class="n">HybridModel_without_qf</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Train-the-model.">
<h2>Train the model.<a class="headerlink" href="#Train-the-model." title="Link to this heading">#</a></h2>
<p>When training the model, we iterate the dataloader. Get the <code class="docutils literal notranslate"><span class="pre">inputs</span></code> and <code class="docutils literal notranslate"><span class="pre">targets</span></code> data. Feed <code class="docutils literal notranslate"><span class="pre">inputs</span></code> to the model and get <code class="docutils literal notranslate"><span class="pre">outputs</span></code>. Calculate the negative loss likelihood loss(<code class="docutils literal notranslate"><span class="pre">F.nll_loss</span></code>). Reset all the gradients of parameters in the model to zero. Call <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> to perform backpropagation. Call <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code> to update all the parameters.</p>
<p>After each epoch, we will valid the model. In validation, we can use qiskit remote because we don’t need to calculate gradients.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">accu_list1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_list1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">accu_list2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_list2</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">feed_dict</span> <span class="ow">in</span> <span class="n">dataflow</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">feed_dict</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">feed_dict</span><span class="p">[</span><span class="s1">&#39;digit&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">valid_test</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="n">split</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">target_all</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">output_all</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">feed_dict</span> <span class="ow">in</span> <span class="n">dataflow</span><span class="p">[</span><span class="n">split</span><span class="p">]:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">feed_dict</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">feed_dict</span><span class="p">[</span><span class="s1">&#39;digit&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="n">qiskit</span><span class="p">)</span>

            <span class="n">target_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
            <span class="n">output_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">target_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">target_all</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">output_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output_all</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">output_all</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target_all</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">indices</span><span class="p">))</span>
    <span class="n">size</span> <span class="o">=</span> <span class="n">target_all</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">corrects</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">corrects</span> <span class="o">/</span> <span class="n">size</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output_all</span><span class="p">,</span> <span class="n">target_all</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2"> set accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">split</span><span class="si">}</span><span class="s2"> set loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">loss</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="c1"># train</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="n">train</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>

    <span class="c1"># valid</span>
    <span class="n">accu</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">valid_test</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="p">)</span>
    <span class="n">accu_list1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accu</span><span class="p">)</span>
    <span class="n">loss_list1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1:
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.005
test set accuracy: 0.8066666666666666
test set loss: 0.6323180794715881
Epoch 2:
0.004945369001834514
test set accuracy: 0.7766666666666666
test set loss: 0.5900668501853943
Epoch 3:
0.004783863644106502
test set accuracy: 0.8466666666666667
test set loss: 0.48249581456184387
Epoch 4:
0.0045225424859373685
test set accuracy: 0.8133333333333334
test set loss: 0.5225163698196411
Epoch 5:
0.0041728265158971455
test set accuracy: 0.8033333333333333
test set loss: 0.6009621620178223
Epoch 6:
0.00375
test set accuracy: 0.8333333333333334
test set loss: 0.44394049048423767
Epoch 7:
0.0032725424859373687
test set accuracy: 0.84
test set loss: 0.4330306053161621
Epoch 8:
0.002761321158169134
test set accuracy: 0.8366666666666667
test set loss: 0.45171523094177246
Epoch 9:
0.002238678841830867
test set accuracy: 0.8633333333333333
test set loss: 0.4244077205657959
Epoch 10:
0.001727457514062632
test set accuracy: 0.8633333333333333
test set loss: 0.40085339546203613
Epoch 11:
0.0012500000000000007
test set accuracy: 0.8533333333333334
test set loss: 0.40397733449935913
Epoch 12:
0.0008271734841028553
test set accuracy: 0.87
test set loss: 0.3975270986557007
Epoch 13:
0.00047745751406263163
test set accuracy: 0.8566666666666667
test set loss: 0.4006715416908264
Epoch 14:
0.00021613635589349755
test set accuracy: 0.8666666666666667
test set loss: 0.39790403842926025
Epoch 15:
5.463099816548578e-05
test set accuracy: 0.8666666666666667
test set loss: 0.3979119062423706
</pre></div></div>
</div>
<p>Train the model without quanvolutional filters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model_without_qf</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="c1"># train</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="n">train</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="n">model_without_qf</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>

    <span class="c1"># valid</span>
    <span class="n">accu</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">valid_test</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">model_without_qf</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">accu_list2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accu</span><span class="p">)</span>
    <span class="n">loss_list2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1:
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.005
test set accuracy: 0.7733333333333333
test set loss: 0.6043258905410767
Epoch 2:
0.004945369001834514
test set accuracy: 0.8166666666666667
test set loss: 0.5571645498275757
Epoch 3:
0.004783863644106502
test set accuracy: 0.8466666666666667
test set loss: 0.46128183603286743
Epoch 4:
0.0045225424859373685
test set accuracy: 0.8366666666666667
test set loss: 0.5158915519714355
Epoch 5:
0.0041728265158971455
test set accuracy: 0.8666666666666667
test set loss: 0.45338067412376404
Epoch 6:
0.00375
test set accuracy: 0.8466666666666667
test set loss: 0.4563254714012146
Epoch 7:
0.0032725424859373687
test set accuracy: 0.8566666666666667
test set loss: 0.4633018374443054
Epoch 8:
0.002761321158169134
test set accuracy: 0.86
test set loss: 0.46147480607032776
Epoch 9:
0.002238678841830867
test set accuracy: 0.85
test set loss: 0.45319321751594543
Epoch 10:
0.001727457514062632
test set accuracy: 0.84
test set loss: 0.46221110224723816
Epoch 11:
0.0012500000000000007
test set accuracy: 0.8533333333333334
test set loss: 0.4611275792121887
Epoch 12:
0.0008271734841028553
test set accuracy: 0.8533333333333334
test set loss: 0.4614029824733734
Epoch 13:
0.00047745751406263163
test set accuracy: 0.8533333333333334
test set loss: 0.4610340893268585
Epoch 14:
0.00021613635589349755
test set accuracy: 0.8533333333333334
test set loss: 0.46056315302848816
Epoch 15:
5.463099816548578e-05
test set accuracy: 0.8533333333333334
test set loss: 0.4606676697731018
</pre></div></div>
</div>
</section>
<section id="Compare-Quanvolutional-Neural-Network-with-classical-model.">
<h2>Compare Quanvolutional Neural Network with classical model.<a class="headerlink" href="#Compare-Quanvolutional-Neural-Network-with-classical-model." title="Link to this heading">#</a></h2>
<p>After training, we can plot the accuracy and loss curve. We can see that model with quanvolutional filter can achieve slightly higher accuracy than model without quanvolution.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">accu_list1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;with quanvolution filter&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">accu_list2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;without quanvolution filter&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mf">0.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;with quanvolution filter&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_list2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;without quanvolution filter&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_quanvolution_quanvolution_32_0.png" src="../../_images/examples_quanvolution_quanvolution_32_0.png" />
</div>
</div>
<p>Here we can also see the image before quanvolutional filter and after quanvolutional filter.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>

<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_channels</span> <span class="o">=</span> <span class="mi">4</span>
<span class="k">for</span> <span class="n">feed_dict</span> <span class="ow">in</span> <span class="n">dataflow</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]:</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">feed_dict</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="k">break</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:</span><span class="n">n_samples</span><span class="p">]</span>
<span class="n">after_quanv</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">qf</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">14</span><span class="o">*</span><span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">norm</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_channels</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">c</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;channel </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">c</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">after_quanv</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/examples_quanvolution_quanvolution_34_1.png" src="../../_images/examples_quanvolution_quanvolution_34_1.png" />
</div>
</div>
</section>
<section id="Evaluate-on-real-quantum-computer.">
<h2>Evaluate on real quantum computer.<a class="headerlink" href="#Evaluate-on-real-quantum-computer." title="Link to this heading">#</a></h2>
<p>At last, we can run our quanvolutional filter on IBMQ’s real quantum machine. The process is really slow so I will not show it here. If you have higher priority access to IBMQ qiskit, you can check the code cell in installation and replace our token with your advance token. That will make the process faster.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># test</span>
<span class="n">valid_test</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># run on Qiskit simulator and real Quantum Computers</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">qiskit</span> <span class="kn">import</span> <span class="n">IBMQ</span>
    <span class="kn">from</span> <span class="nn">torchquantum.plugin</span> <span class="kn">import</span> <span class="n">QiskitProcessor</span>
    <span class="c1"># firstly perform simulate</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test with Qiskit Simulator&quot;</span><span class="p">)</span>
    <span class="n">processor_simulation</span> <span class="o">=</span> <span class="n">QiskitProcessor</span><span class="p">(</span><span class="n">use_real_qc</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">qf</span><span class="o">.</span><span class="n">set_qiskit_processor</span><span class="p">(</span><span class="n">processor_simulation</span><span class="p">)</span>
    <span class="n">valid_test</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">qiskit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># then try to run on REAL QC</span>
    <span class="n">backend_name</span> <span class="o">=</span> <span class="s1">&#39;ibmq_quito&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test on Real Quantum Computer </span><span class="si">{</span><span class="n">backend_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">processor_real_qc</span> <span class="o">=</span> <span class="n">QiskitProcessor</span><span class="p">(</span><span class="n">use_real_qc</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">backend_name</span><span class="o">=</span><span class="n">backend_name</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">qf</span><span class="o">.</span><span class="n">set_qiskit_processor</span><span class="p">(</span><span class="n">processor_real_qc</span><span class="p">)</span>
    <span class="n">valid_test</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">qiskit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Please install qiskit, create an IBM Q Experience Account and &quot;</span>
          <span class="s2">&quot;save the account token according to the instruction at &quot;</span>
          <span class="s2">&quot;&#39;https://github.com/Qiskit/qiskit-ibmq-provider&#39;, &quot;</span>
          <span class="s2">&quot;then try again.&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<section id="Trainable-Quanvolutional-Filter">
<h3>Trainable Quanvolutional Filter<a class="headerlink" href="#Trainable-Quanvolutional-Filter" title="Link to this heading">#</a></h3>
<p>In this section, we consider the case that quanvolutional filters are trainable, and we compare various models with nearly the same number of trainale parameters. The four model compared here are described by the following figure.</p>
<div align="center"><p><img alt="conv-full-layer" class="no-scaled-link" src="https://github.com/mit-han-lab/torchquantum/blob/master/figs/4models.png?raw=true" style="width: 600px;" /></p>
</div><p>The Model1 contains a trainable quanvolutional filter and a fully connected layer.</p>
<p>The Model2 contains a trainable quanvolutional filter and a quantum fully connected layer. We use <code class="docutils literal notranslate"><span class="pre">U3CU3Layer0</span></code> from <code class="docutils literal notranslate"><span class="pre">torchquantum.layers</span></code> to implement the QFC layer.</p>
<p>When building the ansatz part of the QFC, we need to pass a dict describing the architecture of the ansatz. Here the dict is <code class="docutils literal notranslate"><span class="pre">{'n_wires':</span> <span class="pre">self.n_wires,</span> <span class="pre">'n_blocks':</span> <span class="pre">4,</span> <span class="pre">'n_layers_per_block':</span> <span class="pre">2}</span></code>, which means the ansatz contains n_wires qubits, there are 4 blocks and in each block are 2 layers. Passing the arch to <code class="docutils literal notranslate"><span class="pre">U3CU3Layer0</span></code> we will get a trainable ansatz with 4 blocks and in each block contains 4 U3 gates followed by 4 CU3 gates.</p>
<p>The Model3 is simply a QFC layer.</p>
<p>The Model4 is two fully connected layers.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchquantum.encoding</span> <span class="kn">import</span> <span class="n">encoder_op_list_name_dict</span>
<span class="kn">from</span> <span class="nn">torchquantum.layers</span> <span class="kn">import</span> <span class="n">U3CU3Layer0</span>

<span class="k">class</span> <span class="nc">TrainableQuanvFilter</span><span class="p">(</span><span class="n">tq</span><span class="o">.</span><span class="n">QuantumModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_device</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">QuantumDevice</span><span class="p">(</span><span class="n">n_wires</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">GeneralEncoder</span><span class="p">(</span>
        <span class="p">[</span>   <span class="p">{</span><span class="s1">&#39;input_idx&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="s1">&#39;ry&#39;</span><span class="p">,</span> <span class="s1">&#39;wires&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">]},</span>
            <span class="p">{</span><span class="s1">&#39;input_idx&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="s1">&#39;ry&#39;</span><span class="p">,</span> <span class="s1">&#39;wires&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">]},</span>
            <span class="p">{</span><span class="s1">&#39;input_idx&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="s1">&#39;ry&#39;</span><span class="p">,</span> <span class="s1">&#39;wires&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">]},</span>
            <span class="p">{</span><span class="s1">&#39;input_idx&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;func&#39;</span><span class="p">:</span> <span class="s1">&#39;ry&#39;</span><span class="p">,</span> <span class="s1">&#39;wires&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">]},])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">arch</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_wires&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span><span class="p">,</span> <span class="s1">&#39;n_blocks&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;n_layers_per_block&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span> <span class="o">=</span> <span class="n">U3CU3Layer0</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">MeasureAll</span><span class="p">(</span><span class="n">tq</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">bsz</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

        <span class="n">data_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">[:,</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">r</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">r</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">bsz</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">use_qiskit</span><span class="p">:</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qiskit_processor</span><span class="o">.</span><span class="n">process_parameterized</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">)</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">)</span>

                <span class="n">data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

        <span class="c1"># transpose to (bsz, channel, 2x2)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">result</span>

<span class="k">class</span> <span class="nc">QuantumClassifier</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_device</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">QuantumDevice</span><span class="p">(</span><span class="n">n_wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">GeneralEncoder</span><span class="p">(</span><span class="n">encoder_op_list_name_dict</span><span class="p">[</span><span class="s1">&#39;4x4_ryzxy&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">arch</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_wires&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span><span class="p">,</span> <span class="s1">&#39;n_blocks&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;n_layers_per_block&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span> <span class="o">=</span> <span class="n">U3CU3Layer0</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">MeasureAll</span><span class="p">(</span><span class="n">tq</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">bsz</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">use_qiskit</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qiskit_processor</span><span class="o">.</span><span class="n">process_parameterized</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">QFC</span><span class="p">(</span><span class="n">tq</span><span class="o">.</span><span class="n">QuantumModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_device</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">QuantumDevice</span><span class="p">(</span><span class="n">n_wires</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">GeneralEncoder</span><span class="p">(</span><span class="n">encoder_op_list_name_dict</span><span class="p">[</span><span class="s1">&#39;4x4_ryzxy&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">arch</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_wires&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_wires</span><span class="p">,</span> <span class="s1">&#39;n_blocks&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;n_layers_per_block&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span> <span class="o">=</span> <span class="n">U3CU3Layer0</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measure</span> <span class="o">=</span> <span class="n">tq</span><span class="o">.</span><span class="n">MeasureAll</span><span class="p">(</span><span class="n">tq</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">bsz</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">if</span> <span class="n">use_qiskit</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qiskit_processor</span><span class="o">.</span><span class="n">process_parameterized</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">q_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">measure</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span>


<span class="k">class</span> <span class="nc">Model1</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qf</span> <span class="o">=</span> <span class="n">TrainableQuanvFilter</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Model2</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qf</span> <span class="o">=</span> <span class="n">TrainableQuanvFilter</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qfc</span> <span class="o">=</span> <span class="n">QFC</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qfc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Model3</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qfc</span> <span class="o">=</span> <span class="n">QuantumClassifier</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qfc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Model4</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">use_qiskit</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
        <span class="n">bsz</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Here we do the MNIST 4 classification tasks.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;./mnist_data&#39;</span><span class="p">,</span>
    <span class="n">train_valid_split_ratio</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="n">digits_of_interest</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">n_test_samples</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">n_train_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">dataflow</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="n">sampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">RandomSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">])</span>
    <span class="n">dataflow</span><span class="p">[</span><span class="n">split</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">],</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">use_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">accus</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">model_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">Model1</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">Model2</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">Model3</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">Model4</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">model_list</span><span class="p">:</span>
  <span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">15</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
  <span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="c1"># train</span>
      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
      <span class="n">train</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>
      <span class="c1"># valid</span>
      <span class="n">accu</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">valid_test</span><span class="p">(</span><span class="n">dataflow</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
      <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
  <span class="n">accus</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accu</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">accu</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">accus</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;accuracy of model</span><span class="si">{0}</span><span class="s1">: </span><span class="si">{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">accu</span><span class="p">))</span>
</pre></div>
</div>
</div>
<script type="application/vnd.jupyter.widget-state+json">
{"18acae4757154a10a7e2b9ebe4fbd53b": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "1c75908cdb0d4909a266ef3f0184c13d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "237d834d5fd74efa947683722d3e0e37": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_c893fabe4af6410d837a0bd191df61d9", "max": 1648877, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_f86c7ffecc394345a4eeb587cfd404d1", "value": 1648877}}, "23dbd6346f684afebcc4ea0d3e72a67e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_3b090dcf208c4822892a0afc2ba2e6a9", "IPY_MODEL_d0a2f52a311541a686f592a985e1aac0", "IPY_MODEL_41e329d1bd764c7cad4d2e834df50cd9"], "layout": "IPY_MODEL_e85d5726a566462e962baa75f32074d6"}}, "26d0390ad17048799741582271721a3e": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "29be09a9c5344928a9d2dda75ed8680c": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_45f166ea914e49c5bcf2ec39a649e351", "placeholder": "\u200b", "style": "IPY_MODEL_f69883e80817409c9a10a2ec6d6ef68c", "value": " 1649664/? [00:00&lt;00:00, 6011445.81it/s]"}}, "30b8e4960e564891ad81ac242c228b25": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_a8e8fb1c355445698cbc828dddffb9e5", "placeholder": "\u200b", "style": "IPY_MODEL_d274e40c0adb4d3e80e8d1cf5ad475ee", "value": ""}}, "32bd67ddf3a44b879cb123aa797627c0": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_e81b4f6589d649758fd2cd18da8ab35f", "placeholder": "\u200b", "style": "IPY_MODEL_7584295a605c4a99a4dccce31be4cb2d", "value": ""}}, "34e1a2b9f934411090026a0ee98a3b5b": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "364f865b5e334ac6add27ef1a32b8173": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "393cc69622f3428fba3e10886e5ab65d": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3b090dcf208c4822892a0afc2ba2e6a9": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_b6d2f65a2e644523b7ecc6e3e9e17de3", "placeholder": "\u200b", "style": "IPY_MODEL_5de520efee524ca28ed5b1b42861bef7", "value": ""}}, "3f37e8639ddd4a6eac44420ce3275cd7": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "41e329d1bd764c7cad4d2e834df50cd9": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_26d0390ad17048799741582271721a3e", "placeholder": "\u200b", "style": "IPY_MODEL_c168c7416db742f5bc74d45fe4a9bf05", "value": " 29696/? [00:00&lt;00:00, 1002987.94it/s]"}}, "45f166ea914e49c5bcf2ec39a649e351": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4abe9a5443514e00a536c839a9a5e04d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "5335eb0e67f84c85b9efacc7793d24fd": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "5953a85cd7334c828cf5005b2807fa41": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_364f865b5e334ac6add27ef1a32b8173", "placeholder": "\u200b", "style": "IPY_MODEL_18acae4757154a10a7e2b9ebe4fbd53b", "value": ""}}, "5de520efee524ca28ed5b1b42861bef7": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "694229176eb84488811763e57ccdbd9f": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7584295a605c4a99a4dccce31be4cb2d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "7cbce63b72c843e9ad824dce59a7e2fb": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_393cc69622f3428fba3e10886e5ab65d", "placeholder": "\u200b", "style": "IPY_MODEL_1c75908cdb0d4909a266ef3f0184c13d", "value": " 5120/? [00:00&lt;00:00, 87902.47it/s]"}}, "952170c8ff4d4fa9b7141d372b35cdd1": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_3f37e8639ddd4a6eac44420ce3275cd7", "max": 4542, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_e2b60171e7ca45bea357831419d2f9c6", "value": 4542}}, "a8e8fb1c355445698cbc828dddffb9e5": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ace3e747ccfd4f9f9faf46ce34936ce1": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_34e1a2b9f934411090026a0ee98a3b5b", "placeholder": "\u200b", "style": "IPY_MODEL_5335eb0e67f84c85b9efacc7793d24fd", "value": " 9913344/? [00:00&lt;00:00, 30809548.66it/s]"}}, "ae65786c8b1e4e789ecb72bcd6b9b211": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_5953a85cd7334c828cf5005b2807fa41", "IPY_MODEL_952170c8ff4d4fa9b7141d372b35cdd1", "IPY_MODEL_7cbce63b72c843e9ad824dce59a7e2fb"], "layout": "IPY_MODEL_cfc67a5bebd247838d29b9babacbc103"}}, "b2ca643df597463dad1d5efe8abf64c4": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b6d2f65a2e644523b7ecc6e3e9e17de3": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c168c7416db742f5bc74d45fe4a9bf05": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "c46454929cae4e89976f42d9bc391a94": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_dc961678433f488babca027e197d2aa1", "max": 9912422, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_d312e5166b28438da2b9e91de91f0e09", "value": 9912422}}, "c893fabe4af6410d837a0bd191df61d9": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c8c570bdf96340c1bbf4e612f3d0c3c4": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "cfc67a5bebd247838d29b9babacbc103": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d0a2f52a311541a686f592a985e1aac0": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_b2ca643df597463dad1d5efe8abf64c4", "max": 28881, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_4abe9a5443514e00a536c839a9a5e04d", "value": 28881}}, "d274e40c0adb4d3e80e8d1cf5ad475ee": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "d312e5166b28438da2b9e91de91f0e09": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "dc961678433f488babca027e197d2aa1": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ddcca6cc591f45a887f80bcc5d27ce13": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_30b8e4960e564891ad81ac242c228b25", "IPY_MODEL_c46454929cae4e89976f42d9bc391a94", "IPY_MODEL_ace3e747ccfd4f9f9faf46ce34936ce1"], "layout": "IPY_MODEL_c8c570bdf96340c1bbf4e612f3d0c3c4"}}, "e2b60171e7ca45bea357831419d2f9c6": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "e81b4f6589d649758fd2cd18da8ab35f": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e85d5726a566462e962baa75f32074d6": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f314f3212d8f49468ccce3ad1cb8af6e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_32bd67ddf3a44b879cb123aa797627c0", "IPY_MODEL_237d834d5fd74efa947683722d3e0e37", "IPY_MODEL_29be09a9c5344928a9d2dda75ed8680c"], "layout": "IPY_MODEL_694229176eb84488811763e57ccdbd9f"}}, "f69883e80817409c9a10a2ec6d6ef68c": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "f86c7ffecc394345a4eeb587cfd404d1": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}}
</script></section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../superdense_coding/superdense_coding_torchquantum.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Superdense Coding</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../quantum_kernel_method/quantum_kernel_method.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Quantum Kernel Methods for IRIS dataset classification with TorchQuantum.</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2021, Hanrui Wang
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Quanvolution (Quantum convolution) for MNIST image classification with TorchQuantum.</a><ul>
<li><a class="reference internal" href="#Outline">Outline</a><ul>
<li><a class="reference internal" href="#Introduction-to-Quanvolutional-Neural-Network.">Introduction to Quanvolutional Neural Network.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Convolutional-Neural-Network">Convolutional Neural Network</a></li>
<li><a class="reference internal" href="#Quantum-convolution">Quantum convolution</a><ul>
<li><a class="reference internal" href="#Build-and-train-a-Quanvolutional-Neural-Network.">Build and train a Quanvolutional Neural Network.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Installation">Installation</a></li>
<li><a class="reference internal" href="#Step">Step</a></li>
<li><a class="reference internal" href="#Build-a-quanvolutional-filter">Build a quanvolutional filter</a></li>
<li><a class="reference internal" href="#Build-the-whole-hybrid-model.">Build the whole hybrid model.</a></li>
<li><a class="reference internal" href="#Load-the-dataset-MNIST">Load the dataset MNIST</a></li>
<li><a class="reference internal" href="#Train-the-model.">Train the model.</a></li>
<li><a class="reference internal" href="#Compare-Quanvolutional-Neural-Network-with-classical-model.">Compare Quanvolutional Neural Network with classical model.</a></li>
<li><a class="reference internal" href="#Evaluate-on-real-quantum-computer.">Evaluate on real quantum computer.</a><ul>
<li><a class="reference internal" href="#Trainable-Quanvolutional-Filter">Trainable Quanvolutional Filter</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=2709fde1"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=32e29ea5"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>